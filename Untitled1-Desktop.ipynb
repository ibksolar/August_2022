{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbf0fa04-d15f-40e3-bc8e-e0c581c9707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages Loaded\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,TensorBoard,ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.datasets import mnist, cifar10\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from scipy.io import loadmat \n",
    "import mat73\n",
    "from datetime import datetime\n",
    "import ipynbname\n",
    "import time\n",
    "\n",
    "\n",
    "from packaging import version\n",
    "print(\"Packages Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac4d22a9-05e5-4ece-bd8d-66a58fb87557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA RTX A6000, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e0ff66a-fe8d-4b53-923d-87fd82eaa274",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mibksolar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ibksolar/my-test-project/runs/3oc0qf8j\" target=\"_blank\">DenseLayers_trial</a></strong> to <a href=\"https://wandb.ai/ibksolar/my-test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/ibksolar/my-test-project/runs/3oc0qf8j?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x173a675a9d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "wandb.init(project=\"my-test-project\", \n",
    "           entity=\"ibksolar\",\n",
    "           name=\"DenseLayers_trial\",\n",
    "           config = {\n",
    "                          \"learning_rate\": \"NA\",\n",
    "                          \"epochs\": 50,\n",
    "                          \"batch_size\": 512,\n",
    "                          \"nodes\": 2048,\n",
    "                          \"row_length\":21,\n",
    "                          #\"base_path\":base_path,\n",
    "                          \"num_classes\":22,\n",
    "\n",
    "}\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0424b7b-4283-46f0-9bc9-01a09099c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# raw_data1 = loadmat('new_echo_cnn_in_out_jstarrs2021_first_try/echo_cnn_in_out_jstars1.mat')\n",
    "# raw_data1 = loadmat('echo_cnn_in_out_GOOD_layers/new_echo_cnn_in_out_jstars1.mat') 'findpeaks_layers/new_echo_cnn_in_out_jstars1.mat'\n",
    "\n",
    "raw_data1 = loadmat('../../../Python_Env/final_layers_rowblock15_21/filtered_image/new_echo_cnn_in_out_jstars1.mat')\n",
    "raw_data2 = loadmat('../../../Python_Env/final_layers_rowblock15_21/filtered_image/new_echo_cnn_in_out_jstars2.mat')\n",
    "raw_data3 = loadmat('../../../Python_Env/final_layers_rowblock15_21/filtered_image/new_echo_cnn_in_out_jstars3.mat')\n",
    "# raw_data4 = loadmat('findpeaks_layers_rowblock20/new_echo_cnn_in_out_jstars4.mat')\n",
    "\n",
    "d1 = raw_data1['echo_cnn1']\n",
    "t1 = raw_data1['echo_target1']\n",
    "i1 = raw_data1['echo_idx1']\n",
    "\n",
    "d2 = raw_data2['echo_cnn2']\n",
    "t2 = raw_data2['echo_target2']\n",
    "i2 = raw_data2['echo_idx2']\n",
    "\n",
    "d3 = raw_data3['echo_cnn3']\n",
    "t3 = raw_data3['echo_target3']\n",
    "i3 = raw_data3['echo_idx3']\n",
    "\n",
    "# d4 = raw_data4['echo_cnn4']\n",
    "# t4 = raw_data4['echo_target4']\n",
    "# i4 = raw_data4['echo_idx4']\n",
    "\n",
    "all_data = np.concatenate( (d1,d2,d3),axis = 0 )\n",
    "all_target = np.concatenate( (t1,t2,t3),axis = 0 )\n",
    "all_idx = np.concatenate( (i1,i2,i3),axis = 0 )\n",
    "\n",
    "# Set all nan in the data to zero\n",
    "nan_idx = np.isnan(all_data).any(axis =-1)\n",
    "all_target[nan_idx] = 0\n",
    "all_data[ np.isnan(all_data) ]= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9fb9b83-f2b1-4b99-82a7-e1580e7a2694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# base_path = '..\\\\..\\\\all_block_data\\Dec_Train_block_len_21_011121_2331'\n",
    "base_path = '../all_block_data/Old_data/Dec_Train_block_len_21_131121_2213'\n",
    "\n",
    "# Confirm path is right...\n",
    "print(f'{os.path.isdir(base_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e179ca79-43c2-45d8-a10e-1bb54507a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_new_data = False\n",
    "\n",
    "if load_new_data:    \n",
    "    raw_data1 = mat73.loadmat(base_path + '/echo_cnn_in_out_jstars.mat')\n",
    "    all_data = raw_data1['echo_cnn_input']#*255\n",
    "    all_target = raw_data1['echo_cnn_target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eaf3c7e-1bb9-4d3b-b0af-deca0f0995b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions match\n"
     ]
    }
   ],
   "source": [
    "row_length = 21 # CHANGE HERE <==\n",
    "col_length = 15\n",
    "\n",
    "# Check that the dimension of data is correct\n",
    "if all_data.shape[1] == row_length*col_length:\n",
    "    print('Dimensions match')\n",
    "else:\n",
    "    print(f' Row block length:{row_length} and col length:{col_length} does not match Data dimension:{all_data.shape[1]}') \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab1acb17-7dee-417b-97bc-8d0bba4e4cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_class = row_length \n",
    "\n",
    "# Highest class is mapped to row_length+1\n",
    "all_target[all_target == max_class+1 ] = 0\n",
    "\n",
    "\n",
    "shuffle = 1\n",
    "if shuffle:\n",
    "    random.Random(1337).shuffle(all_data)\n",
    "    random.Random(1337).shuffle(all_target)\n",
    "    random.Random(1337).shuffle(all_idx)\n",
    "\n",
    "## Prep data\n",
    "train_size = int(np.floor(0.75*len(all_target)));\n",
    "test_size = int(np.round( 0.15* all_data.shape[0] ))\n",
    "val_size = all_data.shape[0] -train_size - test_size\n",
    "\n",
    "\n",
    "x_train = all_data[0:train_size,:]\n",
    "\n",
    "x_test = all_data[train_size:train_size+test_size,:]\n",
    "\n",
    "x_val = all_data[-val_size:,:]\n",
    "\n",
    "y_train = all_target[:train_size]\n",
    "y_test  = all_target[train_size:train_size+test_size]\n",
    "y_val = all_target[-val_size:]\n",
    "\n",
    "var_input_shape = x_train.shape[1:] # 240 columns\n",
    "num_classes = max_class+1 # layers\n",
    "\n",
    "# Convert labels to categorical orthonormal vectors\n",
    "y_train_1hot = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_1hot  = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a2085b8-2b22-42ee-b8ed-e2d1e546ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = wandb.config\n",
    "config = {\n",
    "          \"learning_rate\": \"NA\",\n",
    "          #\"epochs\": 50,\n",
    "          #\"batch_size\": 512,\n",
    "          \"nodes\": 2048,\n",
    "          \"row_length\":21,\n",
    "          #\"base_path\":base_path,\n",
    "          \"num_classes\":22,\n",
    "}\n",
    "\n",
    "config['batch_size'] = 64\n",
    "config['epochs'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e92d5bc-42bf-4e33-974a-11bc2d2c0644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil\n",
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "class Monitor(Thread):\n",
    "    def __init__(self, delay, HardStop= False):\n",
    "        super(Monitor, self).__init__()\n",
    "        self.stopped = False\n",
    "        self.delay = delay # Time between calls to GPUtil\n",
    "        self.HardStop = HardStop\n",
    "        self.start()\n",
    "\n",
    "    def run(self):\n",
    "        while not self.stopped and not self.HardStop :\n",
    "            GPUtil.showUtilization()\n",
    "            time.sleep(self.delay)\n",
    "             \n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b709185f-c394-4c52-afa5-75bcf5964ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start time:14_March_22_1240\n",
      "Epoch 1/5\n",
      "1534/1534 [==============================] - 16s 10ms/step - loss: 1.9540 - accuracy: 0.2914 - top-3-accuracy: 0.0430 - val_loss: 1.5839 - val_accuracy: 0.4475 - val_top-3-accuracy: 0.0405 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "1534/1534 [==============================] - 15s 10ms/step - loss: 1.6141 - accuracy: 0.3843 - top-3-accuracy: 0.0467 - val_loss: 1.3862 - val_accuracy: 0.4733 - val_top-3-accuracy: 0.0606 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "1534/1534 [==============================] - 15s 10ms/step - loss: 1.4874 - accuracy: 0.4223 - top-3-accuracy: 0.0520 - val_loss: 1.8352 - val_accuracy: 0.3326 - val_top-3-accuracy: 0.0721 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "1534/1534 [==============================] - 15s 10ms/step - loss: 1.4150 - accuracy: 0.4461 - top-3-accuracy: 0.0540 - val_loss: 1.2537 - val_accuracy: 0.5327 - val_top-3-accuracy: 0.0545 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "1534/1534 [==============================] - 15s 10ms/step - loss: 1.3614 - accuracy: 0.4662 - top-3-accuracy: 0.0550 - val_loss: 1.3398 - val_accuracy: 0.5012 - val_top-3-accuracy: 0.0562 - lr: 0.0010\n",
      "Training End time:14_March_22_1241\n"
     ]
    }
   ],
   "source": [
    "# Define Sequential model with 3 layers\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(config['nodes'], activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dense(config['nodes'], activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(config['nodes'], activation=\"relu\", name=\"layer3\"),\n",
    "        layers.Dense(config['num_classes'],activation=\"softmax\", name=\"Final_layer\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "opt = tf.keras.optimizers.RMSprop(\n",
    "    learning_rate=0.001,\n",
    "    rho=0.999,\n",
    "    momentum=0.999,\n",
    "    epsilon=1e-07,\n",
    "    #centered=True,\n",
    "    name=\"RMSprop\")\n",
    "\n",
    "top_K = 3\n",
    "model.compile( \"rmsprop\", loss= 'sparse_categorical_crossentropy', metrics=['accuracy',tf.keras.metrics.TopKCategoricalAccuracy(top_K, name=\"top-3-accuracy\")])  #label_smoothing=0.05, tf.keras.losses.KLDivergence()\n",
    "#optimizer = opt,\"rmsprop\"\n",
    "\n",
    "\n",
    "# Callbacks\n",
    "config['start_time'] = datetime.strftime( datetime.now(),'%d_%B_%y_%H%M')\n",
    "model_save_path = os.path.join(os.path.dirname(os.getcwd()), r'all_block_data\\PulsedTrainTest')\n",
    "logs = model_save_path+'/'+ipynbname.name()+f\"/{config['start_time']}_logs/\" \n",
    "callbacks = [\n",
    "    #ModelCheckpoint(base_path2+'/'+ipynbname.name()+f\"/{start_time}_Checkpoint.h5\", save_best_only=True, monitor=\"val_loss\"),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.05, patience=15, min_lr=0.0001),\n",
    "    #EarlyStopping(monitor=\"val_loss\", patience=60, verbose=1),\n",
    "    TensorBoard(log_dir = logs,histogram_freq = 1,profile_batch = '1,20'),\n",
    "    #WandbCallback()\n",
    "]\n",
    "\n",
    "Report = {} # This reports time and GPU usage for each batch size\n",
    "\n",
    "for curr_batch_size in [ 1024]:  #128, 512,\n",
    "    \n",
    "    # Instantiate monitor with a 10-second delay between updates\n",
    "    #monitor = Monitor(10)\n",
    "    BUFFER_SIZE = curr_batch_size *2\n",
    "    \n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_ds = train_ds.shuffle(BUFFER_SIZE).batch(curr_batch_size).prefetch(AUTO)\n",
    "\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    test_ds = test_ds.batch(curr_batch_size).prefetch(AUTO)\n",
    "    \n",
    "    config['start_time'] = datetime.strftime( datetime.now(),'%d_%B_%y_%H%M') # Repeat to get exact start time\n",
    "    print(f'Training start time:{config[\"start_time\"]}')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    history = model.fit(train_ds,\n",
    "              epochs= config['epochs'], \n",
    "              batch_size= curr_batch_size, \n",
    "              validation_data=test_ds,\n",
    "             callbacks=callbacks) #mcp_save, callbacks=[reduce_lr_loss]\n",
    "\n",
    "    config['end_time'] = datetime.strftime( datetime.now(),'%d_%B_%y_%H%M')\n",
    "    stop_time= time.time()\n",
    "    print(f'Training End time:{config[\"end_time\"]}')\n",
    "    \n",
    "    # Update Record\n",
    "    \n",
    "    Report[curr_batch_size] = ( os.environ['COMPUTERNAME'],config['start_time'],config['end_time'],int(stop_time-start_time), monitor )\n",
    "    \n",
    "    # Close monitor\n",
    "    #monitor.stop()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d6ebe87-be62-45ed-9e32-4c8d1079c6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 73% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 73% |\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f96cc022-e090-4f3d-b031-efda3f6f5d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-47f771f62333593c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-47f771f62333593c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6245;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir={logz} --port=6245"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d1328a-78f7-4826-864f-1dfc513c5865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_2.8",
   "language": "python",
   "name": "tf2.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
