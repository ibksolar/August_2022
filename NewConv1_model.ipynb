{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44f51388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages Loaded\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,TensorBoard,ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.datasets import mnist, cifar10\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from scipy.io import loadmat \n",
    "import mat73\n",
    "from datetime import datetime\n",
    "import ipynbname\n",
    "\n",
    "print(\"Packages Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40ae7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c524bd30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mibksolar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ibksolar/my-test-project/runs/1zf9406l\" target=\"_blank\">Conv3BlocksJan2022_withfindpeaks_05_January_22_06_20</a></strong> to <a href=\"https://wandb.ai/ibksolar/my-test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/ibksolar/my-test-project/runs/1zf9406l?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2302ab84f70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "time_stamp = datetime.strftime( datetime.now(),'%d_%B_%y_%H_%M')\n",
    "Uniqueness_of_model = 'Experimenting with findpeaks(straight) data: Want to attempt shuffling of the data with ConvResNet with 3Blocks'\n",
    "\n",
    "wandb.init(project=\"my-test-project\", entity=\"ibksolar\", name=\"Conv3BlocksJan2022_withfindpeaks_\"+time_stamp)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c95ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# base_path = '..\\\\..\\\\all_block_data\\Dec_Train_block_len_21_011121_2331'\n",
    "#base_path = '../all_block_data/Old_data/Dec_Train_block_len_21_231121_1531'\n",
    "base_path = '../all_block_data\\FindPeaks_data\\Dec_Train_block_len_21_030122_0614'\n",
    "\n",
    "# Confirm path is right...\n",
    "print(f'{os.path.isdir(base_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7f5c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_data1 = mat73.loadmat(base_path + '/echo_cnn_in_out_jstars.mat')\n",
    "all_data = raw_data1['echo_cnn_input']\n",
    "all_target = raw_data1['echo_cnn_target']\n",
    "coords = raw_data1['coords']\n",
    "echo_idx = raw_data1['orig_echo_idx']\n",
    "\n",
    "# Set all nan in the data to zero\n",
    "nan_idx = np.isnan(all_data).any(axis =-1)\n",
    "all_target[nan_idx] = 0\n",
    "all_data[ np.isnan(all_data) ]= 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff24c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate data because data after truncate point is notgood for training\n",
    "truncate_data = False\n",
    "if truncate_data:    \n",
    "    echo_idx = np.asarray(echo_idx)\n",
    "    stop_val = 600\n",
    "\n",
    "    stop_list, = np.where(echo_idx == stop_val)\n",
    "    stop_idx = stop_list[-1]\n",
    "\n",
    "    all_data = all_data[:stop_idx]\n",
    "    all_target = all_target[:stop_idx]\n",
    "\n",
    "    print(f'Data shape {all_data.shape}')\n",
    "    print(f'Target shape {all_target.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc47ab2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions match\n"
     ]
    }
   ],
   "source": [
    "row_length = 21 # CHANGE HERE <==\n",
    "col_length = 15\n",
    "\n",
    "# Check that the dimension of data is correct\n",
    "if all_data.shape[1] == row_length*col_length:\n",
    "    print('Dimensions match')\n",
    "else:\n",
    "    print(f' Row block length:{row_length} and col length:{col_length} does not match Data dimension:{all_data.shape[1]}') \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e07a19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:(1897984, 21, 5, 1)  X_test:(355872, 21, 5, 1)\n",
      "Shape of y_train:(1897984,)  y_test:(355872,)\n"
     ]
    }
   ],
   "source": [
    "max_class = row_length \n",
    "\n",
    "# Highest class is mapped to row_length+1\n",
    "all_target[all_target == max_class+1 ] = 0\n",
    "\n",
    "\n",
    "shuffle = 1\n",
    "if shuffle:\n",
    "    random.Random(1337).shuffle(all_data)\n",
    "    random.Random(1337).shuffle(all_target)\n",
    "    # random.Random(1337).shuffle(all_idx)\n",
    "\n",
    "## Prep data\n",
    "train_size = int(np.floor(0.8*len(all_target)));\n",
    "test_size = int(np.round( 0.15* all_data.shape[0] ))\n",
    "val_size = all_data.shape[0] -train_size - test_size\n",
    "\n",
    "mid_pt = 8\n",
    "x_train = all_data[0:train_size,:]\n",
    "x_train = np.reshape( x_train, (x_train.shape[0],max_class,-1,1), order = 'F' )\n",
    "x_train = x_train[:,:,mid_pt-2:mid_pt+3,:]\n",
    "\n",
    "x_test = all_data[train_size:train_size+test_size,:]\n",
    "x_test = np.reshape( x_test,(x_test.shape[0],max_class,-1,1), order = 'F' )\n",
    "x_test = x_test[:,:,mid_pt-2:mid_pt+3,:]\n",
    "\n",
    "x_val = all_data[-val_size:,:]\n",
    "x_val = np.reshape( x_val,(x_val.shape[0],max_class,-1,1), order = 'F' )\n",
    "x_val = x_val[:,:,mid_pt-2:mid_pt+3,:]\n",
    "\n",
    "y_train = all_target[:train_size]\n",
    "y_test  = all_target[train_size:train_size+test_size]\n",
    "y_val = all_target[-val_size:]\n",
    "\n",
    "var_input_shape = x_train.shape[1:] # 240 columns\n",
    "num_classes = max_class+1 # layers\n",
    "\n",
    "\n",
    "# Convert labels to categorical orthonormal vectors\n",
    "# y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test  = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(f'Shape of X_train:{x_train.shape}  X_test:{x_test.shape}')\n",
    "print(f'Shape of y_train:{y_train.shape}  y_test:{y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d1609a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "print(num_classes)\n",
    "print(len(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95897dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some of the input\n",
    "\n",
    "_ = plt.plot(x_train[200].flatten())\n",
    "_ = plt.title(y_train[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ebb7754-4ce6-42d0-9de3-10caf47d1d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get file name: auto-generating name\n",
      "Activation_function not in workspace\n",
      "extras  is not in workspace\n",
      "Current run hyper_params are dict_keys(['S_N', 'Start_time', 'NoteBook_name', 'Uniqueness_of_each_run', 'Base_dir', 'Train_shape', 'Output_shape', 'num_epochs', 'Activation_function', 'optimizer', 'learning_rate', 'loss_function', 'Accuracy_per_epoch', 'Loss_per_epoch', 'Stop_time', 'Model_config', 'Performance_on_test_set', 'output_path', 'shuffle', 'Computer_name', 'extras']):dict_values([3, '05_January_22_0733', 'Conv3Blocks', 'Experimenting with findpeaks(straight) data: Want to attempt shuffling of the data with ConvResNet with 3Blocks', '../all_block_data\\\\FindPeaks_data\\\\Dec_Train_block_len_21_030122_0614', (1897984, 21, 5, 1), '', '', '', '', '', '', [], [], '', '', '', '', 1, 'AQ-LHJBMA1', ''])\n",
      "Fields to be updated include: ['Activation_function', 'learning_rate', 'loss_function', 'Accuracy_per_epoch', 'Loss_per_epoch', 'Stop_time', 'Model_config', 'Performance_on_test_set', 'extras']\n"
     ]
    }
   ],
   "source": [
    "# Populate the param log\n",
    "log ={}\n",
    "log['Notebook_name'] = \"Conv3Blocks\" #ipynbname.name()\n",
    "log['Uniqueness_of_each_run'] = Uniqueness_of_model\n",
    "log['base_dir'] = base_path\n",
    "log['Train_shape'] = x_train.shape\n",
    "log['Output_shape'] = ''\n",
    "log['num_epochs'] = ''\n",
    "log['batch_size'] = ''\n",
    "log['activation_function'] = ''\n",
    "log['optimizer'] = ''\n",
    "log['learning_rate'] = ''\n",
    "log['loss_finction'] = ''\n",
    "log['accuracy'] = []\n",
    "log['loss'] = []\n",
    "log['stop_time'] = ''\n",
    "log['Model_config'] = ''\n",
    "log['Performance_on_test_set'] = ''\n",
    "log['output_path'] = ''  # output: where the trained model is saved\n",
    "log['shuffle'] = shuffle\n",
    "log['run_completion_comment'] = '' # Comment on training and probably evaluation too\n",
    "\n",
    "from model_hyper_param_log import create_log_entry, update_log_entry\n",
    "if \"log_idx\" in globals():\n",
    "    log[\"S_N\"] = log_idx\n",
    "log_idx = create_log_entry('../testing_sheet2.xlsx', log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6cbc2d5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "11835/11835 [==============================] - 753s 63ms/step - loss: 2.4890 - sparse_categorical_accuracy: 0.1335 - sparse_top_k_categorical_accuracy: 0.3829 - val_loss: 2.3137 - val_sparse_categorical_accuracy: 0.1731 - val_sparse_top_k_categorical_accuracy: 0.4632 - lr: 3.0000e-04\n",
      "Epoch 2/70\n",
      "11835/11835 [==============================] - 766s 65ms/step - loss: 2.3895 - sparse_categorical_accuracy: 0.1686 - sparse_top_k_categorical_accuracy: 0.4370 - val_loss: 2.2221 - val_sparse_categorical_accuracy: 0.2431 - val_sparse_top_k_categorical_accuracy: 0.5704 - lr: 3.0000e-04\n",
      "Epoch 3/70\n",
      "11835/11835 [==============================] - 749s 63ms/step - loss: 2.3322 - sparse_categorical_accuracy: 0.2178 - sparse_top_k_categorical_accuracy: 0.5132 - val_loss: 2.0592 - val_sparse_categorical_accuracy: 0.3354 - val_sparse_top_k_categorical_accuracy: 0.7480 - lr: 3.0000e-04\n",
      "Epoch 4/70\n",
      "11835/11835 [==============================] - 765s 65ms/step - loss: 2.3133 - sparse_categorical_accuracy: 0.2300 - sparse_top_k_categorical_accuracy: 0.5252 - val_loss: 2.0125 - val_sparse_categorical_accuracy: 0.3580 - val_sparse_top_k_categorical_accuracy: 0.7593 - lr: 3.0000e-04\n",
      "Epoch 5/70\n",
      "11835/11835 [==============================] - 761s 64ms/step - loss: 2.2935 - sparse_categorical_accuracy: 0.2386 - sparse_top_k_categorical_accuracy: 0.5303 - val_loss: 1.9463 - val_sparse_categorical_accuracy: 0.3795 - val_sparse_top_k_categorical_accuracy: 0.7688 - lr: 3.0000e-04\n",
      "Epoch 6/70\n",
      "11835/11835 [==============================] - 759s 64ms/step - loss: 2.2794 - sparse_categorical_accuracy: 0.2525 - sparse_top_k_categorical_accuracy: 0.5342 - val_loss: 1.9458 - val_sparse_categorical_accuracy: 0.4024 - val_sparse_top_k_categorical_accuracy: 0.7759 - lr: 3.0000e-04\n",
      "Epoch 7/70\n",
      "11835/11835 [==============================] - 748s 63ms/step - loss: 2.2720 - sparse_categorical_accuracy: 0.2604 - sparse_top_k_categorical_accuracy: 0.5372 - val_loss: 1.8849 - val_sparse_categorical_accuracy: 0.4216 - val_sparse_top_k_categorical_accuracy: 0.7809 - lr: 3.0000e-04\n",
      "Epoch 8/70\n",
      "11835/11835 [==============================] - 765s 65ms/step - loss: 2.2675 - sparse_categorical_accuracy: 0.2636 - sparse_top_k_categorical_accuracy: 0.5385 - val_loss: 1.8845 - val_sparse_categorical_accuracy: 0.4334 - val_sparse_top_k_categorical_accuracy: 0.7817 - lr: 3.0000e-04\n",
      "Epoch 9/70\n",
      "11835/11835 [==============================] - 755s 64ms/step - loss: 2.2643 - sparse_categorical_accuracy: 0.2662 - sparse_top_k_categorical_accuracy: 0.5399 - val_loss: 1.8939 - val_sparse_categorical_accuracy: 0.4368 - val_sparse_top_k_categorical_accuracy: 0.7818 - lr: 3.0000e-04\n",
      "Epoch 10/70\n",
      "11835/11835 [==============================] - 778s 66ms/step - loss: 2.2616 - sparse_categorical_accuracy: 0.2685 - sparse_top_k_categorical_accuracy: 0.5409 - val_loss: 1.8690 - val_sparse_categorical_accuracy: 0.4342 - val_sparse_top_k_categorical_accuracy: 0.7871 - lr: 3.0000e-04\n",
      "Epoch 11/70\n",
      "11835/11835 [==============================] - 771s 65ms/step - loss: 2.2593 - sparse_categorical_accuracy: 0.2714 - sparse_top_k_categorical_accuracy: 0.5412 - val_loss: 1.8879 - val_sparse_categorical_accuracy: 0.4417 - val_sparse_top_k_categorical_accuracy: 0.7824 - lr: 3.0000e-04\n",
      "Epoch 12/70\n",
      "11835/11835 [==============================] - 773s 65ms/step - loss: 2.2575 - sparse_categorical_accuracy: 0.2729 - sparse_top_k_categorical_accuracy: 0.5422 - val_loss: 1.8505 - val_sparse_categorical_accuracy: 0.4408 - val_sparse_top_k_categorical_accuracy: 0.7848 - lr: 3.0000e-04\n",
      "Epoch 13/70\n",
      "11835/11835 [==============================] - 765s 65ms/step - loss: 2.2556 - sparse_categorical_accuracy: 0.2742 - sparse_top_k_categorical_accuracy: 0.5427 - val_loss: 1.8509 - val_sparse_categorical_accuracy: 0.4487 - val_sparse_top_k_categorical_accuracy: 0.7897 - lr: 3.0000e-04\n",
      "Epoch 14/70\n",
      "11835/11835 [==============================] - 759s 64ms/step - loss: 2.2540 - sparse_categorical_accuracy: 0.2756 - sparse_top_k_categorical_accuracy: 0.5431 - val_loss: 1.8357 - val_sparse_categorical_accuracy: 0.4486 - val_sparse_top_k_categorical_accuracy: 0.7903 - lr: 3.0000e-04\n",
      "Epoch 15/70\n",
      "11835/11835 [==============================] - 770s 65ms/step - loss: 2.2527 - sparse_categorical_accuracy: 0.2772 - sparse_top_k_categorical_accuracy: 0.5436 - val_loss: 1.8593 - val_sparse_categorical_accuracy: 0.4536 - val_sparse_top_k_categorical_accuracy: 0.7859 - lr: 3.0000e-04\n",
      "Epoch 16/70\n",
      "11835/11835 [==============================] - 765s 65ms/step - loss: 2.2511 - sparse_categorical_accuracy: 0.2780 - sparse_top_k_categorical_accuracy: 0.5443 - val_loss: 1.8236 - val_sparse_categorical_accuracy: 0.4573 - val_sparse_top_k_categorical_accuracy: 0.7891 - lr: 3.0000e-04\n",
      "Epoch 17/70\n",
      "11835/11835 [==============================] - 777s 66ms/step - loss: 2.2498 - sparse_categorical_accuracy: 0.2795 - sparse_top_k_categorical_accuracy: 0.5448 - val_loss: 1.8316 - val_sparse_categorical_accuracy: 0.4501 - val_sparse_top_k_categorical_accuracy: 0.7879 - lr: 3.0000e-04\n",
      "Epoch 18/70\n",
      "11835/11835 [==============================] - 773s 65ms/step - loss: 2.2485 - sparse_categorical_accuracy: 0.2799 - sparse_top_k_categorical_accuracy: 0.5453 - val_loss: 1.8207 - val_sparse_categorical_accuracy: 0.4630 - val_sparse_top_k_categorical_accuracy: 0.7928 - lr: 3.0000e-04\n",
      "Epoch 19/70\n",
      "11835/11835 [==============================] - 778s 66ms/step - loss: 2.2426 - sparse_categorical_accuracy: 0.2835 - sparse_top_k_categorical_accuracy: 0.5465 - val_loss: 1.8078 - val_sparse_categorical_accuracy: 0.4625 - val_sparse_top_k_categorical_accuracy: 0.7875 - lr: 3.0000e-04\n",
      "Epoch 20/70\n",
      "11835/11835 [==============================] - 772s 65ms/step - loss: 2.2379 - sparse_categorical_accuracy: 0.2858 - sparse_top_k_categorical_accuracy: 0.5483 - val_loss: 1.7968 - val_sparse_categorical_accuracy: 0.4716 - val_sparse_top_k_categorical_accuracy: 0.8003 - lr: 3.0000e-04\n",
      "Epoch 21/70\n",
      "11835/11835 [==============================] - 772s 65ms/step - loss: 2.2351 - sparse_categorical_accuracy: 0.2878 - sparse_top_k_categorical_accuracy: 0.5495 - val_loss: 1.7864 - val_sparse_categorical_accuracy: 0.4707 - val_sparse_top_k_categorical_accuracy: 0.7996 - lr: 3.0000e-04\n",
      "Epoch 22/70\n",
      "11835/11835 [==============================] - 767s 65ms/step - loss: 2.2328 - sparse_categorical_accuracy: 0.2889 - sparse_top_k_categorical_accuracy: 0.5500 - val_loss: 1.8065 - val_sparse_categorical_accuracy: 0.4655 - val_sparse_top_k_categorical_accuracy: 0.7996 - lr: 3.0000e-04\n",
      "Epoch 23/70\n",
      "11835/11835 [==============================] - 771s 65ms/step - loss: 2.2311 - sparse_categorical_accuracy: 0.2902 - sparse_top_k_categorical_accuracy: 0.5509 - val_loss: 1.8007 - val_sparse_categorical_accuracy: 0.4765 - val_sparse_top_k_categorical_accuracy: 0.7996 - lr: 3.0000e-04\n",
      "Epoch 24/70\n",
      "11835/11835 [==============================] - 770s 65ms/step - loss: 2.2273 - sparse_categorical_accuracy: 0.2906 - sparse_top_k_categorical_accuracy: 0.5508 - val_loss: 1.8100 - val_sparse_categorical_accuracy: 0.4632 - val_sparse_top_k_categorical_accuracy: 0.7938 - lr: 3.0000e-04\n",
      "Epoch 25/70\n",
      "11835/11835 [==============================] - 742s 63ms/step - loss: 2.2220 - sparse_categorical_accuracy: 0.2920 - sparse_top_k_categorical_accuracy: 0.5515 - val_loss: 1.7555 - val_sparse_categorical_accuracy: 0.4913 - val_sparse_top_k_categorical_accuracy: 0.8048 - lr: 3.0000e-04\n",
      "Epoch 26/70\n",
      "11835/11835 [==============================] - 760s 64ms/step - loss: 2.2185 - sparse_categorical_accuracy: 0.2939 - sparse_top_k_categorical_accuracy: 0.5520 - val_loss: 1.7550 - val_sparse_categorical_accuracy: 0.4876 - val_sparse_top_k_categorical_accuracy: 0.8056 - lr: 3.0000e-04\n",
      "Epoch 27/70\n",
      "11835/11835 [==============================] - 760s 64ms/step - loss: 2.2149 - sparse_categorical_accuracy: 0.2959 - sparse_top_k_categorical_accuracy: 0.5533 - val_loss: 1.7519 - val_sparse_categorical_accuracy: 0.4874 - val_sparse_top_k_categorical_accuracy: 0.7993 - lr: 3.0000e-04\n",
      "Epoch 28/70\n",
      "11835/11835 [==============================] - 768s 65ms/step - loss: 2.2124 - sparse_categorical_accuracy: 0.2978 - sparse_top_k_categorical_accuracy: 0.5533 - val_loss: 1.7383 - val_sparse_categorical_accuracy: 0.4909 - val_sparse_top_k_categorical_accuracy: 0.8015 - lr: 3.0000e-04\n",
      "Epoch 29/70\n",
      "11835/11835 [==============================] - 779s 66ms/step - loss: 2.2095 - sparse_categorical_accuracy: 0.2996 - sparse_top_k_categorical_accuracy: 0.5536 - val_loss: 1.7216 - val_sparse_categorical_accuracy: 0.4986 - val_sparse_top_k_categorical_accuracy: 0.8035 - lr: 3.0000e-04\n",
      "Epoch 30/70\n",
      "11835/11835 [==============================] - 779s 66ms/step - loss: 2.2072 - sparse_categorical_accuracy: 0.3008 - sparse_top_k_categorical_accuracy: 0.5542 - val_loss: 1.7275 - val_sparse_categorical_accuracy: 0.5078 - val_sparse_top_k_categorical_accuracy: 0.8039 - lr: 3.0000e-04\n",
      "Epoch 31/70\n",
      "11835/11835 [==============================] - 780s 66ms/step - loss: 2.2050 - sparse_categorical_accuracy: 0.3025 - sparse_top_k_categorical_accuracy: 0.5544 - val_loss: 1.7318 - val_sparse_categorical_accuracy: 0.4977 - val_sparse_top_k_categorical_accuracy: 0.7986 - lr: 3.0000e-04\n",
      "Epoch 32/70\n",
      "11835/11835 [==============================] - 771s 65ms/step - loss: 2.2034 - sparse_categorical_accuracy: 0.3038 - sparse_top_k_categorical_accuracy: 0.5550 - val_loss: 1.7315 - val_sparse_categorical_accuracy: 0.5106 - val_sparse_top_k_categorical_accuracy: 0.7983 - lr: 3.0000e-04\n",
      "Epoch 33/70\n",
      "11835/11835 [==============================] - 777s 66ms/step - loss: 2.2014 - sparse_categorical_accuracy: 0.3054 - sparse_top_k_categorical_accuracy: 0.5552 - val_loss: 1.7087 - val_sparse_categorical_accuracy: 0.5121 - val_sparse_top_k_categorical_accuracy: 0.8044 - lr: 3.0000e-04\n",
      "Epoch 34/70\n",
      "11835/11835 [==============================] - 766s 65ms/step - loss: 2.1998 - sparse_categorical_accuracy: 0.3068 - sparse_top_k_categorical_accuracy: 0.5558 - val_loss: 1.7104 - val_sparse_categorical_accuracy: 0.5185 - val_sparse_top_k_categorical_accuracy: 0.8010 - lr: 3.0000e-04\n",
      "Epoch 35/70\n",
      "11835/11835 [==============================] - 771s 65ms/step - loss: 2.1986 - sparse_categorical_accuracy: 0.3080 - sparse_top_k_categorical_accuracy: 0.5557 - val_loss: 1.6976 - val_sparse_categorical_accuracy: 0.5093 - val_sparse_top_k_categorical_accuracy: 0.7982 - lr: 3.0000e-04\n",
      "Epoch 36/70\n",
      "11835/11835 [==============================] - 772s 65ms/step - loss: 2.1971 - sparse_categorical_accuracy: 0.3094 - sparse_top_k_categorical_accuracy: 0.5560 - val_loss: 1.6940 - val_sparse_categorical_accuracy: 0.5210 - val_sparse_top_k_categorical_accuracy: 0.8019 - lr: 3.0000e-04\n",
      "Epoch 37/70\n",
      "11835/11835 [==============================] - 780s 66ms/step - loss: 2.1955 - sparse_categorical_accuracy: 0.3098 - sparse_top_k_categorical_accuracy: 0.5562 - val_loss: 1.7066 - val_sparse_categorical_accuracy: 0.5214 - val_sparse_top_k_categorical_accuracy: 0.8005 - lr: 3.0000e-04\n",
      "Epoch 38/70\n",
      "11835/11835 [==============================] - 774s 65ms/step - loss: 2.1944 - sparse_categorical_accuracy: 0.3110 - sparse_top_k_categorical_accuracy: 0.5563 - val_loss: 1.7161 - val_sparse_categorical_accuracy: 0.5247 - val_sparse_top_k_categorical_accuracy: 0.8007 - lr: 3.0000e-04\n",
      "Epoch 39/70\n",
      "11835/11835 [==============================] - 779s 66ms/step - loss: 2.1930 - sparse_categorical_accuracy: 0.3118 - sparse_top_k_categorical_accuracy: 0.5572 - val_loss: 1.7036 - val_sparse_categorical_accuracy: 0.5268 - val_sparse_top_k_categorical_accuracy: 0.8038 - lr: 3.0000e-04\n",
      "Epoch 40/70\n",
      "11835/11835 [==============================] - 756s 64ms/step - loss: 2.1921 - sparse_categorical_accuracy: 0.3125 - sparse_top_k_categorical_accuracy: 0.5572 - val_loss: 1.6966 - val_sparse_categorical_accuracy: 0.5180 - val_sparse_top_k_categorical_accuracy: 0.7966 - lr: 3.0000e-04\n",
      "Epoch 41/70\n",
      "11835/11835 [==============================] - 752s 64ms/step - loss: 2.1908 - sparse_categorical_accuracy: 0.3132 - sparse_top_k_categorical_accuracy: 0.5573 - val_loss: 1.6937 - val_sparse_categorical_accuracy: 0.5182 - val_sparse_top_k_categorical_accuracy: 0.7965 - lr: 3.0000e-04\n",
      "Epoch 42/70\n",
      "11835/11835 [==============================] - 773s 65ms/step - loss: 2.1898 - sparse_categorical_accuracy: 0.3140 - sparse_top_k_categorical_accuracy: 0.5575 - val_loss: 1.7041 - val_sparse_categorical_accuracy: 0.5299 - val_sparse_top_k_categorical_accuracy: 0.8024 - lr: 3.0000e-04\n",
      "Epoch 43/70\n",
      "11835/11835 [==============================] - 769s 65ms/step - loss: 2.1887 - sparse_categorical_accuracy: 0.3145 - sparse_top_k_categorical_accuracy: 0.5575 - val_loss: 1.6780 - val_sparse_categorical_accuracy: 0.5291 - val_sparse_top_k_categorical_accuracy: 0.7994 - lr: 3.0000e-04\n",
      "Epoch 44/70\n",
      "11835/11835 [==============================] - 769s 65ms/step - loss: 2.1877 - sparse_categorical_accuracy: 0.3149 - sparse_top_k_categorical_accuracy: 0.5583 - val_loss: 1.7169 - val_sparse_categorical_accuracy: 0.5270 - val_sparse_top_k_categorical_accuracy: 0.7994 - lr: 3.0000e-04\n",
      "Epoch 45/70\n",
      "11835/11835 [==============================] - 757s 64ms/step - loss: 2.1842 - sparse_categorical_accuracy: 0.3162 - sparse_top_k_categorical_accuracy: 0.5586 - val_loss: 1.6817 - val_sparse_categorical_accuracy: 0.5257 - val_sparse_top_k_categorical_accuracy: 0.7959 - lr: 3.0000e-04\n",
      "Epoch 46/70\n",
      "11835/11835 [==============================] - 762s 64ms/step - loss: 2.1817 - sparse_categorical_accuracy: 0.3173 - sparse_top_k_categorical_accuracy: 0.5590 - val_loss: 1.6846 - val_sparse_categorical_accuracy: 0.5393 - val_sparse_top_k_categorical_accuracy: 0.8029 - lr: 3.0000e-04\n",
      "Epoch 47/70\n",
      "11835/11835 [==============================] - 754s 64ms/step - loss: 2.1790 - sparse_categorical_accuracy: 0.3182 - sparse_top_k_categorical_accuracy: 0.5594 - val_loss: 1.6707 - val_sparse_categorical_accuracy: 0.5223 - val_sparse_top_k_categorical_accuracy: 0.7982 - lr: 3.0000e-04\n",
      "Epoch 48/70\n",
      "11835/11835 [==============================] - 754s 64ms/step - loss: 2.1770 - sparse_categorical_accuracy: 0.3186 - sparse_top_k_categorical_accuracy: 0.5597 - val_loss: 1.6791 - val_sparse_categorical_accuracy: 0.5332 - val_sparse_top_k_categorical_accuracy: 0.7993 - lr: 3.0000e-04\n",
      "Epoch 49/70\n",
      "11835/11835 [==============================] - 760s 64ms/step - loss: 2.1755 - sparse_categorical_accuracy: 0.3195 - sparse_top_k_categorical_accuracy: 0.5602 - val_loss: 1.6712 - val_sparse_categorical_accuracy: 0.5459 - val_sparse_top_k_categorical_accuracy: 0.8041 - lr: 3.0000e-04\n",
      "Epoch 50/70\n",
      "11835/11835 [==============================] - 768s 65ms/step - loss: 2.1740 - sparse_categorical_accuracy: 0.3195 - sparse_top_k_categorical_accuracy: 0.5606 - val_loss: 1.6640 - val_sparse_categorical_accuracy: 0.5410 - val_sparse_top_k_categorical_accuracy: 0.7989 - lr: 3.0000e-04\n",
      "Epoch 51/70\n",
      "11835/11835 [==============================] - 774s 65ms/step - loss: 2.1726 - sparse_categorical_accuracy: 0.3208 - sparse_top_k_categorical_accuracy: 0.5604 - val_loss: 1.6644 - val_sparse_categorical_accuracy: 0.5468 - val_sparse_top_k_categorical_accuracy: 0.7993 - lr: 3.0000e-04\n",
      "Epoch 52/70\n",
      "11835/11835 [==============================] - 766s 65ms/step - loss: 2.1714 - sparse_categorical_accuracy: 0.3214 - sparse_top_k_categorical_accuracy: 0.5610 - val_loss: 1.6428 - val_sparse_categorical_accuracy: 0.5423 - val_sparse_top_k_categorical_accuracy: 0.8024 - lr: 3.0000e-04\n",
      "Epoch 53/70\n",
      "11835/11835 [==============================] - 767s 65ms/step - loss: 2.1705 - sparse_categorical_accuracy: 0.3219 - sparse_top_k_categorical_accuracy: 0.5613 - val_loss: 1.6575 - val_sparse_categorical_accuracy: 0.5497 - val_sparse_top_k_categorical_accuracy: 0.8019 - lr: 3.0000e-04\n",
      "Epoch 54/70\n",
      "11835/11835 [==============================] - 775s 65ms/step - loss: 2.1697 - sparse_categorical_accuracy: 0.3225 - sparse_top_k_categorical_accuracy: 0.5614 - val_loss: 1.6303 - val_sparse_categorical_accuracy: 0.5455 - val_sparse_top_k_categorical_accuracy: 0.8057 - lr: 3.0000e-04\n",
      "Epoch 55/70\n",
      "11835/11835 [==============================] - 773s 65ms/step - loss: 2.1684 - sparse_categorical_accuracy: 0.3227 - sparse_top_k_categorical_accuracy: 0.5616 - val_loss: 1.6503 - val_sparse_categorical_accuracy: 0.5489 - val_sparse_top_k_categorical_accuracy: 0.8044 - lr: 3.0000e-04\n",
      "Epoch 56/70\n",
      "11835/11835 [==============================] - 787s 67ms/step - loss: 2.1677 - sparse_categorical_accuracy: 0.3234 - sparse_top_k_categorical_accuracy: 0.5621 - val_loss: 1.6375 - val_sparse_categorical_accuracy: 0.5504 - val_sparse_top_k_categorical_accuracy: 0.8059 - lr: 3.0000e-04\n",
      "Epoch 57/70\n",
      "11835/11835 [==============================] - 783s 66ms/step - loss: 2.1666 - sparse_categorical_accuracy: 0.3241 - sparse_top_k_categorical_accuracy: 0.5623 - val_loss: 1.6211 - val_sparse_categorical_accuracy: 0.5539 - val_sparse_top_k_categorical_accuracy: 0.8109 - lr: 3.0000e-04\n",
      "Epoch 58/70\n",
      "11835/11835 [==============================] - 782s 66ms/step - loss: 2.1661 - sparse_categorical_accuracy: 0.3246 - sparse_top_k_categorical_accuracy: 0.5625 - val_loss: 1.6294 - val_sparse_categorical_accuracy: 0.5475 - val_sparse_top_k_categorical_accuracy: 0.8056 - lr: 3.0000e-04\n",
      "Epoch 59/70\n",
      "11835/11835 [==============================] - 795s 67ms/step - loss: 2.1654 - sparse_categorical_accuracy: 0.3251 - sparse_top_k_categorical_accuracy: 0.5629 - val_loss: 1.6434 - val_sparse_categorical_accuracy: 0.5492 - val_sparse_top_k_categorical_accuracy: 0.8032 - lr: 3.0000e-04\n",
      "Epoch 60/70\n",
      "11835/11835 [==============================] - 781s 66ms/step - loss: 2.1647 - sparse_categorical_accuracy: 0.3250 - sparse_top_k_categorical_accuracy: 0.5628 - val_loss: 1.6237 - val_sparse_categorical_accuracy: 0.5526 - val_sparse_top_k_categorical_accuracy: 0.8075 - lr: 3.0000e-04\n",
      "Epoch 61/70\n",
      "11835/11835 [==============================] - 755s 64ms/step - loss: 2.1641 - sparse_categorical_accuracy: 0.3257 - sparse_top_k_categorical_accuracy: 0.5630 - val_loss: 1.6203 - val_sparse_categorical_accuracy: 0.5518 - val_sparse_top_k_categorical_accuracy: 0.8077 - lr: 3.0000e-04\n",
      "Epoch 62/70\n",
      "11835/11835 [==============================] - 768s 65ms/step - loss: 2.1634 - sparse_categorical_accuracy: 0.3260 - sparse_top_k_categorical_accuracy: 0.5634 - val_loss: 1.6349 - val_sparse_categorical_accuracy: 0.5404 - val_sparse_top_k_categorical_accuracy: 0.8041 - lr: 3.0000e-04\n",
      "Epoch 63/70\n",
      "11835/11835 [==============================] - 757s 64ms/step - loss: 2.1627 - sparse_categorical_accuracy: 0.3264 - sparse_top_k_categorical_accuracy: 0.5636 - val_loss: 1.6170 - val_sparse_categorical_accuracy: 0.5529 - val_sparse_top_k_categorical_accuracy: 0.8094 - lr: 3.0000e-04\n",
      "Epoch 64/70\n",
      "11835/11835 [==============================] - 761s 64ms/step - loss: 2.1621 - sparse_categorical_accuracy: 0.3265 - sparse_top_k_categorical_accuracy: 0.5639 - val_loss: 1.6219 - val_sparse_categorical_accuracy: 0.5598 - val_sparse_top_k_categorical_accuracy: 0.8121 - lr: 3.0000e-04\n",
      "Epoch 65/70\n",
      "11835/11835 [==============================] - 786s 66ms/step - loss: 2.1616 - sparse_categorical_accuracy: 0.3271 - sparse_top_k_categorical_accuracy: 0.5644 - val_loss: 1.6352 - val_sparse_categorical_accuracy: 0.5499 - val_sparse_top_k_categorical_accuracy: 0.8063 - lr: 3.0000e-04\n",
      "Epoch 66/70\n",
      "11835/11835 [==============================] - 775s 65ms/step - loss: 2.1609 - sparse_categorical_accuracy: 0.3274 - sparse_top_k_categorical_accuracy: 0.5649 - val_loss: 1.6377 - val_sparse_categorical_accuracy: 0.5486 - val_sparse_top_k_categorical_accuracy: 0.8044 - lr: 3.0000e-04\n",
      "Epoch 67/70\n",
      "11835/11835 [==============================] - 748s 63ms/step - loss: 2.1603 - sparse_categorical_accuracy: 0.3275 - sparse_top_k_categorical_accuracy: 0.5645 - val_loss: 1.6350 - val_sparse_categorical_accuracy: 0.5566 - val_sparse_top_k_categorical_accuracy: 0.8077 - lr: 3.0000e-04\n",
      "Epoch 68/70\n",
      "11835/11835 [==============================] - 750s 63ms/step - loss: 2.1600 - sparse_categorical_accuracy: 0.3282 - sparse_top_k_categorical_accuracy: 0.5645 - val_loss: 1.6220 - val_sparse_categorical_accuracy: 0.5572 - val_sparse_top_k_categorical_accuracy: 0.8093 - lr: 3.0000e-04\n",
      "Epoch 69/70\n",
      "11835/11835 [==============================] - 758s 64ms/step - loss: 2.1487 - sparse_categorical_accuracy: 0.3346 - sparse_top_k_categorical_accuracy: 0.5691 - val_loss: 1.6023 - val_sparse_categorical_accuracy: 0.5636 - val_sparse_top_k_categorical_accuracy: 0.8115 - lr: 1.0000e-04\n",
      "Epoch 70/70\n",
      "11835/11835 [==============================] - 779s 66ms/step - loss: 2.1468 - sparse_categorical_accuracy: 0.3362 - sparse_top_k_categorical_accuracy: 0.5698 - val_loss: 1.5992 - val_sparse_categorical_accuracy: 0.5641 - val_sparse_top_k_categorical_accuracy: 0.8102 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# DO NOT RUN!!! This has template result to be matched\n",
    "\n",
    "# Define Sequential model with 3 layers\n",
    "num_epochs = 70\n",
    "batch_size = 64\n",
    "nodes = 256\n",
    "learning_rate = 0.003 #0.0001\n",
    "\n",
    "wandb.config = { \"learning_rate\": \"learning_rate\",   \"epochs\": num_epochs,\n",
    "  \"batch_size\": batch_size,  \"nodes\": nodes,  \"row_length\":row_length,  \"base_path\":base_path }\n",
    "\n",
    "input_shape = (21,5,1)\n",
    "\n",
    "def ResNetBlock(x,dropout):\n",
    "    conv1 = x\n",
    "    for _ in range(5):                \n",
    "        conv1 = layers.BatchNormalization()(conv1)\n",
    "        conv1 = layers.ReLU()(conv1)\n",
    "        conv1 = layers.SeparableConv2D(filters=64, kernel_size=3, padding=\"same\")(conv1) #input_layer\n",
    "        conv1 = layers.SeparableConv2D(filters=64, kernel_size=3, padding=\"same\")(conv1) # input_layer, Conv1D    \n",
    "        conv1 = layers.BatchNormalization()(conv1)\n",
    "        conv1 = layers.ReLU()(conv1)\n",
    "        conv1 = layers.Dropout(dropout)(conv1)\n",
    "    \n",
    "    res = layers.add([x,conv1])\n",
    "    x = layers.ReLU()(res) # Overwrite x    \n",
    "    return x\n",
    "\n",
    "def ResNetBlock2(x):\n",
    "    x =   layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(x) #input_layer\n",
    "    conv1 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(x) # input_layer, Conv1D\n",
    "    conv1 = layers.BatchNormalization()(conv1)\n",
    "    conv1 = layers.ReLU()(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "    conv2 = layers.BatchNormalization()(conv2)\n",
    "    conv2 = layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = layers.BatchNormalization()(conv3)\n",
    "    conv3 = layers.ReLU()(conv3)\n",
    "    \n",
    "    \n",
    "    conv3 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = layers.BatchNormalization()(conv3)\n",
    "    conv3 = layers.ReLU()(conv3)\n",
    "    \n",
    "    \n",
    "    conv3 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = layers.BatchNormalization()(conv3)\n",
    "    conv3 = layers.ReLU()(conv3)\n",
    "    \n",
    "    conv3 = layers.add([x,conv3])\n",
    "    x = layers.ReLU()(conv3) # Overwrite x\n",
    "    \n",
    "    return x\n",
    "\n",
    "def make_model(input_shape,dropout):\n",
    "    input_layer = layers.Input(input_shape)    \n",
    "    x =   layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(input_layer)    \n",
    "    \n",
    "    for _ in range(30):\n",
    "        x = ResNetBlock2(input_layer,dropout)\n",
    "    \n",
    "    # conv1 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(input_layer) #Conv1D\n",
    "    # conv1 = layers.BatchNormalization()(conv1)\n",
    "    # conv1 = layers.ReLU()(conv1)\n",
    "    # conv2 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "    # conv2 = layers.BatchNormalization()(conv2)\n",
    "    # conv2 = layers.ReLU()(conv2)\n",
    "    # conv3 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    # conv3 = layers.BatchNormalization()(conv3)\n",
    "    # conv3 = layers.ReLU()(conv3)\n",
    "    \n",
    "    gap = layers.GlobalAveragePooling2D()(x)    \n",
    "    gap = layers.Flatten()(gap)\n",
    "    gap = layers.Dropout(0)(gap)\n",
    "    gap = layers.Dense(128, activation=\"softmax\")(gap)\n",
    "    output_layer = layers.Dense(num_classes, activation=\"softmax\")(gap)\n",
    "\n",
    "    return tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model = make_model(input_shape = input_shape,dropout = 0) #x_train.shape[1:]\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(base_path+'/'+ipynbname.name()+\"/best_model.h5\", save_best_only=True, monitor=\"val_loss\"),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, patience=5, min_lr=0.0001),\n",
    "    #EarlyStopping(monitor=\"val_loss\", patience=25, verbose=1), \n",
    "    WandbCallback()\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Poly Rate scheduler ( This kept having issues)\n",
    "starter_learning_rate = 0.01\n",
    "end_learning_rate = 0.0001\n",
    "decay_steps = 10000\n",
    "learning_rate_fn = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    starter_learning_rate,\n",
    "    decay_steps,\n",
    "    end_learning_rate,\n",
    "    power=0.25)\n",
    "\n",
    "\n",
    "opt1 = tf.keras.optimizers.RMSprop(learning_rate=learning_rate,rho=0.9,momentum=0.9, epsilon=1e-07,centered=True,name=\"RMSprop\")\n",
    "opt2 = tf.keras.optimizers.Adam(learning_rate=learning_rate,amsgrad=True)\n",
    "poly_rate = tf.keras.optimizers.SGD(learning_rate = learning_rate_fn) # All the schedulers gives errors\n",
    "poly_rate2 = tf.keras.optimizers.Adam(learning_rate = learning_rate_fn)\n",
    "# top_K = 3\n",
    "# model.compile( optimizer = opt, loss= 'categorical_crossentropy', metrics=['accuracy',tf.keras.metrics.TopKCategoricalAccuracy(top_K, name=\"top-3-accuracy\")])  #label_smoothing=0.05, tf.keras.losses.KLDivergence()\n",
    "\n",
    "model.compile( optimizer=opt2,loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\",tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3)] )\n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "          epochs= num_epochs, \n",
    "          batch_size= batch_size, \n",
    "          validation_data=(x_test, y_test),\n",
    "         callbacks=callbacks) #mcp_save, callbacks=[reduce_lr_loss]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "075f2d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1480/1480 [==============================] - 30s 20ms/step - loss: 1.4855 - sparse_categorical_accuracy: 0.5992 - sparse_top_k_categorical_accuracy: 0.8544\n",
      "Test accuracy: 59.92%\n",
      "Test top 5 accuracy: 85.44%\n"
     ]
    }
   ],
   "source": [
    "_, accuracy,top_3_accuracy = model.evaluate(x_val, y_val)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "print(f\"Test top 5 accuracy: {round(top_3_accuracy * 100, 2)}%\")\n",
    "\n",
    "\n",
    "model.save(f'{base_path}//NewResNet_weights_3ConvBlocks//{time_stamp}_Acc_{accuracy:.3f}_{row_length}x{col_length}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf7a56a3-e26b-4d09-a6b3-59ff631b929e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start time:05_January_22_1140\n",
      "Epoch 1/70\n",
      "    6/14828 [..............................] - ETA: 4:43:18 - loss: nan - sparse_categorical_accuracy: 0.1094 - sparse_top_k_categorical_accuracy: 0.1771WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1039s vs `on_train_batch_end` time: 0.8821s). Check your callbacks.\n",
      " 9783/14828 [==================>...........] - ETA: 36:45 - loss: nan - sparse_categorical_accuracy: 0.0831 - sparse_top_k_categorical_accuracy: 1.0861e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3660/3098453029.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m history = model.fit(x_train, y_train,\n\u001b[0m\u001b[0;32m    135\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ibk_tf_new\\lib\\site-packages\\wandb\\integration\\keras\\keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ibk_tf_new\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ibk_tf_new\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1221\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1222\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ibk_tf_new\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    434\u001b[0m     \"\"\"\n\u001b[0;32m    435\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ibk_tf_new\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m       raise ValueError(\n",
      "\u001b[1;32m~\\.conda\\envs\\ibk_tf_new\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ibk_tf_new\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m       \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ibk_tf_new\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ibk_tf_new\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ibk_tf_new\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ibk_tf_new\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ibk_tf_new\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ibk_tf_new\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    548\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ibk_tf_new\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \"\"\"\n\u001b[0;32m   1148\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ibk_tf_new\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1113\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Same code as the training cell above is repeated to use the previous output as reference\n",
    "num_epochs = 70\n",
    "batch_size = 128 #128, 256\n",
    "nodes = 256\n",
    "learning_rate = 3e-2 #0.0001\n",
    "dropout = 0.2\n",
    "\n",
    "wandb.config = { \"learning_rate\": \"learning_rate\",   \"epochs\": num_epochs,\n",
    "  \"batch_size\": batch_size,  \"nodes\": nodes,  \"row_length\":row_length,  \"base_path\":base_path }\n",
    "wandb.config.update(log)\n",
    "\n",
    "# Update log['extras']\n",
    "log['extras'] = wandb.config\n",
    "#### ===== End of logging ========\n",
    "\n",
    "input_shape = (21,5,1)\n",
    "\n",
    "def ResNetBlock(x,dropout):\n",
    "    conv1 = x\n",
    "    for _ in range(5):                \n",
    "        conv1 = layers.BatchNormalization()(conv1)\n",
    "        conv1 = layers.ReLU()(conv1)\n",
    "        conv1 = layers.SeparableConv2D(filters=64, kernel_size=3, padding=\"same\")(conv1) #input_layer\n",
    "        conv1 = layers.SeparableConv2D(filters=64, kernel_size=3, padding=\"same\")(conv1) # input_layer, Conv1D    \n",
    "        conv1 = layers.BatchNormalization()(conv1)\n",
    "        conv1 = layers.ReLU()(conv1)\n",
    "        conv1 = layers.Dropout(dropout)(conv1)\n",
    "    \n",
    "    res = layers.add([x,conv1])\n",
    "    x = layers.ReLU()(res) # Overwrite x    \n",
    "    return x\n",
    "\n",
    "def ResNetBlock2(x):\n",
    "    num_filters = 128\n",
    "    k_size = 3 #(21,3)\n",
    "    \n",
    "    x =   layers.Conv2D(filters=num_filters, kernel_size=k_size, padding=\"same\")(x) #input_layer\n",
    "    conv1 = layers.Conv2D(filters=num_filters, kernel_size=k_size, padding=\"same\")(x) # input_layer, Conv1D\n",
    "    conv1 = layers.BatchNormalization()(conv1)\n",
    "    conv1 = layers.ReLU()(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(filters=num_filters, kernel_size=k_size, padding=\"same\")(conv1)\n",
    "    conv2 = layers.BatchNormalization()(conv2)\n",
    "    conv2 = layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = layers.Conv2D(filters=num_filters, kernel_size=k_size, padding=\"same\")(conv2)\n",
    "    conv3 = layers.BatchNormalization()(conv3)\n",
    "    conv3 = layers.ReLU()(conv3)\n",
    "    \n",
    "    \n",
    "    conv3 = layers.Conv2D(filters=num_filters, kernel_size=k_size, padding=\"same\")(conv2)\n",
    "    conv3 = layers.BatchNormalization()(conv3)\n",
    "    conv3 = layers.ReLU()(conv3)\n",
    "    \n",
    "    \n",
    "    conv3 = layers.Conv2D(filters=num_filters, kernel_size=k_size, padding=\"same\")(conv2)\n",
    "    conv3 = layers.BatchNormalization()(conv3)\n",
    "    conv3 = layers.ReLU()(conv3)\n",
    "    \n",
    "    conv3 = layers.add([x,conv3])\n",
    "    x = layers.ReLU()(conv3) # Overwrite x\n",
    "    \n",
    "    return x\n",
    "\n",
    "def make_model(input_shape,dropout):\n",
    "    input_layer = layers.Input(input_shape)    \n",
    "    x =  layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(input_layer)    \n",
    "    \n",
    "    for _ in range(30):\n",
    "        x = ResNetBlock2(x) #input_layer,dropout\n",
    "    \n",
    "    # conv1 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(input_layer) #Conv1D\n",
    "    # conv1 = layers.BatchNormalization()(conv1)\n",
    "    # conv1 = layers.ReLU()(conv1)\n",
    "    # conv2 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "    # conv2 = layers.BatchNormalization()(conv2)\n",
    "    # conv2 = layers.ReLU()(conv2)\n",
    "    # conv3 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    # conv3 = layers.BatchNormalization()(conv3)\n",
    "    # conv3 = layers.ReLU()(conv3)\n",
    "    \n",
    "    gap = layers.GlobalAveragePooling2D()(x)    \n",
    "    gap = layers.Flatten()(gap)\n",
    "    gap = layers.Dense(256, activation=\"softmax\")(gap)\n",
    "    gap = layers.Dropout(dropout)(gap)    \n",
    "    output_layer = layers.Dense(num_classes, activation=\"softmax\")(gap)\n",
    "\n",
    "    return tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model = make_model(input_shape = input_shape,dropout = dropout) #x_train.shape[1:]\n",
    "\n",
    "try:\n",
    "    Nb_name = ipynbname.name()\n",
    "except:\n",
    "    Nb_name =\"Conv3Blocks\"\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(base_path+'/'+Nb_name+\"/best_model.h5\", save_best_only=True, monitor=\"val_loss\"),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, min_lr=0.0001,verbose = 1),\n",
    "    #EarlyStopping(monitor=\"val_loss\", patience=25, verbose=1), \n",
    "    WandbCallback()\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Poly Rate scheduler ( This kept having issues)\n",
    "starter_learning_rate = 0.01\n",
    "end_learning_rate = 0.0001\n",
    "decay_steps = 10000\n",
    "learning_rate_fn = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    starter_learning_rate,\n",
    "    decay_steps,\n",
    "    end_learning_rate,\n",
    "    power=0.25)\n",
    "\n",
    "\n",
    "opt1 = tf.keras.optimizers.RMSprop(learning_rate=learning_rate,rho=0.9,momentum=0.9, epsilon=1e-07,centered=True,name=\"RMSprop\")\n",
    "opt2 = tf.keras.optimizers.Adam(learning_rate=learning_rate,amsgrad=True)\n",
    "\n",
    "weight_decay = 0.005 #0.3\n",
    "opt3 = tfa.optimizers.AdamW(learning_rate=learning_rate, weight_decay=weight_decay) #Adam(amsgrad=True)\n",
    "\n",
    "poly_rate = tf.keras.optimizers.SGD(learning_rate = learning_rate_fn) # All the schedulers gives errors\n",
    "poly_rate2 = tf.keras.optimizers.Adam(learning_rate = learning_rate_fn)\n",
    "# top_K = 3\n",
    "# model.compile( optimizer = opt, loss= 'categorical_crossentropy', metrics=['accuracy',tf.keras.metrics.TopKCategoricalAccuracy(top_K, name=\"top-3-accuracy\")])  #label_smoothing=0.05, tf.keras.losses.KLDivergence()\n",
    "\n",
    "start_time = datetime.strftime( datetime.now(),'%d_%B_%y_%H%M')\n",
    "print(f'Training start time:{start_time}')\n",
    "\n",
    "model.compile( optimizer=opt3,loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\",tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3)] )\n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "          epochs= num_epochs, \n",
    "          batch_size= batch_size, \n",
    "          validation_data=(x_test, y_test),\n",
    "         callbacks=callbacks) #mcp_save, callbacks=[reduce_lr_loss]\n",
    "\n",
    "# Update manual log file\n",
    "params_to_be_updated = update_log_entry('../testing_sheet2.xlsx', log['S_N'], model, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8559ef79-1ff1-4b52-a0d6-0b1f0d211825",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.2138 - sparse_categorical_accuracy: 0.2859 - sparse_top_k_categorical_accuracy: 0.5417 - val_loss: 1.7609 - val_sparse_categorical_accuracy: 0.5028 - val_sparse_top_k_categorical_accuracy: 0.8081 - lr: 0.0030\n",
      "Epoch 2/100\n",
      "11835/11835 [==============================] - 78s 7ms/step - loss: 2.2082 - sparse_categorical_accuracy: 0.2891 - sparse_top_k_categorical_accuracy: 0.5436 - val_loss: 1.7331 - val_sparse_categorical_accuracy: 0.4917 - val_sparse_top_k_categorical_accuracy: 0.8001 - lr: 0.0030\n",
      "Epoch 3/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.2039 - sparse_categorical_accuracy: 0.2911 - sparse_top_k_categorical_accuracy: 0.5453 - val_loss: 1.6962 - val_sparse_categorical_accuracy: 0.5184 - val_sparse_top_k_categorical_accuracy: 0.8152 - lr: 0.0030\n",
      "Epoch 4/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.2006 - sparse_categorical_accuracy: 0.2926 - sparse_top_k_categorical_accuracy: 0.5462 - val_loss: 1.7257 - val_sparse_categorical_accuracy: 0.5007 - val_sparse_top_k_categorical_accuracy: 0.8037 - lr: 0.0030\n",
      "Epoch 5/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1977 - sparse_categorical_accuracy: 0.2937 - sparse_top_k_categorical_accuracy: 0.5468 - val_loss: 1.7691 - val_sparse_categorical_accuracy: 0.4996 - val_sparse_top_k_categorical_accuracy: 0.8064 - lr: 0.0030\n",
      "Epoch 6/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1951 - sparse_categorical_accuracy: 0.2949 - sparse_top_k_categorical_accuracy: 0.5480 - val_loss: 1.6598 - val_sparse_categorical_accuracy: 0.5212 - val_sparse_top_k_categorical_accuracy: 0.8189 - lr: 0.0030\n",
      "Epoch 7/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1927 - sparse_categorical_accuracy: 0.2967 - sparse_top_k_categorical_accuracy: 0.5484 - val_loss: 1.6519 - val_sparse_categorical_accuracy: 0.5281 - val_sparse_top_k_categorical_accuracy: 0.8226 - lr: 0.0030\n",
      "Epoch 8/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1908 - sparse_categorical_accuracy: 0.2975 - sparse_top_k_categorical_accuracy: 0.5496 - val_loss: 1.7699 - val_sparse_categorical_accuracy: 0.4938 - val_sparse_top_k_categorical_accuracy: 0.8009 - lr: 0.0030\n",
      "Epoch 9/100\n",
      "11835/11835 [==============================] - 78s 7ms/step - loss: 2.1889 - sparse_categorical_accuracy: 0.2984 - sparse_top_k_categorical_accuracy: 0.5501 - val_loss: 1.6535 - val_sparse_categorical_accuracy: 0.5276 - val_sparse_top_k_categorical_accuracy: 0.8174 - lr: 0.0030\n",
      "Epoch 10/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1874 - sparse_categorical_accuracy: 0.2999 - sparse_top_k_categorical_accuracy: 0.5506 - val_loss: 1.6416 - val_sparse_categorical_accuracy: 0.5293 - val_sparse_top_k_categorical_accuracy: 0.8224 - lr: 0.0030\n",
      "Epoch 11/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1859 - sparse_categorical_accuracy: 0.3007 - sparse_top_k_categorical_accuracy: 0.5512 - val_loss: 1.6675 - val_sparse_categorical_accuracy: 0.5272 - val_sparse_top_k_categorical_accuracy: 0.8165 - lr: 0.0030\n",
      "Epoch 12/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1843 - sparse_categorical_accuracy: 0.3014 - sparse_top_k_categorical_accuracy: 0.5517 - val_loss: 1.7051 - val_sparse_categorical_accuracy: 0.5162 - val_sparse_top_k_categorical_accuracy: 0.8123 - lr: 0.0030\n",
      "Epoch 13/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1829 - sparse_categorical_accuracy: 0.3024 - sparse_top_k_categorical_accuracy: 0.5519 - val_loss: 1.6869 - val_sparse_categorical_accuracy: 0.5221 - val_sparse_top_k_categorical_accuracy: 0.8171 - lr: 0.0030\n",
      "Epoch 14/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1814 - sparse_categorical_accuracy: 0.3032 - sparse_top_k_categorical_accuracy: 0.5522 - val_loss: 1.6152 - val_sparse_categorical_accuracy: 0.5443 - val_sparse_top_k_categorical_accuracy: 0.8267 - lr: 0.0030\n",
      "Epoch 15/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1806 - sparse_categorical_accuracy: 0.3033 - sparse_top_k_categorical_accuracy: 0.5523 - val_loss: 1.7038 - val_sparse_categorical_accuracy: 0.5123 - val_sparse_top_k_categorical_accuracy: 0.8161 - lr: 0.0030\n",
      "Epoch 16/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1790 - sparse_categorical_accuracy: 0.3046 - sparse_top_k_categorical_accuracy: 0.5536 - val_loss: 1.6538 - val_sparse_categorical_accuracy: 0.5332 - val_sparse_top_k_categorical_accuracy: 0.8166 - lr: 0.0030\n",
      "Epoch 17/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1784 - sparse_categorical_accuracy: 0.3046 - sparse_top_k_categorical_accuracy: 0.5533 - val_loss: 1.6419 - val_sparse_categorical_accuracy: 0.5418 - val_sparse_top_k_categorical_accuracy: 0.8273 - lr: 0.0030\n",
      "Epoch 18/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1769 - sparse_categorical_accuracy: 0.3060 - sparse_top_k_categorical_accuracy: 0.5535 - val_loss: 1.5993 - val_sparse_categorical_accuracy: 0.5405 - val_sparse_top_k_categorical_accuracy: 0.8246 - lr: 0.0030\n",
      "Epoch 19/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1761 - sparse_categorical_accuracy: 0.3062 - sparse_top_k_categorical_accuracy: 0.5544 - val_loss: 1.5970 - val_sparse_categorical_accuracy: 0.5451 - val_sparse_top_k_categorical_accuracy: 0.8288 - lr: 0.0030\n",
      "Epoch 20/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1753 - sparse_categorical_accuracy: 0.3066 - sparse_top_k_categorical_accuracy: 0.5544 - val_loss: 1.7053 - val_sparse_categorical_accuracy: 0.5313 - val_sparse_top_k_categorical_accuracy: 0.8195 - lr: 0.0030\n",
      "Epoch 21/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1743 - sparse_categorical_accuracy: 0.3077 - sparse_top_k_categorical_accuracy: 0.5548 - val_loss: 1.6307 - val_sparse_categorical_accuracy: 0.5458 - val_sparse_top_k_categorical_accuracy: 0.8295 - lr: 0.0030\n",
      "Epoch 22/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1733 - sparse_categorical_accuracy: 0.3075 - sparse_top_k_categorical_accuracy: 0.5554 - val_loss: 1.6087 - val_sparse_categorical_accuracy: 0.5438 - val_sparse_top_k_categorical_accuracy: 0.8270 - lr: 0.0030\n",
      "Epoch 23/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1726 - sparse_categorical_accuracy: 0.3085 - sparse_top_k_categorical_accuracy: 0.5551 - val_loss: 1.6649 - val_sparse_categorical_accuracy: 0.5434 - val_sparse_top_k_categorical_accuracy: 0.8248 - lr: 0.0030\n",
      "Epoch 24/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1717 - sparse_categorical_accuracy: 0.3090 - sparse_top_k_categorical_accuracy: 0.5556 - val_loss: 1.5818 - val_sparse_categorical_accuracy: 0.5444 - val_sparse_top_k_categorical_accuracy: 0.8275 - lr: 0.0030\n",
      "Epoch 25/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1710 - sparse_categorical_accuracy: 0.3090 - sparse_top_k_categorical_accuracy: 0.5557 - val_loss: 1.6359 - val_sparse_categorical_accuracy: 0.5385 - val_sparse_top_k_categorical_accuracy: 0.8251 - lr: 0.0030\n",
      "Epoch 26/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1698 - sparse_categorical_accuracy: 0.3103 - sparse_top_k_categorical_accuracy: 0.5562 - val_loss: 1.6400 - val_sparse_categorical_accuracy: 0.5356 - val_sparse_top_k_categorical_accuracy: 0.8209 - lr: 0.0030\n",
      "Epoch 27/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1694 - sparse_categorical_accuracy: 0.3102 - sparse_top_k_categorical_accuracy: 0.5558 - val_loss: 1.6464 - val_sparse_categorical_accuracy: 0.5342 - val_sparse_top_k_categorical_accuracy: 0.8225 - lr: 0.0030\n",
      "Epoch 28/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1687 - sparse_categorical_accuracy: 0.3110 - sparse_top_k_categorical_accuracy: 0.5564 - val_loss: 1.6499 - val_sparse_categorical_accuracy: 0.5429 - val_sparse_top_k_categorical_accuracy: 0.8258 - lr: 0.0030\n",
      "Epoch 29/100\n",
      "11835/11835 [==============================] - 78s 7ms/step - loss: 2.1678 - sparse_categorical_accuracy: 0.3117 - sparse_top_k_categorical_accuracy: 0.5570 - val_loss: 1.6142 - val_sparse_categorical_accuracy: 0.5534 - val_sparse_top_k_categorical_accuracy: 0.8286 - lr: 0.0030\n",
      "Epoch 30/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1598 - sparse_categorical_accuracy: 0.3166 - sparse_top_k_categorical_accuracy: 0.5594 - val_loss: 1.5607 - val_sparse_categorical_accuracy: 0.5642 - val_sparse_top_k_categorical_accuracy: 0.8347 - lr: 7.5000e-04\n",
      "Epoch 31/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1584 - sparse_categorical_accuracy: 0.3170 - sparse_top_k_categorical_accuracy: 0.5599 - val_loss: 1.5584 - val_sparse_categorical_accuracy: 0.5679 - val_sparse_top_k_categorical_accuracy: 0.8346 - lr: 7.5000e-04\n",
      "Epoch 32/100\n",
      "11835/11835 [==============================] - 78s 7ms/step - loss: 2.1577 - sparse_categorical_accuracy: 0.3179 - sparse_top_k_categorical_accuracy: 0.5599 - val_loss: 1.5824 - val_sparse_categorical_accuracy: 0.5638 - val_sparse_top_k_categorical_accuracy: 0.8338 - lr: 7.5000e-04\n",
      "Epoch 33/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1571 - sparse_categorical_accuracy: 0.3180 - sparse_top_k_categorical_accuracy: 0.5602 - val_loss: 1.5781 - val_sparse_categorical_accuracy: 0.5652 - val_sparse_top_k_categorical_accuracy: 0.8331 - lr: 7.5000e-04\n",
      "Epoch 34/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1567 - sparse_categorical_accuracy: 0.3185 - sparse_top_k_categorical_accuracy: 0.5603 - val_loss: 1.5605 - val_sparse_categorical_accuracy: 0.5665 - val_sparse_top_k_categorical_accuracy: 0.8343 - lr: 7.5000e-04\n",
      "Epoch 35/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1566 - sparse_categorical_accuracy: 0.3182 - sparse_top_k_categorical_accuracy: 0.5607 - val_loss: 1.5837 - val_sparse_categorical_accuracy: 0.5662 - val_sparse_top_k_categorical_accuracy: 0.8333 - lr: 7.5000e-04\n",
      "Epoch 36/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1557 - sparse_categorical_accuracy: 0.3193 - sparse_top_k_categorical_accuracy: 0.5606 - val_loss: 1.5657 - val_sparse_categorical_accuracy: 0.5647 - val_sparse_top_k_categorical_accuracy: 0.8334 - lr: 7.5000e-04\n",
      "Epoch 37/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1532 - sparse_categorical_accuracy: 0.3206 - sparse_top_k_categorical_accuracy: 0.5615 - val_loss: 1.5543 - val_sparse_categorical_accuracy: 0.5723 - val_sparse_top_k_categorical_accuracy: 0.8360 - lr: 1.8750e-04\n",
      "Epoch 38/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1526 - sparse_categorical_accuracy: 0.3211 - sparse_top_k_categorical_accuracy: 0.5615 - val_loss: 1.5560 - val_sparse_categorical_accuracy: 0.5726 - val_sparse_top_k_categorical_accuracy: 0.8365 - lr: 1.8750e-04\n",
      "Epoch 39/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1524 - sparse_categorical_accuracy: 0.3213 - sparse_top_k_categorical_accuracy: 0.5619 - val_loss: 1.5639 - val_sparse_categorical_accuracy: 0.5716 - val_sparse_top_k_categorical_accuracy: 0.8355 - lr: 1.8750e-04\n",
      "Epoch 40/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1519 - sparse_categorical_accuracy: 0.3218 - sparse_top_k_categorical_accuracy: 0.5615 - val_loss: 1.5610 - val_sparse_categorical_accuracy: 0.5726 - val_sparse_top_k_categorical_accuracy: 0.8356 - lr: 1.8750e-04\n",
      "Epoch 41/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1521 - sparse_categorical_accuracy: 0.3216 - sparse_top_k_categorical_accuracy: 0.5616 - val_loss: 1.5600 - val_sparse_categorical_accuracy: 0.5728 - val_sparse_top_k_categorical_accuracy: 0.8357 - lr: 1.8750e-04\n",
      "Epoch 42/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1518 - sparse_categorical_accuracy: 0.3216 - sparse_top_k_categorical_accuracy: 0.5620 - val_loss: 1.5553 - val_sparse_categorical_accuracy: 0.5727 - val_sparse_top_k_categorical_accuracy: 0.8366 - lr: 1.8750e-04\n",
      "Epoch 43/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1514 - sparse_categorical_accuracy: 0.3214 - sparse_top_k_categorical_accuracy: 0.5621 - val_loss: 1.5576 - val_sparse_categorical_accuracy: 0.5734 - val_sparse_top_k_categorical_accuracy: 0.8358 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1513 - sparse_categorical_accuracy: 0.3219 - sparse_top_k_categorical_accuracy: 0.5621 - val_loss: 1.5566 - val_sparse_categorical_accuracy: 0.5737 - val_sparse_top_k_categorical_accuracy: 0.8364 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1511 - sparse_categorical_accuracy: 0.3223 - sparse_top_k_categorical_accuracy: 0.5624 - val_loss: 1.5506 - val_sparse_categorical_accuracy: 0.5735 - val_sparse_top_k_categorical_accuracy: 0.8359 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1509 - sparse_categorical_accuracy: 0.3220 - sparse_top_k_categorical_accuracy: 0.5621 - val_loss: 1.5524 - val_sparse_categorical_accuracy: 0.5732 - val_sparse_top_k_categorical_accuracy: 0.8365 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1509 - sparse_categorical_accuracy: 0.3222 - sparse_top_k_categorical_accuracy: 0.5616 - val_loss: 1.5532 - val_sparse_categorical_accuracy: 0.5741 - val_sparse_top_k_categorical_accuracy: 0.8362 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1509 - sparse_categorical_accuracy: 0.3223 - sparse_top_k_categorical_accuracy: 0.5621 - val_loss: 1.5549 - val_sparse_categorical_accuracy: 0.5737 - val_sparse_top_k_categorical_accuracy: 0.8363 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1512 - sparse_categorical_accuracy: 0.3222 - sparse_top_k_categorical_accuracy: 0.5621 - val_loss: 1.5552 - val_sparse_categorical_accuracy: 0.5737 - val_sparse_top_k_categorical_accuracy: 0.8360 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1510 - sparse_categorical_accuracy: 0.3219 - sparse_top_k_categorical_accuracy: 0.5621 - val_loss: 1.5563 - val_sparse_categorical_accuracy: 0.5744 - val_sparse_top_k_categorical_accuracy: 0.8362 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1506 - sparse_categorical_accuracy: 0.3221 - sparse_top_k_categorical_accuracy: 0.5625 - val_loss: 1.5522 - val_sparse_categorical_accuracy: 0.5739 - val_sparse_top_k_categorical_accuracy: 0.8363 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1509 - sparse_categorical_accuracy: 0.3220 - sparse_top_k_categorical_accuracy: 0.5620 - val_loss: 1.5544 - val_sparse_categorical_accuracy: 0.5744 - val_sparse_top_k_categorical_accuracy: 0.8362 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1505 - sparse_categorical_accuracy: 0.3226 - sparse_top_k_categorical_accuracy: 0.5625 - val_loss: 1.5471 - val_sparse_categorical_accuracy: 0.5744 - val_sparse_top_k_categorical_accuracy: 0.8367 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1506 - sparse_categorical_accuracy: 0.3224 - sparse_top_k_categorical_accuracy: 0.5625 - val_loss: 1.5515 - val_sparse_categorical_accuracy: 0.5735 - val_sparse_top_k_categorical_accuracy: 0.8361 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "11835/11835 [==============================] - 81s 7ms/step - loss: 2.1506 - sparse_categorical_accuracy: 0.3225 - sparse_top_k_categorical_accuracy: 0.5626 - val_loss: 1.5538 - val_sparse_categorical_accuracy: 0.5745 - val_sparse_top_k_categorical_accuracy: 0.8368 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1504 - sparse_categorical_accuracy: 0.3223 - sparse_top_k_categorical_accuracy: 0.5624 - val_loss: 1.5504 - val_sparse_categorical_accuracy: 0.5749 - val_sparse_top_k_categorical_accuracy: 0.8367 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1503 - sparse_categorical_accuracy: 0.3226 - sparse_top_k_categorical_accuracy: 0.5619 - val_loss: 1.5503 - val_sparse_categorical_accuracy: 0.5744 - val_sparse_top_k_categorical_accuracy: 0.8363 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1504 - sparse_categorical_accuracy: 0.3222 - sparse_top_k_categorical_accuracy: 0.5621 - val_loss: 1.5556 - val_sparse_categorical_accuracy: 0.5740 - val_sparse_top_k_categorical_accuracy: 0.8358 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1502 - sparse_categorical_accuracy: 0.3226 - sparse_top_k_categorical_accuracy: 0.5625 - val_loss: 1.5549 - val_sparse_categorical_accuracy: 0.5736 - val_sparse_top_k_categorical_accuracy: 0.8359 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1500 - sparse_categorical_accuracy: 0.3228 - sparse_top_k_categorical_accuracy: 0.5625 - val_loss: 1.5540 - val_sparse_categorical_accuracy: 0.5746 - val_sparse_top_k_categorical_accuracy: 0.8364 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1505 - sparse_categorical_accuracy: 0.3224 - sparse_top_k_categorical_accuracy: 0.5620 - val_loss: 1.5549 - val_sparse_categorical_accuracy: 0.5743 - val_sparse_top_k_categorical_accuracy: 0.8363 - lr: 1.0000e-04\n",
      "Epoch 62/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1499 - sparse_categorical_accuracy: 0.3229 - sparse_top_k_categorical_accuracy: 0.5627 - val_loss: 1.5560 - val_sparse_categorical_accuracy: 0.5749 - val_sparse_top_k_categorical_accuracy: 0.8364 - lr: 1.0000e-04\n",
      "Epoch 63/100\n",
      "11835/11835 [==============================] - 81s 7ms/step - loss: 2.1500 - sparse_categorical_accuracy: 0.3234 - sparse_top_k_categorical_accuracy: 0.5626 - val_loss: 1.5467 - val_sparse_categorical_accuracy: 0.5761 - val_sparse_top_k_categorical_accuracy: 0.8369 - lr: 1.0000e-04\n",
      "Epoch 64/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1502 - sparse_categorical_accuracy: 0.3227 - sparse_top_k_categorical_accuracy: 0.5621 - val_loss: 1.5516 - val_sparse_categorical_accuracy: 0.5746 - val_sparse_top_k_categorical_accuracy: 0.8358 - lr: 1.0000e-04\n",
      "Epoch 65/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1499 - sparse_categorical_accuracy: 0.3225 - sparse_top_k_categorical_accuracy: 0.5627 - val_loss: 1.5524 - val_sparse_categorical_accuracy: 0.5745 - val_sparse_top_k_categorical_accuracy: 0.8361 - lr: 1.0000e-04\n",
      "Epoch 66/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1499 - sparse_categorical_accuracy: 0.3233 - sparse_top_k_categorical_accuracy: 0.5625 - val_loss: 1.5551 - val_sparse_categorical_accuracy: 0.5748 - val_sparse_top_k_categorical_accuracy: 0.8360 - lr: 1.0000e-04\n",
      "Epoch 67/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1498 - sparse_categorical_accuracy: 0.3228 - sparse_top_k_categorical_accuracy: 0.5626 - val_loss: 1.5545 - val_sparse_categorical_accuracy: 0.5748 - val_sparse_top_k_categorical_accuracy: 0.8362 - lr: 1.0000e-04\n",
      "Epoch 68/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1493 - sparse_categorical_accuracy: 0.3229 - sparse_top_k_categorical_accuracy: 0.5628 - val_loss: 1.5459 - val_sparse_categorical_accuracy: 0.5747 - val_sparse_top_k_categorical_accuracy: 0.8363 - lr: 1.0000e-04\n",
      "Epoch 69/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1494 - sparse_categorical_accuracy: 0.3229 - sparse_top_k_categorical_accuracy: 0.5625 - val_loss: 1.5510 - val_sparse_categorical_accuracy: 0.5755 - val_sparse_top_k_categorical_accuracy: 0.8365 - lr: 1.0000e-04\n",
      "Epoch 70/100\n",
      "11835/11835 [==============================] - 79s 7ms/step - loss: 2.1496 - sparse_categorical_accuracy: 0.3228 - sparse_top_k_categorical_accuracy: 0.5626 - val_loss: 1.5472 - val_sparse_categorical_accuracy: 0.5755 - val_sparse_top_k_categorical_accuracy: 0.8365 - lr: 1.0000e-04\n",
      "Epoch 71/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1495 - sparse_categorical_accuracy: 0.3234 - sparse_top_k_categorical_accuracy: 0.5622 - val_loss: 1.5504 - val_sparse_categorical_accuracy: 0.5749 - val_sparse_top_k_categorical_accuracy: 0.8362 - lr: 1.0000e-04\n",
      "Epoch 72/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1492 - sparse_categorical_accuracy: 0.3232 - sparse_top_k_categorical_accuracy: 0.5627 - val_loss: 1.5561 - val_sparse_categorical_accuracy: 0.5738 - val_sparse_top_k_categorical_accuracy: 0.8355 - lr: 1.0000e-04\n",
      "Epoch 73/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1493 - sparse_categorical_accuracy: 0.3231 - sparse_top_k_categorical_accuracy: 0.5621 - val_loss: 1.5529 - val_sparse_categorical_accuracy: 0.5756 - val_sparse_top_k_categorical_accuracy: 0.8360 - lr: 1.0000e-04\n",
      "Epoch 74/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1493 - sparse_categorical_accuracy: 0.3234 - sparse_top_k_categorical_accuracy: 0.5626 - val_loss: 1.5518 - val_sparse_categorical_accuracy: 0.5752 - val_sparse_top_k_categorical_accuracy: 0.8360 - lr: 1.0000e-04\n",
      "Epoch 75/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1488 - sparse_categorical_accuracy: 0.3237 - sparse_top_k_categorical_accuracy: 0.5627 - val_loss: 1.5480 - val_sparse_categorical_accuracy: 0.5757 - val_sparse_top_k_categorical_accuracy: 0.8368 - lr: 1.0000e-04\n",
      "Epoch 76/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1490 - sparse_categorical_accuracy: 0.3234 - sparse_top_k_categorical_accuracy: 0.5627 - val_loss: 1.5509 - val_sparse_categorical_accuracy: 0.5756 - val_sparse_top_k_categorical_accuracy: 0.8361 - lr: 1.0000e-04\n",
      "Epoch 77/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1488 - sparse_categorical_accuracy: 0.3236 - sparse_top_k_categorical_accuracy: 0.5630 - val_loss: 1.5529 - val_sparse_categorical_accuracy: 0.5754 - val_sparse_top_k_categorical_accuracy: 0.8358 - lr: 1.0000e-04\n",
      "Epoch 78/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1492 - sparse_categorical_accuracy: 0.3233 - sparse_top_k_categorical_accuracy: 0.5625 - val_loss: 1.5507 - val_sparse_categorical_accuracy: 0.5756 - val_sparse_top_k_categorical_accuracy: 0.8368 - lr: 1.0000e-04\n",
      "Epoch 79/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1492 - sparse_categorical_accuracy: 0.3233 - sparse_top_k_categorical_accuracy: 0.5627 - val_loss: 1.5522 - val_sparse_categorical_accuracy: 0.5759 - val_sparse_top_k_categorical_accuracy: 0.8367 - lr: 1.0000e-04\n",
      "Epoch 80/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1487 - sparse_categorical_accuracy: 0.3237 - sparse_top_k_categorical_accuracy: 0.5628 - val_loss: 1.5505 - val_sparse_categorical_accuracy: 0.5752 - val_sparse_top_k_categorical_accuracy: 0.8363 - lr: 1.0000e-04\n",
      "Epoch 81/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1487 - sparse_categorical_accuracy: 0.3236 - sparse_top_k_categorical_accuracy: 0.5630 - val_loss: 1.5510 - val_sparse_categorical_accuracy: 0.5753 - val_sparse_top_k_categorical_accuracy: 0.8362 - lr: 1.0000e-04\n",
      "Epoch 82/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1488 - sparse_categorical_accuracy: 0.3233 - sparse_top_k_categorical_accuracy: 0.5623 - val_loss: 1.5470 - val_sparse_categorical_accuracy: 0.5755 - val_sparse_top_k_categorical_accuracy: 0.8359 - lr: 1.0000e-04\n",
      "Epoch 83/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1489 - sparse_categorical_accuracy: 0.3236 - sparse_top_k_categorical_accuracy: 0.5625 - val_loss: 1.5500 - val_sparse_categorical_accuracy: 0.5757 - val_sparse_top_k_categorical_accuracy: 0.8360 - lr: 1.0000e-04\n",
      "Epoch 84/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1484 - sparse_categorical_accuracy: 0.3241 - sparse_top_k_categorical_accuracy: 0.5625 - val_loss: 1.5493 - val_sparse_categorical_accuracy: 0.5761 - val_sparse_top_k_categorical_accuracy: 0.8360 - lr: 1.0000e-04\n",
      "Epoch 85/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1490 - sparse_categorical_accuracy: 0.3232 - sparse_top_k_categorical_accuracy: 0.5624 - val_loss: 1.5507 - val_sparse_categorical_accuracy: 0.5757 - val_sparse_top_k_categorical_accuracy: 0.8362 - lr: 1.0000e-04\n",
      "Epoch 86/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1487 - sparse_categorical_accuracy: 0.3240 - sparse_top_k_categorical_accuracy: 0.5630 - val_loss: 1.5548 - val_sparse_categorical_accuracy: 0.5759 - val_sparse_top_k_categorical_accuracy: 0.8352 - lr: 1.0000e-04\n",
      "Epoch 87/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1483 - sparse_categorical_accuracy: 0.3240 - sparse_top_k_categorical_accuracy: 0.5630 - val_loss: 1.5470 - val_sparse_categorical_accuracy: 0.5762 - val_sparse_top_k_categorical_accuracy: 0.8364 - lr: 1.0000e-04\n",
      "Epoch 88/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1485 - sparse_categorical_accuracy: 0.3235 - sparse_top_k_categorical_accuracy: 0.5630 - val_loss: 1.5481 - val_sparse_categorical_accuracy: 0.5767 - val_sparse_top_k_categorical_accuracy: 0.8365 - lr: 1.0000e-04\n",
      "Epoch 89/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1484 - sparse_categorical_accuracy: 0.3238 - sparse_top_k_categorical_accuracy: 0.5625 - val_loss: 1.5490 - val_sparse_categorical_accuracy: 0.5756 - val_sparse_top_k_categorical_accuracy: 0.8358 - lr: 1.0000e-04\n",
      "Epoch 90/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1483 - sparse_categorical_accuracy: 0.3237 - sparse_top_k_categorical_accuracy: 0.5625 - val_loss: 1.5486 - val_sparse_categorical_accuracy: 0.5764 - val_sparse_top_k_categorical_accuracy: 0.8360 - lr: 1.0000e-04\n",
      "Epoch 91/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1483 - sparse_categorical_accuracy: 0.3238 - sparse_top_k_categorical_accuracy: 0.5635 - val_loss: 1.5466 - val_sparse_categorical_accuracy: 0.5763 - val_sparse_top_k_categorical_accuracy: 0.8362 - lr: 1.0000e-04\n",
      "Epoch 92/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1479 - sparse_categorical_accuracy: 0.3240 - sparse_top_k_categorical_accuracy: 0.5629 - val_loss: 1.5478 - val_sparse_categorical_accuracy: 0.5766 - val_sparse_top_k_categorical_accuracy: 0.8364 - lr: 1.0000e-04\n",
      "Epoch 93/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1479 - sparse_categorical_accuracy: 0.3238 - sparse_top_k_categorical_accuracy: 0.5626 - val_loss: 1.5459 - val_sparse_categorical_accuracy: 0.5764 - val_sparse_top_k_categorical_accuracy: 0.8362 - lr: 1.0000e-04\n",
      "Epoch 94/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1481 - sparse_categorical_accuracy: 0.3242 - sparse_top_k_categorical_accuracy: 0.5628 - val_loss: 1.5426 - val_sparse_categorical_accuracy: 0.5766 - val_sparse_top_k_categorical_accuracy: 0.8363 - lr: 1.0000e-04\n",
      "Epoch 95/100\n",
      "11835/11835 [==============================] - 81s 7ms/step - loss: 2.1480 - sparse_categorical_accuracy: 0.3239 - sparse_top_k_categorical_accuracy: 0.5631 - val_loss: 1.5484 - val_sparse_categorical_accuracy: 0.5771 - val_sparse_top_k_categorical_accuracy: 0.8361 - lr: 1.0000e-04\n",
      "Epoch 96/100\n",
      "11835/11835 [==============================] - 82s 7ms/step - loss: 2.1477 - sparse_categorical_accuracy: 0.3243 - sparse_top_k_categorical_accuracy: 0.5634 - val_loss: 1.5458 - val_sparse_categorical_accuracy: 0.5768 - val_sparse_top_k_categorical_accuracy: 0.8367 - lr: 1.0000e-04\n",
      "Epoch 97/100\n",
      "11835/11835 [==============================] - 82s 7ms/step - loss: 2.1479 - sparse_categorical_accuracy: 0.3240 - sparse_top_k_categorical_accuracy: 0.5632 - val_loss: 1.5438 - val_sparse_categorical_accuracy: 0.5767 - val_sparse_top_k_categorical_accuracy: 0.8363 - lr: 1.0000e-04\n",
      "Epoch 98/100\n",
      "11835/11835 [==============================] - 81s 7ms/step - loss: 2.1478 - sparse_categorical_accuracy: 0.3238 - sparse_top_k_categorical_accuracy: 0.5630 - val_loss: 1.5446 - val_sparse_categorical_accuracy: 0.5775 - val_sparse_top_k_categorical_accuracy: 0.8365 - lr: 1.0000e-04\n",
      "Epoch 99/100\n",
      "11835/11835 [==============================] - 83s 7ms/step - loss: 2.1477 - sparse_categorical_accuracy: 0.3242 - sparse_top_k_categorical_accuracy: 0.5632 - val_loss: 1.5505 - val_sparse_categorical_accuracy: 0.5759 - val_sparse_top_k_categorical_accuracy: 0.8366 - lr: 1.0000e-04\n",
      "Epoch 100/100\n",
      "11835/11835 [==============================] - 80s 7ms/step - loss: 2.1478 - sparse_categorical_accuracy: 0.3242 - sparse_top_k_categorical_accuracy: 0.5631 - val_loss: 1.5462 - val_sparse_categorical_accuracy: 0.5763 - val_sparse_top_k_categorical_accuracy: 0.8363 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Train ResNet2 model further (100 epochs more??)\n",
    "\n",
    "extra_epochs = 100\n",
    "\n",
    "history2 = model.fit(x_train, y_train,\n",
    "          epochs= extra_epochs, \n",
    "          batch_size= batch_size, \n",
    "          validation_data=(x_test, y_test),\n",
    "         callbacks=callbacks) #mcp_save, callbacks=[reduce_lr_loss]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "455af150-79c6-4ec1-bb9a-7b8669fcbdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1480/1480 [==============================] - 6s 4ms/step - loss: 1.4411 - sparse_categorical_accuracy: 0.6096 - sparse_top_k_categorical_accuracy: 0.8829\n",
      "Test accuracy: 60.96%\n",
      "Test top 5 accuracy: 88.29%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "_, accuracy,top_5_accuracy = model.evaluate(x_val, y_val)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "#_,new_col_length,new_row_length = x_train.shape \n",
    "model.save(f'{base_path}//{ipynbname.name()}//{time_stamp}_Acc_{accuracy:.3f}_Top5Acc_{top_5_accuracy:.3f}_315x1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d25ca6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check start idx: 30035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(9, 9),\n",
       " (14, 14),\n",
       " (14, 14),\n",
       " (10, 9),\n",
       " (12, 11),\n",
       " (11, 11),\n",
       " (7, 8),\n",
       " (10, 10),\n",
       " (13, 13),\n",
       " (12, 11),\n",
       " (8, 9),\n",
       " (14, 15),\n",
       " (13, 13),\n",
       " (12, 12),\n",
       " (14, 14),\n",
       " (10, 10),\n",
       " (8, 9),\n",
       " (13, 13),\n",
       " (10, 10),\n",
       " (8, 8)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "check_start = random.randint(0,len(x_val))\n",
    "\n",
    "print(f'Check start idx: {check_start}')\n",
    "[(int(y_val[idx]), np.argmax(model.predict(np.expand_dims(x_val[idx],axis=0))) ) for idx in range(check_start,check_start+20) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3010684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from previous training\n",
    "load_model = 0\n",
    "if load_model:\n",
    "    model = tf.keras.models.load_model(r'Y:\\ibikunle\\Python_Project\\Fall_2021\\all_block_data\\Old_data\\Dec_Train_block_len_21_131121_2213\\NewResNet_weights_3ConvBlocks\\NewResNet_Nov21\\NewConv1_model_19_November_21_12_04_Acc_0.6530701518058777_21x15.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c4e5a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "11835/11835 [==============================] - 785s 66ms/step - loss: 2.1430 - sparse_categorical_accuracy: 0.3381 - sparse_top_k_categorical_accuracy: 0.5715 - val_loss: 1.6048 - val_sparse_categorical_accuracy: 0.5650 - val_sparse_top_k_categorical_accuracy: 0.8099 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      "11835/11835 [==============================] - 815s 69ms/step - loss: 2.1422 - sparse_categorical_accuracy: 0.3387 - sparse_top_k_categorical_accuracy: 0.5719 - val_loss: 1.5992 - val_sparse_categorical_accuracy: 0.5687 - val_sparse_top_k_categorical_accuracy: 0.8126 - lr: 1.0000e-04\n",
      "Epoch 3/30\n",
      "11835/11835 [==============================] - 804s 68ms/step - loss: 2.1415 - sparse_categorical_accuracy: 0.3389 - sparse_top_k_categorical_accuracy: 0.5722 - val_loss: 1.5966 - val_sparse_categorical_accuracy: 0.5678 - val_sparse_top_k_categorical_accuracy: 0.8110 - lr: 1.0000e-04\n",
      "Epoch 4/30\n",
      "11835/11835 [==============================] - 808s 68ms/step - loss: 2.1414 - sparse_categorical_accuracy: 0.3390 - sparse_top_k_categorical_accuracy: 0.5718 - val_loss: 1.5986 - val_sparse_categorical_accuracy: 0.5698 - val_sparse_top_k_categorical_accuracy: 0.8121 - lr: 1.0000e-04\n",
      "Epoch 5/30\n",
      "11835/11835 [==============================] - 804s 68ms/step - loss: 2.1408 - sparse_categorical_accuracy: 0.3394 - sparse_top_k_categorical_accuracy: 0.5720 - val_loss: 1.5966 - val_sparse_categorical_accuracy: 0.5679 - val_sparse_top_k_categorical_accuracy: 0.8117 - lr: 1.0000e-04\n",
      "Epoch 6/30\n",
      "11835/11835 [==============================] - 799s 67ms/step - loss: 2.1405 - sparse_categorical_accuracy: 0.3395 - sparse_top_k_categorical_accuracy: 0.5724 - val_loss: 1.5961 - val_sparse_categorical_accuracy: 0.5664 - val_sparse_top_k_categorical_accuracy: 0.8121 - lr: 1.0000e-04\n",
      "Epoch 7/30\n",
      "11835/11835 [==============================] - 787s 66ms/step - loss: 2.1404 - sparse_categorical_accuracy: 0.3392 - sparse_top_k_categorical_accuracy: 0.5724 - val_loss: 1.5999 - val_sparse_categorical_accuracy: 0.5685 - val_sparse_top_k_categorical_accuracy: 0.8118 - lr: 1.0000e-04\n",
      "Epoch 8/30\n",
      "11835/11835 [==============================] - 803s 68ms/step - loss: 2.1402 - sparse_categorical_accuracy: 0.3399 - sparse_top_k_categorical_accuracy: 0.5725 - val_loss: 1.5983 - val_sparse_categorical_accuracy: 0.5686 - val_sparse_top_k_categorical_accuracy: 0.8119 - lr: 1.0000e-04\n",
      "Epoch 9/30\n",
      "11835/11835 [==============================] - 798s 67ms/step - loss: 2.1400 - sparse_categorical_accuracy: 0.3398 - sparse_top_k_categorical_accuracy: 0.5724 - val_loss: 1.5977 - val_sparse_categorical_accuracy: 0.5688 - val_sparse_top_k_categorical_accuracy: 0.8115 - lr: 1.0000e-04\n",
      "Epoch 10/30\n",
      "11835/11835 [==============================] - 793s 67ms/step - loss: 2.1397 - sparse_categorical_accuracy: 0.3402 - sparse_top_k_categorical_accuracy: 0.5721 - val_loss: 1.6007 - val_sparse_categorical_accuracy: 0.5673 - val_sparse_top_k_categorical_accuracy: 0.8116 - lr: 1.0000e-04\n",
      "Epoch 11/30\n",
      "11835/11835 [==============================] - 796s 67ms/step - loss: 2.1395 - sparse_categorical_accuracy: 0.3398 - sparse_top_k_categorical_accuracy: 0.5727 - val_loss: 1.6050 - val_sparse_categorical_accuracy: 0.5657 - val_sparse_top_k_categorical_accuracy: 0.8094 - lr: 1.0000e-04\n",
      "Epoch 12/30\n",
      "11835/11835 [==============================] - 805s 68ms/step - loss: 2.1393 - sparse_categorical_accuracy: 0.3398 - sparse_top_k_categorical_accuracy: 0.5727 - val_loss: 1.6010 - val_sparse_categorical_accuracy: 0.5667 - val_sparse_top_k_categorical_accuracy: 0.8105 - lr: 1.0000e-04\n",
      "Epoch 13/30\n",
      "11835/11835 [==============================] - 793s 67ms/step - loss: 2.1389 - sparse_categorical_accuracy: 0.3404 - sparse_top_k_categorical_accuracy: 0.5728 - val_loss: 1.5924 - val_sparse_categorical_accuracy: 0.5667 - val_sparse_top_k_categorical_accuracy: 0.8105 - lr: 1.0000e-04\n",
      "Epoch 14/30\n",
      "11835/11835 [==============================] - 807s 68ms/step - loss: 2.1390 - sparse_categorical_accuracy: 0.3404 - sparse_top_k_categorical_accuracy: 0.5730 - val_loss: 1.5981 - val_sparse_categorical_accuracy: 0.5709 - val_sparse_top_k_categorical_accuracy: 0.8121 - lr: 1.0000e-04\n",
      "Epoch 15/30\n",
      "11835/11835 [==============================] - 793s 67ms/step - loss: 2.1386 - sparse_categorical_accuracy: 0.3409 - sparse_top_k_categorical_accuracy: 0.5729 - val_loss: 1.6008 - val_sparse_categorical_accuracy: 0.5665 - val_sparse_top_k_categorical_accuracy: 0.8082 - lr: 1.0000e-04\n",
      "Epoch 16/30\n",
      "11835/11835 [==============================] - 809s 68ms/step - loss: 2.1387 - sparse_categorical_accuracy: 0.3404 - sparse_top_k_categorical_accuracy: 0.5728 - val_loss: 1.5924 - val_sparse_categorical_accuracy: 0.5637 - val_sparse_top_k_categorical_accuracy: 0.8104 - lr: 1.0000e-04\n",
      "Epoch 17/30\n",
      "11835/11835 [==============================] - 816s 69ms/step - loss: 2.1383 - sparse_categorical_accuracy: 0.3404 - sparse_top_k_categorical_accuracy: 0.5728 - val_loss: 1.5974 - val_sparse_categorical_accuracy: 0.5656 - val_sparse_top_k_categorical_accuracy: 0.8101 - lr: 1.0000e-04\n",
      "Epoch 18/30\n",
      "11835/11835 [==============================] - 801s 68ms/step - loss: 2.1380 - sparse_categorical_accuracy: 0.3406 - sparse_top_k_categorical_accuracy: 0.5733 - val_loss: 1.5967 - val_sparse_categorical_accuracy: 0.5659 - val_sparse_top_k_categorical_accuracy: 0.8106 - lr: 1.0000e-04\n",
      "Epoch 19/30\n",
      "11835/11835 [==============================] - 816s 69ms/step - loss: 2.1381 - sparse_categorical_accuracy: 0.3406 - sparse_top_k_categorical_accuracy: 0.5735 - val_loss: 1.6062 - val_sparse_categorical_accuracy: 0.5662 - val_sparse_top_k_categorical_accuracy: 0.8089 - lr: 1.0000e-04\n",
      "Epoch 20/30\n",
      "11835/11835 [==============================] - 806s 68ms/step - loss: 2.1377 - sparse_categorical_accuracy: 0.3413 - sparse_top_k_categorical_accuracy: 0.5735 - val_loss: 1.6014 - val_sparse_categorical_accuracy: 0.5694 - val_sparse_top_k_categorical_accuracy: 0.8101 - lr: 1.0000e-04\n",
      "Epoch 21/30\n",
      "11835/11835 [==============================] - 799s 68ms/step - loss: 2.1376 - sparse_categorical_accuracy: 0.3414 - sparse_top_k_categorical_accuracy: 0.5736 - val_loss: 1.5944 - val_sparse_categorical_accuracy: 0.5694 - val_sparse_top_k_categorical_accuracy: 0.8114 - lr: 1.0000e-04\n",
      "Epoch 22/30\n",
      "11835/11835 [==============================] - 796s 67ms/step - loss: 2.1374 - sparse_categorical_accuracy: 0.3415 - sparse_top_k_categorical_accuracy: 0.5736 - val_loss: 1.5970 - val_sparse_categorical_accuracy: 0.5677 - val_sparse_top_k_categorical_accuracy: 0.8109 - lr: 1.0000e-04\n",
      "Epoch 23/30\n",
      "11835/11835 [==============================] - 799s 67ms/step - loss: 2.1374 - sparse_categorical_accuracy: 0.3411 - sparse_top_k_categorical_accuracy: 0.5735 - val_loss: 1.5893 - val_sparse_categorical_accuracy: 0.5651 - val_sparse_top_k_categorical_accuracy: 0.8083 - lr: 1.0000e-04\n",
      "Epoch 24/30\n",
      "11835/11835 [==============================] - 795s 67ms/step - loss: 2.1369 - sparse_categorical_accuracy: 0.3412 - sparse_top_k_categorical_accuracy: 0.5740 - val_loss: 1.6031 - val_sparse_categorical_accuracy: 0.5660 - val_sparse_top_k_categorical_accuracy: 0.8096 - lr: 1.0000e-04\n",
      "Epoch 25/30\n",
      "11835/11835 [==============================] - 789s 67ms/step - loss: 2.1372 - sparse_categorical_accuracy: 0.3414 - sparse_top_k_categorical_accuracy: 0.5733 - val_loss: 1.5979 - val_sparse_categorical_accuracy: 0.5679 - val_sparse_top_k_categorical_accuracy: 0.8098 - lr: 1.0000e-04\n",
      "Epoch 26/30\n",
      "11835/11835 [==============================] - 804s 68ms/step - loss: 2.1369 - sparse_categorical_accuracy: 0.3416 - sparse_top_k_categorical_accuracy: 0.5738 - val_loss: 1.5916 - val_sparse_categorical_accuracy: 0.5684 - val_sparse_top_k_categorical_accuracy: 0.8121 - lr: 1.0000e-04\n",
      "Epoch 27/30\n",
      "11835/11835 [==============================] - 819s 69ms/step - loss: 2.1369 - sparse_categorical_accuracy: 0.3417 - sparse_top_k_categorical_accuracy: 0.5736 - val_loss: 1.5964 - val_sparse_categorical_accuracy: 0.5691 - val_sparse_top_k_categorical_accuracy: 0.8112 - lr: 1.0000e-04\n",
      "Epoch 28/30\n",
      "11835/11835 [==============================] - 825s 70ms/step - loss: 2.1364 - sparse_categorical_accuracy: 0.3417 - sparse_top_k_categorical_accuracy: 0.5738 - val_loss: 1.5957 - val_sparse_categorical_accuracy: 0.5674 - val_sparse_top_k_categorical_accuracy: 0.8106 - lr: 1.0000e-04\n",
      "Epoch 29/30\n",
      "11835/11835 [==============================] - 821s 69ms/step - loss: 2.1363 - sparse_categorical_accuracy: 0.3420 - sparse_top_k_categorical_accuracy: 0.5740 - val_loss: 1.5968 - val_sparse_categorical_accuracy: 0.5696 - val_sparse_top_k_categorical_accuracy: 0.8132 - lr: 1.0000e-04\n",
      "Epoch 30/30\n",
      "11835/11835 [==============================] - 811s 69ms/step - loss: 2.1360 - sparse_categorical_accuracy: 0.3420 - sparse_top_k_categorical_accuracy: 0.5739 - val_loss: 1.5923 - val_sparse_categorical_accuracy: 0.5689 - val_sparse_top_k_categorical_accuracy: 0.8095 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Train further\n",
    "# Define Sequential model with 3 layers\n",
    "num_epochs = 30\n",
    "batch_size = 64\n",
    "nodes = 256\n",
    "learning_rate = 1e-3\n",
    "\n",
    "wandb.config = {\n",
    "  \"learning_rate\": \"learning_rate\",\n",
    "  \"epochs\": num_epochs,\n",
    "  \"batch_size\": batch_size,\n",
    "  \"nodes\": nodes,\n",
    "  \"row_length\":row_length,\n",
    "  \"base_path\":base_path\n",
    "\n",
    "}\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(base_path+\"//NewResNet_weights_3ConvBlocks//\"+time_stamp+\"_best_model.h5\", save_best_only=True, monitor=\"val_loss\"),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, patience=10, min_lr=0.0001),    \n",
    "    WandbCallback()\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "          epochs= num_epochs, \n",
    "          batch_size= batch_size, \n",
    "          validation_data=(x_test, y_test),\n",
    "         callbacks=callbacks) #mcp_save, callbacks=[reduce_lr_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf9e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0e3b52e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1480/1480 [==============================] - 31s 21ms/step - loss: 1.4794 - sparse_categorical_accuracy: 0.6039 - sparse_top_k_categorical_accuracy: 0.8525\n",
      "Test accuracy: 60.39%\n",
      "Test top 5 accuracy: 85.25%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 14008... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c450787b284a2199c73a7a1c5b4340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 1.14MB of 1.14MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, accuracy,top_3_accuracy = model.evaluate(x_val, y_val)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "print(f\"Test top 5 accuracy: {round(top_3_accuracy * 100, 2)}%\")\n",
    "\n",
    "_,new_col_length,new_row_length,_ = x_train.shape \n",
    "model.save(f'{base_path}//NewResNet_weights_3ConvBlocks//{time_stamp}_Acc_{accuracy:.3f}_Top3Acc{top_3_accuracy:.3f}_{new_row_length}x{new_col_length}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837e3e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibk_tf_new",
   "language": "python",
   "name": "ibk_tf_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
