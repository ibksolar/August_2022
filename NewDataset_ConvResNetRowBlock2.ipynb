{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbf0fa04-d15f-40e3-bc8e-e0c581c9707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages Loaded\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,TensorBoard,ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.datasets import mnist, cifar10\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from scipy.io import loadmat \n",
    "import mat73\n",
    "from datetime import datetime\n",
    "import ipynbname\n",
    "\n",
    "print(\"Packages Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac4d22a9-05e5-4ece-bd8d-66a58fb87557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e0ff66a-fe8d-4b53-923d-87fd82eaa274",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mibksolar\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ibksolar/my-test-project/runs/yf6gvp0q\" target=\"_blank\">NewDataset_1stTry</a></strong> to <a href=\"https://wandb.ai/ibksolar/my-test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/ibksolar/my-test-project/runs/yf6gvp0q?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2d3a531d670>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "wandb.init(project=\"my-test-project\", entity=\"ibksolar\", name=\"NewDataset_1stTry\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9fb9b83-f2b1-4b99-82a7-e1580e7a2694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# base_path = '..\\\\..\\\\all_block_data\\Dec_Train_block_len_21_011121_2331'\n",
    "base_path = '../all_block_data/Old_data/Dec_Train_block_len_21_231121_1531'\n",
    "\n",
    "# Confirm path is right...\n",
    "print(f'{os.path.isdir(base_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e179ca79-43c2-45d8-a10e-1bb54507a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_data1 = mat73.loadmat(base_path + '/echo_cnn_in_out_jstars.mat')\n",
    "all_data = raw_data1['echo_cnn_input']\n",
    "all_target = raw_data1['echo_cnn_target']\n",
    "coords = raw_data1['coords']\n",
    "echo_idx = raw_data1['orig_echo_idx']\n",
    "\n",
    "# Set all nan in the data to zero\n",
    "nan_idx = np.isnan(all_data).any(axis =-1)\n",
    "all_target[nan_idx] = 0\n",
    "all_data[ np.isnan(all_data) ]= 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5382710c-f23a-4ce8-a01c-5c11a5e8e845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape (917311, 315)\n",
      "Target shape (917311,)\n"
     ]
    }
   ],
   "source": [
    "# Truncate data because data after truncate point is notgood for training\n",
    "echo_idx = np.asarray(echo_idx)\n",
    "stop_val = 600\n",
    "\n",
    "stop_list, = np.where(echo_idx == stop_val)\n",
    "stop_idx = stop_list[-1]\n",
    "\n",
    "all_data = all_data[:stop_idx]\n",
    "all_target = all_target[:stop_idx]\n",
    "\n",
    "print(f'Data shape {all_data.shape}')\n",
    "print(f'Target shape {all_target.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eaf3c7e-1bb9-4d3b-b0af-deca0f0995b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions match\n"
     ]
    }
   ],
   "source": [
    "row_length = 21 # CHANGE HERE <==\n",
    "col_length = 15\n",
    "\n",
    "# Check that the dimension of data is correct\n",
    "if all_data.shape[1] == row_length*col_length:\n",
    "    print('Dimensions match')\n",
    "else:\n",
    "    print(f' Row block length:{row_length} and col length:{col_length} does not match Data dimension:{all_data.shape[1]}') \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1acb17-7dee-417b-97bc-8d0bba4e4cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:(733848, 315)  X_test:(137597, 315)\n",
      "Shape of y_train:(733848, 22)  y_test:(137597, 22)\n"
     ]
    }
   ],
   "source": [
    "max_class = row_length \n",
    "\n",
    "# Highest class is mapped to row_length+1\n",
    "all_target[all_target == max_class+1 ] = 0\n",
    "\n",
    "\n",
    "shuffle = 0\n",
    "if shuffle:\n",
    "    random.Random(1337).shuffle(all_data)\n",
    "    random.Random(1337).shuffle(all_target)\n",
    "    # random.Random(1337).shuffle(all_idx)\n",
    "\n",
    "## Prep data\n",
    "train_size = int(np.floor(0.8*len(all_target)));\n",
    "test_size = int(np.round( 0.15* all_data.shape[0] ))\n",
    "val_size = all_data.shape[0] -train_size - test_size\n",
    "\n",
    "\n",
    "x_train = all_data[0:train_size,:]\n",
    "# x_train = np.reshape( x_train, (x_train.shape[0],max_class,-1,1) )\n",
    "\n",
    "x_test = all_data[train_size:train_size+test_size,:]\n",
    "# x_test = np.reshape( x_test, (x_test.shape[0],max_class,-1,1) )\n",
    "\n",
    "x_val = all_data[-val_size:,:]\n",
    "# x_val = np.reshape( x_val,(x_val.shape[0],max_class,-1,1) )\n",
    "\n",
    "y_train = all_target[:train_size]\n",
    "y_test  = all_target[train_size:train_size+test_size]\n",
    "y_val = all_target[-val_size:]\n",
    "\n",
    "var_input_shape = x_train.shape[1:] # 240 columns\n",
    "num_classes = max_class+1 # layers\n",
    "\n",
    "# Convert labels to categorical orthonormal vectors\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test  = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "print(f'Shape of X_train:{x_train.shape}  X_test:{x_test.shape}')\n",
    "print(f'Shape of y_train:{y_train.shape}  y_test:{y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6188688-1b48-4c60-ba5a-d08e672fa359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 5812/11467 [==============>...............] - ETA: 22:04 - loss: 2.2102 - accuracy: 0.4002 - top-3-accuracy: 0.7758"
     ]
    }
   ],
   "source": [
    "# Create your own ResNet here.\n",
    "\n",
    "# Skip 3 connection version of base model\n",
    "drop_out = 0.3\n",
    "nodes = 256\n",
    "shp = x_train.shape[1]\n",
    "\n",
    "inputs = tf.keras.Input(shape=(shp,), name='img')\n",
    "# aug_inputs = data_augmentation(inputs)\n",
    "\n",
    "x = Dense(nodes, activation='relu')(inputs)\n",
    "block_1_output = Dense(nodes, activation='relu')(x)\n",
    "\n",
    "x = Dense(nodes)(block_1_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "\n",
    "x = Dense(nodes)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "\n",
    "x = Dense(nodes)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "block_2_output = tf.keras.layers.add([x, block_1_output])\n",
    "\n",
    "x = Dense(nodes)(block_2_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "x = Dense(nodes)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "x = Dense(nodes)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "block_3_output = tf.keras.layers.add([x, block_2_output])\n",
    "\n",
    "x = Dense(nodes)(block_3_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "x = Dense(nodes)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "x = Dense(nodes)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "block_4_output = tf.keras.layers.add([x, block_3_output])\n",
    "\n",
    "x = Dense(nodes)(block_4_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "x = Dense(nodes)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "x = Dense(nodes)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "block_5_output = tf.keras.layers.add([x, block_4_output])\n",
    "\n",
    "\n",
    "x = Dense(nodes)(block_5_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "x = Dense(nodes)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "x = Dense(nodes)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "block_6_output = tf.keras.layers.add([x, block_5_output])\n",
    "\n",
    "x = Dense(nodes)(block_6_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "x = Dense(nodes)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "x = Dense(nodes)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "block_7_output = tf.keras.layers.add([x, block_6_output])\n",
    "\n",
    "x = Dense(nodes)(block_7_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "x = Dense(nodes)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "x = Dense(nodes)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "block_8_output = tf.keras.layers.add([x, block_7_output])\n",
    "\n",
    "x = Dense(nodes)(block_8_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "x = Dense(nodes)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "x = Dense(nodes)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "block_9_output = tf.keras.layers.add([x, block_8_output])\n",
    "\n",
    "x = Dense(nodes)(block_9_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "x = Dense(nodes)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(drop_out)(x)\n",
    "x = Dense(nodes)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "block_10_output = tf.keras.layers.add([x, block_9_output])\n",
    "\n",
    "\n",
    "x = Dense(nodes, activation='relu')(block_10_output)\n",
    "x = Dropout(drop_out)(x)\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs, name='Plain_Old_Resnet')\n",
    "\n",
    "top_K = 3\n",
    "weight_decay = 0.3\n",
    "\n",
    "optimizer = tfa.optimizers.AdamW(learning_rate=1e-1, weight_decay=weight_decay) #Adam(amsgrad=True)\n",
    "\n",
    "model.compile( Adam(learning_rate=1e-4,amsgrad=True), loss= tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1), metrics=['accuracy',tf.keras.metrics.TopKCategoricalAccuracy(top_K, name=\"top-3-accuracy\")])  #label_smoothing=0.05, tf.keras.losses.KLDivergence()\n",
    "\n",
    "time_stamp = datetime.strftime( datetime.now(),'%d_%B_%y_%H%M')\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=25, verbose=0, mode='min')\n",
    "# mcp_save = ModelCheckpoint('jstars_june_{epoch:02d}_{val_loss:.2f}.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "# mcp_path = f'{base_path}_/tmp/{time_stamp}_jstars_Epoch_{epoch:02d}_ValLoss{val_loss:.2f}.hdf5'\n",
    "# mcp_save = ModelCheckpoint('/tmp/jstars_Epoch_{epoch:02d}_ValLoss{val_loss:.2f}.hdf5', save_best_only=True, monitor='val_loss', mode='min') #{base_path}_\n",
    "\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=0, emin_delta =1e-4, mode='min')\n",
    "\n",
    "#TO DO: Would normalizing with from sklearn.preprocessing import MinMaxScaler help? Try later\n",
    "model.fit(x_train, y_train,\n",
    "          epochs= 50, \n",
    "          batch_size= 64, \n",
    "          validation_data=(x_test, y_test)) #mcp_save, callbacks=[reduce_lr_loss]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b709185f-c394-4c52-afa5-75bcf5964ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15663/15663 [==============================] - 8270s 527ms/step - loss: 1558866298929152.0000 - accuracy: 0.1153 - val_loss: 2.6399 - val_accuracy: 0.0999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\i368o351\\Anaconda3\\envs\\ibk_sept21_tf2.5\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "15663/15663 [==============================] - 8170s 522ms/step - loss: 2.5868 - accuracy: 0.1152 - val_loss: 2.6337 - val_accuracy: 0.0999\n",
      "Epoch 3/100\n",
      "15663/15663 [==============================] - 8128s 519ms/step - loss: 2.5868 - accuracy: 0.1156 - val_loss: 2.6303 - val_accuracy: 0.0999\n",
      "Epoch 4/100\n",
      "15663/15663 [==============================] - 8161s 521ms/step - loss: 2.5868 - accuracy: 0.1155 - val_loss: 2.6271 - val_accuracy: 0.0999\n",
      "Epoch 5/100\n",
      "15663/15663 [==============================] - 8302s 530ms/step - loss: 2.5868 - accuracy: 0.1154 - val_loss: 2.6247 - val_accuracy: 0.0999\n",
      "Epoch 6/100\n",
      "15663/15663 [==============================] - 8239s 526ms/step - loss: 2.5868 - accuracy: 0.1155 - val_loss: 2.6225 - val_accuracy: 0.0999\n",
      "Epoch 7/100\n",
      "10128/15663 [==================>...........] - ETA: 45:46 - loss: 2.5872 - accuracy: 0.1154"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Could not synchronize CUDA stream: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\3/ipykernel_3280/3612340396.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m history = model.fit(x_train, y_train,\n\u001b[0m\u001b[0;32m    107\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ibk_sept21_tf2.5\\lib\\site-packages\\wandb\\integration\\keras\\keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ibk_sept21_tf2.5\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1189\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ibk_sept21_tf2.5\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \"\"\"\n\u001b[0;32m    434\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ibk_sept21_tf2.5\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ibk_sept21_tf2.5\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ibk_sept21_tf2.5\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m       \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ibk_sept21_tf2.5\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1028\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1029\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ibk_sept21_tf2.5\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ibk_sept21_tf2.5\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ibk_sept21_tf2.5\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ibk_sept21_tf2.5\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ibk_sept21_tf2.5\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    510\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    513\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ibk_sept21_tf2.5\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     \"\"\"\n\u001b[0;32m   1093\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1094\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1095\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ibk_sept21_tf2.5\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1060\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1062\u001b[1;33m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1063\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ibk_sept21_tf2.5\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Could not synchronize CUDA stream: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered"
     ]
    }
   ],
   "source": [
    "# Define Sequential model with 3 layers\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "nodes = 256\n",
    "learning_rate = 1e-4\n",
    "\n",
    "wandb.config = {\n",
    "  \"learning_rate\": \"learning_rate\",\n",
    "  \"epochs\": num_epochs,\n",
    "  \"batch_size\": batch_size,\n",
    "  \"nodes\": nodes,\n",
    "  \"row_length\":row_length,\n",
    "  \"base_path\":base_path\n",
    "\n",
    "}\n",
    "\n",
    "input_shape = x_train.shape[1:] #(21,15,1)\n",
    "\n",
    "def ResNetBlock(x):\n",
    "    x =   layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(x) #input_layer\n",
    "    conv1 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(x) # input_layer, Conv1D\n",
    "    conv1 = layers.BatchNormalization()(conv1)\n",
    "    conv1 = layers.ReLU()(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "    conv2 = layers.BatchNormalization()(conv2)\n",
    "    conv2 = layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = layers.BatchNormalization()(conv3)\n",
    "    conv3 = layers.ReLU()(conv3)\n",
    "    \n",
    "    \n",
    "    conv3 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = layers.BatchNormalization()(conv3)\n",
    "    conv3 = layers.ReLU()(conv3)\n",
    "    \n",
    "    \n",
    "    conv3 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = layers.BatchNormalization()(conv3)\n",
    "    conv3 = layers.ReLU()(conv3)\n",
    "    \n",
    "    conv3 = layers.add([x,conv3])\n",
    "    x = layers.ReLU()(conv3) # Overwrite x\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def make_model(input_shape):\n",
    "    input_layer = layers.Input(input_shape)\n",
    "    \n",
    "    x =   layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
    "    \n",
    "    for _ in range(20):\n",
    "        x = ResNetBlock(x)\n",
    "    \n",
    "    # conv1 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(input_layer) #Conv1D\n",
    "    # conv1 = layers.BatchNormalization()(conv1)\n",
    "    # conv1 = layers.ReLU()(conv1)\n",
    "    # conv2 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "    # conv2 = layers.BatchNormalization()(conv2)\n",
    "    # conv2 = layers.ReLU()(conv2)\n",
    "    # conv3 = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    # conv3 = layers.BatchNormalization()(conv3)\n",
    "    # conv3 = layers.ReLU()(conv3)\n",
    "    \n",
    "    gap = layers.GlobalAveragePooling2D()(x)\n",
    "    gap = layers.Flatten()(gap)\n",
    "\n",
    "    output_layer = layers.Dense(num_classes, activation=\"softmax\")(gap)\n",
    "\n",
    "    return tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model = make_model(input_shape = input_shape) #x_train.shape[1:]\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_loss\"),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, patience=5, min_lr=0.0001),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=25, verbose=1), \n",
    "    WandbCallback()\n",
    "]\n",
    "\n",
    "\n",
    "# Poly Rate scheduler\n",
    "starter_learning_rate = 0.1\n",
    "end_learning_rate = 0.001\n",
    "decay_steps = 1000\n",
    "learning_rate_fn = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    starter_learning_rate,\n",
    "    decay_steps,\n",
    "    end_learning_rate,\n",
    "    power=0.5)\n",
    "\n",
    "# opt1 = tf.keras.optimizers.RMSprop(learning_rate=0.1,rho=0.9,momentum=0.9, epsilon=1e-07,centered=True,name=\"RMSprop\")\n",
    "opt2 = tf.keras.optimizers.Adam(learning_rate=learning_rate,amsgrad=True)\n",
    "poly_rate = tf.keras.optimizers.SGD(learning_rate = learning_rate_fn)\n",
    "poly_rate2 = tf.keras.optimizers.Adam(learning_rate = learning_rate_fn)\n",
    "\n",
    "# top_K = 3\n",
    "# model.compile( optimizer = opt, loss= 'categorical_crossentropy', metrics=['accuracy',tf.keras.metrics.TopKCategoricalAccuracy(top_K, name=\"top-3-accuracy\")])  #label_smoothing=0.05, tf.keras.losses.KLDivergence()\n",
    "\n",
    "model.compile( optimizer=poly_rate2,loss=\"categorical_crossentropy\", metrics=[\"accuracy\"],) #sparse_categorical_accuracy\n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "          epochs= num_epochs, \n",
    "          batch_size= batch_size, \n",
    "          validation_data=(x_test, y_test),\n",
    "         callbacks=callbacks) #mcp_save, callbacks=[reduce_lr_loss]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6ebe87-be62-45ed-9e32-4c8d1079c6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, accuracy = model.evaluate(x_val, y_val)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "# print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "_,new_col_length,new_row_length = x_train.shape \n",
    "model.save(f'{base_path}//{ipynbname.name()}//{time_stamp}_Acc_{accuracy:.3f}_{new_row_length}x{new_col_length}.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.9_IBk_tf2.5_Sep21",
   "language": "python",
   "name": "ibk_tf_2.5_sep21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
