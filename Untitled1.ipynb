{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbf0fa04-d15f-40e3-bc8e-e0c581c9707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages Loaded\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,TensorBoard,ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.datasets import mnist, cifar10\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from scipy.io import loadmat \n",
    "import mat73\n",
    "from datetime import datetime\n",
    "import ipynbname\n",
    "import time\n",
    "\n",
    "\n",
    "from packaging import version\n",
    "print(\"Packages Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac4d22a9-05e5-4ece-bd8d-66a58fb87557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "    \n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e0ff66a-fe8d-4b53-923d-87fd82eaa274",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mibksolar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ibksolar/my-test-project/runs/3oc0qf8j\" target=\"_blank\">DenseLayers_trial</a></strong> to <a href=\"https://wandb.ai/ibksolar/my-test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/ibksolar/my-test-project/runs/3oc0qf8j?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x173a675a9d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "wandb.init(project=\"my-test-project\", \n",
    "           entity=\"ibksolar\",\n",
    "           name=\"DenseLayers_trial\",\n",
    "           config = {\n",
    "                          \"learning_rate\": \"NA\",\n",
    "                          \"epochs\": 50,\n",
    "                          \"batch_size\": 512,\n",
    "                          \"nodes\": 2048,\n",
    "                          \"row_length\":21,\n",
    "                          #\"base_path\":base_path,\n",
    "                          \"num_classes\":22,\n",
    "\n",
    "}\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0424b7b-4283-46f0-9bc9-01a09099c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# raw_data1 = loadmat('new_echo_cnn_in_out_jstarrs2021_first_try/echo_cnn_in_out_jstars1.mat')\n",
    "# raw_data1 = loadmat('echo_cnn_in_out_GOOD_layers/new_echo_cnn_in_out_jstars1.mat') 'findpeaks_layers/new_echo_cnn_in_out_jstars1.mat'\n",
    "\n",
    "raw_data1 = loadmat('../../../Python_Env/final_layers_rowblock15_21/filtered_image/new_echo_cnn_in_out_jstars1.mat')\n",
    "raw_data2 = loadmat('../../../Python_Env/final_layers_rowblock15_21/filtered_image/new_echo_cnn_in_out_jstars2.mat')\n",
    "raw_data3 = loadmat('../../../Python_Env/final_layers_rowblock15_21/filtered_image/new_echo_cnn_in_out_jstars3.mat')\n",
    "# raw_data4 = loadmat('findpeaks_layers_rowblock20/new_echo_cnn_in_out_jstars4.mat')\n",
    "\n",
    "d1 = raw_data1['echo_cnn1']\n",
    "t1 = raw_data1['echo_target1']\n",
    "i1 = raw_data1['echo_idx1']\n",
    "\n",
    "d2 = raw_data2['echo_cnn2']\n",
    "t2 = raw_data2['echo_target2']\n",
    "i2 = raw_data2['echo_idx2']\n",
    "\n",
    "d3 = raw_data3['echo_cnn3']\n",
    "t3 = raw_data3['echo_target3']\n",
    "i3 = raw_data3['echo_idx3']\n",
    "\n",
    "# d4 = raw_data4['echo_cnn4']\n",
    "# t4 = raw_data4['echo_target4']\n",
    "# i4 = raw_data4['echo_idx4']\n",
    "\n",
    "all_data = np.concatenate( (d1,d2,d3),axis = 0 )\n",
    "all_target = np.concatenate( (t1,t2,t3),axis = 0 )\n",
    "all_idx = np.concatenate( (i1,i2,i3),axis = 0 )\n",
    "\n",
    "# Set all nan in the data to zero\n",
    "nan_idx = np.isnan(all_data).any(axis =-1)\n",
    "all_target[nan_idx] = 0\n",
    "all_data[ np.isnan(all_data) ]= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9fb9b83-f2b1-4b99-82a7-e1580e7a2694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# base_path = '..\\\\..\\\\all_block_data\\Dec_Train_block_len_21_011121_2331'\n",
    "base_path = '../all_block_data/Old_data/Dec_Train_block_len_21_131121_2213'\n",
    "\n",
    "# Confirm path is right...\n",
    "print(f'{os.path.isdir(base_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e179ca79-43c2-45d8-a10e-1bb54507a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_new_data = False\n",
    "\n",
    "if load_new_data:    \n",
    "    raw_data1 = mat73.loadmat(base_path + '/echo_cnn_in_out_jstars.mat')\n",
    "    all_data = raw_data1['echo_cnn_input']#*255\n",
    "    all_target = raw_data1['echo_cnn_target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eaf3c7e-1bb9-4d3b-b0af-deca0f0995b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions match\n"
     ]
    }
   ],
   "source": [
    "row_length = 21 # CHANGE HERE <==\n",
    "col_length = 15\n",
    "\n",
    "# Check that the dimension of data is correct\n",
    "if all_data.shape[1] == row_length*col_length:\n",
    "    print('Dimensions match')\n",
    "else:\n",
    "    print(f' Row block length:{row_length} and col length:{col_length} does not match Data dimension:{all_data.shape[1]}') \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1acb17-7dee-417b-97bc-8d0bba4e4cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_class = row_length \n",
    "\n",
    "# Highest class is mapped to row_length+1\n",
    "all_target[all_target == max_class+1 ] = 0\n",
    "\n",
    "\n",
    "shuffle = 1\n",
    "if shuffle:\n",
    "    random.Random(1337).shuffle(all_data)\n",
    "    random.Random(1337).shuffle(all_target)\n",
    "    random.Random(1337).shuffle(all_idx)\n",
    "\n",
    "## Prep data\n",
    "train_size = int(np.floor(0.75*len(all_target)));\n",
    "test_size = int(np.round( 0.15* all_data.shape[0] ))\n",
    "val_size = all_data.shape[0] -train_size - test_size\n",
    "\n",
    "\n",
    "x_train = all_data[0:train_size,:]\n",
    "\n",
    "x_test = all_data[train_size:train_size+test_size,:]\n",
    "\n",
    "x_val = all_data[-val_size:,:]\n",
    "\n",
    "y_train = all_target[:train_size]\n",
    "y_test  = all_target[train_size:train_size+test_size]\n",
    "y_val = all_target[-val_size:]\n",
    "\n",
    "var_input_shape = x_train.shape[1:] # 240 columns\n",
    "num_classes = max_class+1 # layers\n",
    "\n",
    "# Convert labels to categorical orthonormal vectors\n",
    "y_train_1hot = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_1hot  = tf.keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a2085b8-2b22-42ee-b8ed-e2d1e546ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = wandb.config\n",
    "config = {\n",
    "          \"learning_rate\": \"NA\",\n",
    "          #\"epochs\": 50,\n",
    "          #\"batch_size\": 512,\n",
    "          \"nodes\": 2048,\n",
    "          \"row_length\":21,\n",
    "          #\"base_path\":base_path,\n",
    "          \"num_classes\":22,\n",
    "}\n",
    "\n",
    "config['batch_size'] = 64\n",
    "config['epochs'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e92d5bc-42bf-4e33-974a-11bc2d2c0644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil\n",
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "class Monitor(Thread):\n",
    "    def __init__(self, delay, HardStop= False):\n",
    "        super(Monitor, self).__init__()\n",
    "        self.stopped = False\n",
    "        self.delay = delay # Time between calls to GPUtil\n",
    "        self.HardStop = HardStop\n",
    "        self.start()\n",
    "\n",
    "    def run(self):\n",
    "        while not self.stopped and not self.HardStop :\n",
    "            GPUtil.showUtilization()\n",
    "            time.sleep(self.delay)\n",
    "             \n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6c7cff-c423-4ea4-920c-be3057c1538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_ds = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(AUTO)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_ds = val_ds.batch(BATCH_SIZE).prefetch(AUTO)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_ds = test_ds.batch(BATCH_SIZE).prefetch(AUTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b709185f-c394-4c52-afa5-75bcf5964ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n",
      "ERROR:tensorflow:Failed to start profiler: Another profiler is running.\n",
      "Training start time:14_March_22_0145\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Trace already enabled\n",
      "ERROR:tensorflow:Failed to start profiler: Another profiler is running.\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = hierarchical_copy, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = hierarchical_copy, num_packs = 1\n",
      "12272/12272 [==============================] - 394s 32ms/step - loss: 1.4442 - accuracy: 0.4490 - top-3-accuracy: 0.0548 - val_loss: 1.4140 - val_accuracy: 0.4665 - val_top-3-accuracy: 0.0606 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "12272/12272 [==============================] - 395s 32ms/step - loss: 1.2094 - accuracy: 0.5340 - top-3-accuracy: 0.0599 - val_loss: 1.4217 - val_accuracy: 0.4968 - val_top-3-accuracy: 0.0884 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "12272/12272 [==============================] - 401s 33ms/step - loss: 1.1563 - accuracy: 0.5559 - top-3-accuracy: 0.0599 - val_loss: 1.2038 - val_accuracy: 0.5679 - val_top-3-accuracy: 0.0587 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "12272/12272 [==============================] - 413s 34ms/step - loss: 1.1289 - accuracy: 0.5674 - top-3-accuracy: 0.0607 - val_loss: 1.2043 - val_accuracy: 0.5603 - val_top-3-accuracy: 0.0788 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "12272/12272 [==============================] - 421s 34ms/step - loss: 1.1131 - accuracy: 0.5731 - top-3-accuracy: 0.0612 - val_loss: 1.2211 - val_accuracy: 0.5628 - val_top-3-accuracy: 0.0674 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "12272/12272 [==============================] - 426s 35ms/step - loss: 1.1085 - accuracy: 0.5760 - top-3-accuracy: 0.0614 - val_loss: 1.2549 - val_accuracy: 0.5580 - val_top-3-accuracy: 0.0523 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "12272/12272 [==============================] - 438s 36ms/step - loss: 1.1066 - accuracy: 0.5776 - top-3-accuracy: 0.0614 - val_loss: 1.2228 - val_accuracy: 0.5546 - val_top-3-accuracy: 0.0757 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "12272/12272 [==============================] - 463s 38ms/step - loss: 1.0964 - accuracy: 0.5811 - top-3-accuracy: 0.0602 - val_loss: 1.2152 - val_accuracy: 0.5760 - val_top-3-accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "12272/12272 [==============================] - 484s 39ms/step - loss: 1.0881 - accuracy: 0.5840 - top-3-accuracy: 0.0606 - val_loss: 1.3496 - val_accuracy: 0.5299 - val_top-3-accuracy: 0.0551 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "12272/12272 [==============================] - 503s 41ms/step - loss: 1.0865 - accuracy: 0.5865 - top-3-accuracy: 0.0598 - val_loss: 1.2482 - val_accuracy: 0.5763 - val_top-3-accuracy: 0.0569 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "12272/12272 [==============================] - 531s 43ms/step - loss: 1.0881 - accuracy: 0.5862 - top-3-accuracy: 0.0587 - val_loss: 1.3004 - val_accuracy: 0.5614 - val_top-3-accuracy: 0.0522 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "12272/12272 [==============================] - 560s 46ms/step - loss: 1.0866 - accuracy: 0.5864 - top-3-accuracy: 0.0590 - val_loss: 1.2304 - val_accuracy: 0.5756 - val_top-3-accuracy: 0.0747 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "12272/12272 [==============================] - 582s 47ms/step - loss: 1.0816 - accuracy: 0.5883 - top-3-accuracy: 0.0597 - val_loss: 1.1891 - val_accuracy: 0.5894 - val_top-3-accuracy: 0.0810 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "12272/12272 [==============================] - 616s 50ms/step - loss: 1.0823 - accuracy: 0.5888 - top-3-accuracy: 0.0610 - val_loss: 1.2541 - val_accuracy: 0.5648 - val_top-3-accuracy: 0.0739 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "12272/12272 [==============================] - 644s 52ms/step - loss: 1.0776 - accuracy: 0.5914 - top-3-accuracy: 0.0599 - val_loss: 1.2845 - val_accuracy: 0.5572 - val_top-3-accuracy: 0.0873 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "12272/12272 [==============================] - 686s 56ms/step - loss: 1.0713 - accuracy: 0.5933 - top-3-accuracy: 0.0610 - val_loss: 1.3031 - val_accuracy: 0.5573 - val_top-3-accuracy: 0.0628 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "12272/12272 [==============================] - 735s 60ms/step - loss: 1.0721 - accuracy: 0.5933 - top-3-accuracy: 0.0617 - val_loss: 1.3315 - val_accuracy: 0.5573 - val_top-3-accuracy: 0.0685 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "12272/12272 [==============================] - 780s 64ms/step - loss: 1.0717 - accuracy: 0.5930 - top-3-accuracy: 0.0617 - val_loss: 1.2314 - val_accuracy: 0.5846 - val_top-3-accuracy: 0.0724 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "12272/12272 [==============================] - 855s 70ms/step - loss: 1.0622 - accuracy: 0.5959 - top-3-accuracy: 0.0614 - val_loss: 1.3665 - val_accuracy: 0.5574 - val_top-3-accuracy: 0.0532 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "12272/12272 [==============================] - 999s 80ms/step - loss: 1.0574 - accuracy: 0.5975 - top-3-accuracy: 0.0612 - val_loss: 1.3270 - val_accuracy: 0.5649 - val_top-3-accuracy: 0.1007 - lr: 0.0010\n",
      "Training End time:14_March_22_0454\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'monitor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 75>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining End time:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_time\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Update Record\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m Report[curr_batch_size] \u001b[38;5;241m=\u001b[39m ( os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOMPUTERNAME\u001b[39m\u001b[38;5;124m'\u001b[39m],config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_time\u001b[39m\u001b[38;5;124m'\u001b[39m],config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_time\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;28mint\u001b[39m(stop_time\u001b[38;5;241m-\u001b[39mstart_time), \u001b[43mmonitor\u001b[49m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'monitor' is not defined"
     ]
    }
   ],
   "source": [
    "# Define Sequential model with 3 layers\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "strategy = tf.distribute.MirroredStrategy( cross_device_ops=tf.distribute.HierarchicalCopyAllReduce() )\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "\n",
    "# Callbacks\n",
    "config['start_time'] = datetime.strftime( datetime.now(),'%d_%B_%y_%H%M')\n",
    "model_save_path = os.path.join(os.path.dirname(os.getcwd()), r'all_block_data\\PulsedTrainTest')\n",
    "logs = model_save_path+'/'+ipynbname.name()+f\"/{config['start_time']}_logs/\" \n",
    "\n",
    "callbacks = [\n",
    "    #ModelCheckpoint(base_path2+'/'+ipynbname.name()+f\"/{start_time}_Checkpoint.h5\", save_best_only=True, monitor=\"val_loss\"),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.05, patience=15, min_lr=0.0001),\n",
    "    TensorBoard(log_dir = logs,histogram_freq = 1,profile_batch = '1,20')\n",
    "    #EarlyStopping(monitor=\"val_loss\", patience=60, verbose=1), #TensorBoard(log_dir = logs,histogram_freq = 1,profile_batch = '500,520'),\n",
    "    #WandbCallback()\n",
    "]\n",
    "\n",
    "\n",
    "# Use multiple GPU\n",
    "with strategy.scope():\n",
    "    top_K = 3\n",
    "    model = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(config['nodes'], activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dense(config['nodes'], activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(config['nodes'], activation=\"relu\", name=\"layer3\"),\n",
    "        layers.Dense(config['num_classes'],activation=\"softmax\", name=\"Final_layer\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "    opt = tf.keras.optimizers.RMSprop(\n",
    "        learning_rate=0.001,\n",
    "        rho=0.999,\n",
    "        momentum=0.999,\n",
    "        epsilon=1e-07, #centered=True,\n",
    "        name=\"RMSprop\")\n",
    "    model.compile( \"rmsprop\", loss= 'sparse_categorical_crossentropy', metrics=['accuracy',tf.keras.metrics.TopKCategoricalAccuracy(top_K, name=\"top-3-accuracy\")])  #label_smoothing=0.05, tf.keras.losses.KLDivergence()\n",
    "    \n",
    "\n",
    "Report = {} # This reports time and GPU usage for each batch size       \n",
    "#for curr_batch_size in [128, 512, 1024]:\n",
    "curr_batch_size = 128\n",
    "BUFFER_SIZE = curr_batch_size * 2\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "#train_ds = tf.data.Dataset.map(lambda x,y:\n",
    "train_ds = train_ds.shuffle(BUFFER_SIZE).batch(curr_batch_size).prefetch(AUTO) #, drop_remainder=True\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_ds = val_ds.batch(curr_batch_size).prefetch(AUTO)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_ds = test_ds.batch(curr_batch_size).prefetch(AUTO)\n",
    "\n",
    "# Instantiate monitor with a 10-second delay between updates\n",
    "#monitor = Monitor(10)\n",
    "\n",
    "config['start_time'] = datetime.strftime( datetime.now(),'%d_%B_%y_%H%M')\n",
    "print(f'Training start time:{config[\"start_time\"]}')\n",
    "\n",
    "start_time = time.time()\n",
    "history = model.fit(train_ds,\n",
    "          epochs= config['epochs'],           \n",
    "          validation_data=test_ds,\n",
    "         callbacks=callbacks) #mcp_save, callbacks=[reduce_lr_loss]\n",
    "\n",
    "config['end_time'] = datetime.strftime( datetime.now(),'%d_%B_%y_%H%M')\n",
    "stop_time= time.time()\n",
    "print(f'Training End time:{config[\"end_time\"]}')\n",
    "\n",
    "# Update Record\n",
    "Report[curr_batch_size] = ( os.environ['COMPUTERNAME'],config['start_time'],config['end_time'],int(stop_time-start_time), monitor )\n",
    "\n",
    "# Close monitor\n",
    "#monitor.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a978fe93-831b-4924-8d6f-34d69167833f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-268e24ee00fe65a1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-268e24ee00fe65a1\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=\"..\\\\all_block_data\\\\PulsedTrainTest\\\\Untitled1\\\\14_March_22_0145_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6ed07a-1a12-4580-9f37-92d53e47686b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "698c1927-2697-4642-b26a-4c66673fda57",
   "metadata": {},
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_2.8",
   "language": "python",
   "name": "tf_2.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
