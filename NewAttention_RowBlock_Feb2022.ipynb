{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbf0fa04-d15f-40e3-bc8e-e0c581c9707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages Loaded\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,TensorBoard,ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.datasets import mnist, cifar10\n",
    "import tensorflow_addons as tfa\n",
    "from itertools import chain\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from scipy.io import loadmat \n",
    "import mat73\n",
    "from datetime import datetime\n",
    "import ipynbname\n",
    "\n",
    "print(\"Packages Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4d22a9-05e5-4ece-bd8d-66a58fb87557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e0ff66a-fe8d-4b53-923d-87fd82eaa274",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mibksolar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ibksolar/my-test-project/runs/k3o12lsq\" target=\"_blank\">NewAttention_RowBlock_Feb202209_February_22_1402</a></strong> to <a href=\"https://wandb.ai/ibksolar/my-test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/ibksolar/my-test-project/runs/k3o12lsq?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2404f19ea60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "time_stamp = datetime.strftime( datetime.now(),'%d_%B_%y_%H%M')\n",
    "wandb.init(project=\"my-test-project\", entity=\"ibksolar\", name=ipynbname.name()+time_stamp)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9fb9b83-f2b1-4b99-82a7-e1580e7a2694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# base_path = '..\\\\..\\\\all_block_data\\Dec_Train_block_len_21_011121_2331'\n",
    "#base_path = '../all_block_data/Old_data/Dec_Train_block_len_21_231121_1531' '../all_block_data\\FindPeaks_data\\Dec_Train_block_len_21_030122_0614'\n",
    "\n",
    "base_path = '../../../Python_Env/final_layers_rowblock15_21/filtered_image'\n",
    "\n",
    "# Confirm path is right...\n",
    "print(f'{os.path.isdir(base_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "156fdd8c-4315-4d1f-ad47-d35b1ee7e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# raw_data1 = loadmat('new_echo_cnn_in_out_jstarrs2021_first_try/echo_cnn_in_out_jstars1.mat')\n",
    "# raw_data1 = loadmat('echo_cnn_in_out_GOOD_layers/new_echo_cnn_in_out_jstars1.mat') 'findpeaks_layers/new_echo_cnn_in_out_jstars1.mat'\n",
    "\n",
    "raw_data1 = loadmat('../../../Python_Env/final_layers_rowblock15_21/filtered_image/new_echo_cnn_in_out_jstars1.mat')\n",
    "raw_data2 = loadmat('../../../Python_Env/final_layers_rowblock15_21/filtered_image/new_echo_cnn_in_out_jstars2.mat')\n",
    "raw_data3 = loadmat('../../../Python_Env/final_layers_rowblock15_21/filtered_image/new_echo_cnn_in_out_jstars3.mat')\n",
    "# raw_data4 = loadmat('findpeaks_layers_rowblock20/new_echo_cnn_in_out_jstars4.mat')\n",
    "\n",
    "d1 = raw_data1['echo_cnn1']\n",
    "t1 = raw_data1['echo_target1']\n",
    "i1 = raw_data1['echo_idx1']\n",
    "c1 = raw_data1['coords1']\n",
    "\n",
    "d2 = raw_data2['echo_cnn2']\n",
    "t2 = raw_data2['echo_target2']\n",
    "i2 = raw_data2['echo_idx2']\n",
    "c2 = raw_data2['coords2']\n",
    "\n",
    "d3 = raw_data3['echo_cnn3']\n",
    "t3 = raw_data3['echo_target3']\n",
    "i3 = raw_data3['echo_idx3']\n",
    "c3 = raw_data3['coords3']\n",
    "\n",
    "# d4 = raw_data4['echo_cnn4']\n",
    "# t4 = raw_data4['echo_target4']\n",
    "# i4 = raw_data4['echo_idx4']\n",
    "\n",
    "\n",
    "orig_all_data = np.concatenate( (d1,d2,d3),axis = 0 )\n",
    "orig_all_target = np.concatenate( (t1,t2,t3),axis = 0 )\n",
    "orig_all_idx = np.concatenate( (i1,i2,i3),axis = 0 )\n",
    "coords = np.concatenate( (c1,c2,c3),axis = 0 )\n",
    "\n",
    "# Set all nan in the data to zero\n",
    "nan_idx = np.isnan(orig_all_data).any(axis =-1)\n",
    "orig_all_target[nan_idx] = 0\n",
    "orig_all_data[ np.isnan(orig_all_data) ]= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e179ca79-43c2-45d8-a10e-1bb54507a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_new_data = False\n",
    "\n",
    "if load_new_data:\n",
    "    raw_data1 = mat73.loadmat(base_path + '/echo_cnn_in_out_jstars.mat')\n",
    "    all_data = raw_data1['echo_cnn_input']\n",
    "    all_target = raw_data1['echo_cnn_target']\n",
    "    all_coords = raw_data1['coords']\n",
    "    echo_idx =raw_data1['orig_echo_idx']\n",
    "\n",
    "\n",
    "    # Set all nan in the data to zeroprint(f'Sum of NaNs in data is {np.sum(np.any(np.isnan(all_data)))}; in target is {np.sum(np.any(np.isnan(all_target)))} ')\n",
    "\n",
    "    print(f'Sum of NaNs in orignally in data is {np.sum(np.any(np.isnan(all_data)))}; in target is {np.sum(np.any(np.isnan(all_target)))} ')\n",
    "    nan_idx = np.isnan(all_data).any(axis =-1)\n",
    "    all_target[nan_idx] = 0\n",
    "    all_data[ np.isnan(all_data) ]= 0\n",
    "\n",
    "    print(f'Sum of NaNs in data after setting all to 0 is {np.sum(np.any(np.isnan(all_data)))}; in target is {np.sum(np.any(np.isnan(all_target)))} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f13f7172-dac0-45e4-8bd1-7929ae99977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split based on echograms into small dataset representing training and testing.\n",
    "\n",
    "reduce_test_set = True\n",
    "\n",
    "all_echo_idx = np.unique(orig_all_idx)\n",
    "\n",
    "# Start split \n",
    "test_echo_idx = list(chain.from_iterable( [ list(range(20*n+1,20*n+20)) for n in range(1,max(all_echo_idx)//20,2) ] ) )\n",
    "\n",
    "# list(set(test_echo_idx) & set(train_echo_idx))\n",
    "\n",
    "if reduce_test_set:\n",
    "    random.Random(13).shuffle(test_echo_idx)\n",
    "    test_echo_idx = test_echo_idx[:round(0.6*len(test_echo_idx))]\n",
    "    # Need to get the coords of the shuffled test_echo_idx\n",
    "\n",
    "# Create train_echo_idx     \n",
    "train_echo_idx = [int(elem) for elem in all_echo_idx if elem not in test_echo_idx]\n",
    "\n",
    "# Create new coords idx for each rowblock from all the echograms\n",
    "val_cnt = [ (orig_all_idx==elem).sum() for elem in train_echo_idx]\n",
    "new_coords = []\n",
    "for elem in val_cnt:\n",
    "    new_coords.append([*range(elem)])\n",
    "new_coords = np.concatenate(new_coords).ravel()\n",
    "\n",
    "# Get all idx of echos in train_echo_idx\n",
    "search_idx = search_idx = np.where(orig_all_idx == train_echo_idx) #np.where( np.in1d(all_idx,train_echo_idx) )\n",
    "search_idx = list(search_idx[0])\n",
    "\n",
    "all_data = orig_all_data[search_idx]\n",
    "all_target = orig_all_target[search_idx]\n",
    "all_idx = orig_all_idx[search_idx]\n",
    "\n",
    "np.testing.assert_equal(new_coords.shape[0],all_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ad9b9de-ad50-40b2-acd3-2ccd92622741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize all_data\n",
    "standardize = False\n",
    "if standardize:\n",
    "    all_data  = ( all_data - all_data.mean() ) / all_data.std()\n",
    "\n",
    "scale_data = False\n",
    "if scale_data:\n",
    "    all_data = 255*all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65ad29b3-3554-467b-ac66-aa751552daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate data because data after truncate point is notgood for training\n",
    "truncate_data = False\n",
    "if truncate_data:    \n",
    "    echo_idx = np.asarray(echo_idx)\n",
    "    stop_val = 400\n",
    "\n",
    "    stop_list, = np.where(echo_idx == stop_val)\n",
    "    stop_idx = stop_list[-1]\n",
    "\n",
    "    all_data = all_data[:stop_idx]\n",
    "    all_target = all_target[:stop_idx]\n",
    "    all_coords = all_coords[:stop_idx]\n",
    "    echo_idx = echo_idx[:stop_idx]\n",
    "\n",
    "    print(f'Data shape {all_data.shape}')\n",
    "    print(f'Target shape {all_target.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eaf3c7e-1bb9-4d3b-b0af-deca0f0995b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions match\n"
     ]
    }
   ],
   "source": [
    "row_length = 21 # CHANGE HERE <==\n",
    "col_length = 15\n",
    "\n",
    "# Check that the dimension of data is correct\n",
    "if all_data.shape[1] == row_length*col_length:\n",
    "    print('Dimensions match')\n",
    "else:\n",
    "    print(f' Row block length:{row_length} and col length:{col_length} does not match Data dimension:{all_data.shape[1]}') \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "240c5978-0a4c-4a42-af11-b067dffe8ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding\n",
    "if 0:\n",
    "    time_seq = col_length #5\n",
    "    # all_coords = raw_data1['coords']\n",
    "    all_coord_exp = np.zeros((all_coords.shape[0],time_seq,row_length))\n",
    "\n",
    "    for idx in range(len(all_coords)):\n",
    "        a,b,c,_ = np.asarray(all_coords[idx],dtype=\"int\")\n",
    "        if (a%2) == 0: # If row index is even - this isn't implemented well because it requires iterating through individual rows\n",
    "            all_coord_exp[idx] = np.sin( np.outer( np.arange(c,c+time_seq), pow(10000, (2*np.arange(a,b)/row_length)) ) )\n",
    "        else:\n",
    "            all_coord_exp[idx] = np.cos( np.outer( np.arange(c,c+time_seq), pow(10000, (2*np.arange(a,b)/row_length)) ) )\n",
    "\n",
    "    if 0: #truncate_data:\n",
    "        difficult_coords = all_coord_exp[stop_idx+1:]         \n",
    "        all_coord_exp = all_coord_exp[:stop_idx]        \n",
    "\n",
    "\n",
    "    all_coord_exp.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6a4ba46e-c63c-48c2-b618-a810416ee7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 9\n",
    "\n",
    "# Create Coords matrix to be used for Positional Embedding\n",
    "new_coords_mtx = np.zeros( (len(new_coords),seq_length) )\n",
    "\n",
    "for idx,each_coord in enumerate(new_coords):\n",
    "    new_coords_mtx[idx] = np.linspace(0, each_coord, num=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ab1acb17-7dee-417b-97bc-8d0bba4e4cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:(1191987, 9, 21)  X_test:(223498, 9, 21)\n",
      "Shape of y_train:(1191987, 1)  y_test:(223498, 1)\n"
     ]
    }
   ],
   "source": [
    "max_class = row_length \n",
    "\n",
    "# Highest class is mapped to row_length+1\n",
    "all_target[all_target == max_class+1 ] = 0\n",
    "\n",
    "\n",
    "shuffle = 1\n",
    "if shuffle:\n",
    "    random.Random(13).shuffle(all_data)\n",
    "    random.Random(13).shuffle(all_target)\n",
    "    # random.Random(13).shuffle(all_coord_exp)\n",
    "    random.Random(13).shuffle(new_coords_mtx)\n",
    "\n",
    "## Prep data\n",
    "train_size = int(np.floor(0.8*len(all_target)));\n",
    "test_size = int(np.round( 0.15* all_data.shape[0] ))\n",
    "val_size = all_data.shape[0] -train_size - test_size\n",
    "\n",
    "mid_pt = 8\n",
    "neigh =  4\n",
    "\n",
    "x_train = all_data[0:train_size,:]\n",
    "x_train = np.reshape( x_train, (x_train.shape[0],max_class,-1),order ='F' )\n",
    "x_train = x_train[:,:,mid_pt-neigh:mid_pt+neigh+1]\n",
    "# x_train = np.reshape(x_train,(x_train.shape[0],-1))\n",
    "x_train = np.transpose(x_train,(0,2,1))\n",
    "coords_train = new_coords[0:train_size]\n",
    "\n",
    "\n",
    "x_test = all_data[train_size:train_size+test_size,:]\n",
    "x_test = np.reshape( x_test,(x_test.shape[0],max_class,-1), order ='F' )\n",
    "x_test = x_test[:,:,mid_pt-neigh:mid_pt+neigh+1]\n",
    "# x_test = np.reshape(x_test,(x_test.shape[0],-1))\n",
    "x_test = np.transpose(x_test,(0,2,1))\n",
    "coords_test = new_coords[train_size:train_size+test_size]\n",
    "\n",
    "\n",
    "x_val = all_data[-val_size:,:]\n",
    "x_val = np.reshape( x_val,(x_val.shape[0],max_class,-1), order ='F' )\n",
    "x_val = x_val[:,:,mid_pt-neigh:mid_pt+neigh+1]\n",
    "# x_val = np.reshape(x_val,(x_val.shape[0],-1))\n",
    "x_val = np.transpose(x_val,(0,2,1))\n",
    "coords_val = new_coords[-val_size:]\n",
    "\n",
    "\n",
    "y_train = all_target[:train_size]\n",
    "y_test  = all_target[train_size:train_size+test_size]\n",
    "y_val = all_target[-val_size:]\n",
    "\n",
    "var_input_shape = x_train.shape[1:] # 240 columns\n",
    "num_classes = max_class+1 # layers\n",
    "\n",
    "\n",
    "# Convert labels to categorical orthonormal vectors\n",
    "y_train_1hot = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_1hot  = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(f'Shape of X_train:{x_train.shape}  X_test:{x_test.shape}')\n",
    "print(f'Shape of y_train:{y_train.shape}  y_test:{y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2641993-96aa-4d4f-9342-5806258036fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train_new = x_train + coords_train\n",
    "x_test_new = x_test + coords_test\n",
    "x_val_new = x_val + coords_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "90eaf02e-ac0c-47ae-93f8-ff9098ad79e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some of the input\n",
    "rand_idx = random.choice( range(1,x_train.shape[0]) )\n",
    "_ = plt.plot(x_train[rand_idx].flatten())\n",
    "_ = plt.title(f'Index {rand_idx}___Target_value:{y_train[rand_idx]}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3b703d53-632b-4e15-8a4d-8b4f58c78d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get file name: auto-generating name\n",
      "Activation_function not in workspace\n",
      "loss_function not in workspace\n",
      "Accuracy_per_epoch not in workspace\n",
      "Loss_per_epoch not in workspace\n",
      "Stop_time not in workspace\n",
      "extras  is not in workspace\n",
      "Current run hyper_params are dict_keys(['S_N', 'Start_time', 'NoteBook_name', 'Uniqueness_of_each_run', 'Base_dir', 'Train_shape', 'Output_shape', 'num_epochs', 'Activation_function', 'optimizer', 'learning_rate', 'loss_function', 'Accuracy_per_epoch', 'Loss_per_epoch', 'Stop_time', 'Model_config', 'Performance_on_test_set', 'output_path', 'shuffle', 'Computer_name', 'extras']):dict_values([40, '21_February_22_1624', 'NewAttention_RowBlock_Feb2022', 'Attempting to use ResNet as base Model for Attention: Using 15 time_steps_Large batch size(128: Cant do more Memory exhausted)__Adam default optimizer', '../../../Python_Env/final_layers_rowblock15_21/filtered_image', (1191987, 9, 21), '', '', '', '', '', '', '', '', '', '', '', '', 1, 'AQ-98JH673', ''])\n",
      "Fields to be updated include: ['Activation_function', 'loss_function', 'Accuracy_per_epoch', 'Loss_per_epoch', 'Stop_time', 'Model_config', 'extras']\n"
     ]
    }
   ],
   "source": [
    "# Populate the param log\n",
    "log ={}\n",
    "log['Notebook_name'] = ipynbname.name()\n",
    "log['Uniqueness_of_each_run'] = 'Attempting to use ResNet as base Model for Attention: Using 15 time_steps_Large batch size(128: Cant do more Memory exhausted)__Adam default optimizer'\n",
    "log['base_dir'] = base_path\n",
    "log['Train_shape'] = x_train.shape\n",
    "log['Output_shape'] = ''\n",
    "log['num_epochs'] = ''\n",
    "log['batch_size'] = ''\n",
    "log['activation_function'] = ''\n",
    "log['optimizer'] = ''\n",
    "log['learning_rate'] = ''\n",
    "log['loss_finction'] = ''\n",
    "log['accuracy'] = []\n",
    "log['loss'] = []\n",
    "log['stop_time'] = ''\n",
    "log['Model_config'] = ''\n",
    "log['Performance_on_test_set'] = ''\n",
    "log['output_path'] = ''  # output: where the trained model is saved\n",
    "log['shuffle'] = shuffle\n",
    "log['run_completion_comment'] = '' # Comment on training and probably evaluation too\n",
    "\n",
    "from model_hyper_param_log import create_log_entry,update_log_entry\n",
    "if \"log_idx\" in globals():\n",
    "    log[\"S_N\"] = log_idx\n",
    "log_idx = create_log_entry('../testing_sheet2.xlsx', log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b480746-2398-4f2a-95d3-4e92c7c3b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRY KERAS TUNER\n",
    "if 0:\n",
    "    # ResNet params\n",
    "    resnet_heads = 15\n",
    "\n",
    "    # Attention params\n",
    "    num_epochs = 3\n",
    "    batch_size = 64\n",
    "    nodes = 512 #512\n",
    "    learning_rate = 3e-3\n",
    "\n",
    "    head_size = 256 # 256,64\n",
    "    num_heads = 8\n",
    "    ff_dim= 16\n",
    "    num_transformer_blocks= 15\n",
    "    mlp_units=[nodes]*2,  # 128\n",
    "    mlp_dropout=0.3,     #0.4\n",
    "    dropout=0.2    \n",
    "\n",
    "\n",
    "    def model_builder(\n",
    "        input_shape,\n",
    "        hp,\n",
    "        head_size = head_size,\n",
    "        num_heads = num_heads,\n",
    "        ff_dim = ff_dim,\n",
    "        num_transformer_blocks = num_transformer_blocks,\n",
    "        mlp_units = mlp_units,    \n",
    "        dropout=0,\n",
    "        mlp_dropout=0,    \n",
    "    ):\n",
    "        inputs = tf.keras.Input(shape=input_shape)\n",
    "        # x = inputs\n",
    "        x =   layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(inputs)\n",
    "\n",
    "        for _ in range(resnet_heads):\n",
    "            x = ResNetBlock(x)\n",
    "\n",
    "        x = tf.reduce_sum(x,axis=-1)\n",
    "\n",
    "        for _ in range(num_transformer_blocks):\n",
    "            x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "        # Pool or average\n",
    "        # x = layers.GlobalAveragePooling1D()(x)#data_format=\"channels_first\"    \n",
    "        # x = layers.Flatten()(x)\n",
    "\n",
    "        for dim in mlp_units:\n",
    "            x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "            x = layers.Dropout(mlp_dropout)(x)\n",
    "\n",
    "        x = layers.Flatten()(x)\n",
    "        x = layers.Dense(64, activation=\"softmax\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "        outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "        # Tune the learning rate for the optimizer\n",
    "        # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "\n",
    "        hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                    metrics=['accuracy']) \n",
    "        return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    tuner = kt.Hyperband(model_builder,\n",
    "                         objective='val_accuracy',\n",
    "                         max_epochs=10,\n",
    "                         factor=3,)\n",
    "\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    tuner.search(x_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "    # Get the optimal hyperparameters\n",
    "    best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    print(f\"\"\"\n",
    "    The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "    layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "    is {best_hps.get('learning_rate')}.\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b709185f-c394-4c52-afa5-75bcf5964ad9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Functional model inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model_2\" was not an Input tensor, it was generated by layer tf.__operators__.add_27.\n",
      "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
      "The tensor that caused the issue was: tf.__operators__.add_27/AddV2:0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 9, 21), dtype=tf.float32, name='input_12'), name='input_12', description=\"created by layer 'input_12'\") at layer \"tf.__operators__.add_27\". The following previous layers were accessed without issue: ['embedding_4']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28984/963146904.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m          \u001b[1;31m#0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m model = build_model(input_shape,head_size=head_size,num_heads=num_heads,ff_dim=ff_dim,\n\u001b[0m\u001b[0;32m    122\u001b[0m                     \u001b[0mnum_transformer_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_transformer_blocks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                     \u001b[0mmlp_units\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmlp_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28984/963146904.py\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, nodes, dropout, mlp_dropout)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"softmax\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ibk_tf_2.6\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ibk_tf_2.6\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ibk_tf_2.6\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ibk_tf_2.6\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[1;34m(self, inputs, outputs)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0m\u001b[0;32m    193\u001b[0m         self.inputs, self.outputs)\n\u001b[0;32m    194\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ibk_tf_2.6\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m    977\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcomputable_tensors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 979\u001b[1;33m             raise ValueError('Graph disconnected: '\n\u001b[0m\u001b[0;32m    980\u001b[0m                              \u001b[1;34m'cannot obtain value for tensor '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m                              \u001b[1;34m' at layer \"'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\". '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 9, 21), dtype=tf.float32, name='input_12'), name='input_12', description=\"created by layer 'input_12'\") at layer \"tf.__operators__.add_27\". The following previous layers were accessed without issue: ['embedding_4']"
     ]
    }
   ],
   "source": [
    "# Create Custom Model for Attention from base LSTM model\n",
    "loaded_model = tf.keras.models.load_model(r\"Y:\\\\ibikunle\\\\Python_Project\\\\Fall_2021\\all_block_data\\Filteredfiltered_data\\LSTM1_RepeatExactly\\27_January_22_2325_RowBlockLSTM_checkpoint.h5\")\n",
    "for i in range(80):\n",
    "    loaded_model.layers[i].trainable = False\n",
    "    \n",
    "# Patch Embedding\n",
    "class PatchEmbedding(layers.Layer):\n",
    "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
    "        super(PatchEmbedding, self).__init__(**kwargs)\n",
    "        self.num_patch = num_patch\n",
    "        self.proj = layers.Dense(embed_dim)\n",
    "        self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, patch):\n",
    "        pos = tf.range(start=0, limit=self.num_patch, delta=1)\n",
    "        print(f\"Num patches {self.num_patch}: Pos {pos.shape}\")\n",
    "        return self.proj(patch) + self.pos_embed(pos)\n",
    "\n",
    "\n",
    "def ResNetBlock(x,nodes):\n",
    "    #x =   layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(x) #input_layer\n",
    "    conv1 = layers.Conv2D(filters=nodes, kernel_size=3, padding=\"same\")(x) # input_layer, Conv1D\n",
    "    conv1 = layers.BatchNormalization()(conv1)\n",
    "    conv1 = layers.ReLU()(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(filters=nodes, kernel_size=3, padding=\"same\")(conv1)\n",
    "    conv2 = layers.BatchNormalization()(conv2)\n",
    "    conv2 = layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = layers.Conv2D(filters=nodes, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = layers.BatchNormalization()(conv3)\n",
    "    conv3 = layers.ReLU()(conv3)\n",
    "    \n",
    "#     conv4 = layers.Conv2D(filters=nodes, kernel_size=3, padding=\"same\")(conv3)\n",
    "#     conv4 = layers.BatchNormalization()(conv4)\n",
    "#     conv4 = layers.ReLU()(conv4)\n",
    "    \n",
    "#     conv5 = layers.Conv2D(filters=nodes, kernel_size=3, padding=\"same\")(conv4)\n",
    "#     conv5 = layers.BatchNormalization()(conv5)\n",
    "#     conv5 = layers.ReLU()(conv5)\n",
    "    \n",
    "    conv3 = layers.add([x,conv3])\n",
    "    x = layers.ReLU()(conv3) # Overwrite x\n",
    "    \n",
    "    return x\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Attention and Normalization\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(inputs, inputs)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    return x + res\n",
    "\n",
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    nodes,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,    \n",
    "):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    pos_input = tf.keras.Input(shape=(None,))\n",
    "    \n",
    "    pos_embedding = layers.Embedding(input_dim = np.max(new_coords), output_dim = input_shape[-1])(pos_input)\n",
    "\n",
    "    inputs = inputs + pos_embedding\n",
    "    \n",
    "    # for _ in range(resnet_heads):\n",
    "    #     x = ResNetBlock(x,ff_dim)\n",
    "    \n",
    "    x = layers.LSTM(512,recurrent_dropout= 0, return_sequences=True)(inputs)   \n",
    "     \n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)   \n",
    "   \n",
    "    #x = tf.reduce_sum(x,axis=-1)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)    \n",
    "   \n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    return tf.keras.Model([inputs,pos_input], outputs)\n",
    "\n",
    "\n",
    "input_shape = (x_train.shape[1:]) # + (1,)  input_shape = (21,5,) #x_train.shape[2] \n",
    "\n",
    "# ResNet params\n",
    "resnet_heads = 10\n",
    "\n",
    "# Checkpoint path\n",
    "base_path2 = r'Y:\\ibikunle\\Python_Project\\Fall_2021\\all_block_data\\PulsedTrainTest'\n",
    "\n",
    "# Attention params\n",
    "num_epochs = 150\n",
    "batch_size = 128\n",
    "nodes = 64 #512\n",
    "learning_rate = 5e-2\n",
    "\n",
    "head_size = 64 # 256,64\n",
    "num_heads = 4\n",
    "ff_dim= 64\n",
    "num_transformer_blocks= 4\n",
    "mlp_units= [512,1024]  # 128,512\n",
    "mlp_dropout=0.1    #0.4\n",
    "dropout=0.1          #0.25\n",
    "\n",
    "model = build_model(input_shape,head_size=head_size,num_heads=num_heads,ff_dim=ff_dim,\n",
    "                    num_transformer_blocks = num_transformer_blocks,\n",
    "                    mlp_units=mlp_units, nodes=nodes, \n",
    "                    mlp_dropout=mlp_dropout, dropout=dropout)\n",
    "\n",
    "wandb.config = {\n",
    "  \"learning_rate\": \"learning_rate\",\n",
    "  \"epochs\": num_epochs, \n",
    "  \"batch_size\": batch_size,\n",
    "  \"nodes\": nodes,\n",
    "  \"row_length\":row_length,\n",
    "  \"base_path\":base_path,\n",
    "  \"head_size\":head_size, \"num_heads\":num_heads,\n",
    "  \"ff_dim\":ff_dim, \"num_transformer_blocks\":num_transformer_blocks,\n",
    "  \"mlp_units\":mlp_units, \"mlp_dropout\":mlp_dropout,\n",
    "  \"dropout\":dropout\n",
    "}\n",
    "\n",
    "\n",
    "# Poly Rate scheduler\n",
    "starter_learning_rate = 0.001\n",
    "end_learning_rate = 0.0001\n",
    "decay_steps = 1000\n",
    "learning_rate_fn = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    starter_learning_rate,\n",
    "    decay_steps,\n",
    "    end_learning_rate,\n",
    "    power=0.25)\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(base_path2+'/'+ipynbname.name()+\"/best_model.h5\", save_best_only=True, monitor=\"val_loss\"),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.05, patience=10, min_lr=0.0001),\n",
    "    #EarlyStopping(monitor=\"val_loss\", patience=25, verbose=1), \n",
    "    WandbCallback()\n",
    "]\n",
    "\n",
    "# Trying different optimizers\n",
    "opt1 = tf.keras.optimizers.RMSprop(learning_rate=learning_rate,rho=0.9,momentum=0.9, epsilon=1e-07,centered=True,name=\"RMSprop\")\n",
    "opt2 = tf.keras.optimizers.Adam(learning_rate=learning_rate,amsgrad=True)\n",
    "opt3 = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True, name=\"SGD\")\n",
    "opt4 = tfa.optimizers.AdamW(weight_decay = 0.0001, learning_rate=learning_rate,)\n",
    "\n",
    "poly_rate = tf.keras.optimizers.SGD(learning_rate = learning_rate_fn)\n",
    "poly_rate2 = tf.keras.optimizers.Adam(learning_rate = learning_rate_fn)\n",
    "top_K = 3\n",
    "\n",
    "start_time = datetime.strftime( datetime.now(),'%d_%B_%y_%H%M')\n",
    "print(f'Training start time:{start_time}')\n",
    "\n",
    "# model.compile( optimizer = opt, loss= 'categorical_crossentropy', metrics=['accuracy',tf.keras.metrics.TopKCategoricalAccuracy(top_K, name=\"top-3-accuracy\")])  #label_smoothing=0.05, tf.keras.losses.KLDivergence()\n",
    "#model.compile( optimizer=opt1,loss=\"sparse_categorical_crossentropy\" , metrics=[\"sparse_categorical_accuracy\"],) #\"sparse_categorical_crossentropy\" , sparse_categorical_accuracy\", tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.3)\n",
    "model.compile( optimizer = opt4, loss=\"categorical_crossentropy\" , metrics=['accuracy',tf.keras.metrics.TopKCategoricalAccuracy(top_K, name=\"top-3-accuracy\")],) # sparse_categorical_accuracy\", tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.3)\n",
    "#Adam(amsgrad=True), loss=\"categorical_crossentropy\"  optimizer=opt2,loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2)\n",
    "\n",
    "history = model.fit([x_train,new_coords_mtx], y_train_1hot,\n",
    "          epochs= num_epochs, \n",
    "          batch_size= batch_size, \n",
    "          validation_data=(x_test, y_test_1hot),\n",
    "         callbacks=callbacks) #mcp_save, callbacks=[reduce_lr_loss]\n",
    "\n",
    "# Update manual log file\n",
    "params_to_be_updated = update_log_entry('../testing_sheet2.xlsx', log_idx, model, history)\n",
    "\n",
    "# Update model with the best from Callbacks\n",
    "model = tf.keras.models.load_model(base_path2+'/'+ipynbname.name()+\"/best_model.h5\")\n",
    "\n",
    "end_time = datetime.strftime( datetime.now(),'%d_%B_%y_%H_%M')\n",
    "print(f'End time {end_time}')\n",
    "\n",
    "# Previous accuracy before using Findpeaks data was 12%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac03520-07a5-4310-a377-8745960293c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "4049/4049 [==============================] - 780s 192ms/step - loss: 2.0241 - accuracy: 0.3702 - top-3-accuracy: 0.6095 - val_loss: 1.3898 - val_accuracy: 0.6444 - val_top-3-accuracy: 0.8642\n",
      "Epoch 2/350\n",
      "4049/4049 [==============================] - 776s 192ms/step - loss: 2.0203 - accuracy: 0.3735 - top-3-accuracy: 0.6107 - val_loss: 1.3472 - val_accuracy: 0.6591 - val_top-3-accuracy: 0.8709\n",
      "Epoch 3/350\n",
      "4049/4049 [==============================] - 773s 191ms/step - loss: 2.0225 - accuracy: 0.3722 - top-3-accuracy: 0.6096 - val_loss: 1.3711 - val_accuracy: 0.6602 - val_top-3-accuracy: 0.8686\n",
      "Epoch 4/350\n",
      "4049/4049 [==============================] - 776s 192ms/step - loss: 2.0118 - accuracy: 0.3789 - top-3-accuracy: 0.6129 - val_loss: 1.3100 - val_accuracy: 0.6737 - val_top-3-accuracy: 0.8754\n",
      "Epoch 5/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 2.0063 - accuracy: 0.3823 - top-3-accuracy: 0.6139 - val_loss: 1.3071 - val_accuracy: 0.6761 - val_top-3-accuracy: 0.8755\n",
      "Epoch 6/350\n",
      "4049/4049 [==============================] - 774s 191ms/step - loss: 2.0027 - accuracy: 0.3843 - top-3-accuracy: 0.6151 - val_loss: 1.3312 - val_accuracy: 0.6641 - val_top-3-accuracy: 0.8735\n",
      "Epoch 7/350\n",
      "4049/4049 [==============================] - 776s 192ms/step - loss: 1.9988 - accuracy: 0.3868 - top-3-accuracy: 0.6165 - val_loss: 1.2930 - val_accuracy: 0.6904 - val_top-3-accuracy: 0.8794\n",
      "Epoch 8/350\n",
      "4049/4049 [==============================] - 777s 192ms/step - loss: 1.9966 - accuracy: 0.3876 - top-3-accuracy: 0.6167 - val_loss: 1.2868 - val_accuracy: 0.6855 - val_top-3-accuracy: 0.8801\n",
      "Epoch 9/350\n",
      "4049/4049 [==============================] - 774s 191ms/step - loss: 2.0062 - accuracy: 0.3826 - top-3-accuracy: 0.6135 - val_loss: 1.5256 - val_accuracy: 0.5918 - val_top-3-accuracy: 0.8388\n",
      "Epoch 10/350\n",
      "4049/4049 [==============================] - 773s 191ms/step - loss: 2.0182 - accuracy: 0.3747 - top-3-accuracy: 0.6112 - val_loss: 1.2934 - val_accuracy: 0.6830 - val_top-3-accuracy: 0.8780\n",
      "Epoch 11/350\n",
      "4049/4049 [==============================] - 776s 192ms/step - loss: 1.9921 - accuracy: 0.3902 - top-3-accuracy: 0.6184 - val_loss: 1.2845 - val_accuracy: 0.6952 - val_top-3-accuracy: 0.8829\n",
      "Epoch 12/350\n",
      "4049/4049 [==============================] - 776s 192ms/step - loss: 1.9834 - accuracy: 0.3955 - top-3-accuracy: 0.6203 - val_loss: 1.2770 - val_accuracy: 0.6981 - val_top-3-accuracy: 0.8790\n",
      "Epoch 13/350\n",
      "4049/4049 [==============================] - 777s 192ms/step - loss: 1.9792 - accuracy: 0.3983 - top-3-accuracy: 0.6214 - val_loss: 1.2477 - val_accuracy: 0.7056 - val_top-3-accuracy: 0.8843\n",
      "Epoch 14/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 1.9763 - accuracy: 0.3994 - top-3-accuracy: 0.6214 - val_loss: 1.2723 - val_accuracy: 0.6969 - val_top-3-accuracy: 0.8812\n",
      "Epoch 15/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 1.9722 - accuracy: 0.4018 - top-3-accuracy: 0.6228 - val_loss: 1.2544 - val_accuracy: 0.7081 - val_top-3-accuracy: 0.8820\n",
      "Epoch 16/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 1.9691 - accuracy: 0.4032 - top-3-accuracy: 0.6236 - val_loss: 1.2497 - val_accuracy: 0.7078 - val_top-3-accuracy: 0.8822\n",
      "Epoch 17/350\n",
      "4049/4049 [==============================] - 777s 192ms/step - loss: 1.9668 - accuracy: 0.4049 - top-3-accuracy: 0.6239 - val_loss: 1.2430 - val_accuracy: 0.7158 - val_top-3-accuracy: 0.8834\n",
      "Epoch 18/350\n",
      "4049/4049 [==============================] - 778s 192ms/step - loss: 1.9647 - accuracy: 0.4062 - top-3-accuracy: 0.6251 - val_loss: 1.2388 - val_accuracy: 0.7123 - val_top-3-accuracy: 0.8824\n",
      "Epoch 19/350\n",
      "4049/4049 [==============================] - 777s 192ms/step - loss: 1.9615 - accuracy: 0.4077 - top-3-accuracy: 0.6255 - val_loss: 1.2243 - val_accuracy: 0.7195 - val_top-3-accuracy: 0.8854\n",
      "Epoch 20/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 1.9589 - accuracy: 0.4086 - top-3-accuracy: 0.6260 - val_loss: 1.2305 - val_accuracy: 0.7193 - val_top-3-accuracy: 0.8854\n",
      "Epoch 21/350\n",
      "4049/4049 [==============================] - 773s 191ms/step - loss: 1.9591 - accuracy: 0.4084 - top-3-accuracy: 0.6267 - val_loss: 1.2355 - val_accuracy: 0.7224 - val_top-3-accuracy: 0.8882\n",
      "Epoch 22/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9562 - accuracy: 0.4102 - top-3-accuracy: 0.6267 - val_loss: 1.2445 - val_accuracy: 0.7222 - val_top-3-accuracy: 0.8834\n",
      "Epoch 23/350\n",
      "4049/4049 [==============================] - 779s 192ms/step - loss: 1.9525 - accuracy: 0.4122 - top-3-accuracy: 0.6278 - val_loss: 1.2433 - val_accuracy: 0.7235 - val_top-3-accuracy: 0.8863\n",
      "Epoch 24/350\n",
      "4049/4049 [==============================] - 782s 193ms/step - loss: 1.9576 - accuracy: 0.4094 - top-3-accuracy: 0.6262 - val_loss: 1.2221 - val_accuracy: 0.7208 - val_top-3-accuracy: 0.8833\n",
      "Epoch 25/350\n",
      "4049/4049 [==============================] - 782s 193ms/step - loss: 1.9500 - accuracy: 0.4132 - top-3-accuracy: 0.6289 - val_loss: 1.2168 - val_accuracy: 0.7301 - val_top-3-accuracy: 0.8871\n",
      "Epoch 26/350\n",
      "4049/4049 [==============================] - 781s 193ms/step - loss: 1.9471 - accuracy: 0.4150 - top-3-accuracy: 0.6294 - val_loss: 1.1845 - val_accuracy: 0.7331 - val_top-3-accuracy: 0.8890\n",
      "Epoch 27/350\n",
      "4049/4049 [==============================] - 779s 192ms/step - loss: 2.0671 - accuracy: 0.3456 - top-3-accuracy: 0.5939 - val_loss: 1.5457 - val_accuracy: 0.5789 - val_top-3-accuracy: 0.8423\n",
      "Epoch 28/350\n",
      "4049/4049 [==============================] - 779s 193ms/step - loss: 2.0968 - accuracy: 0.3279 - top-3-accuracy: 0.5888 - val_loss: 1.4910 - val_accuracy: 0.5973 - val_top-3-accuracy: 0.8531\n",
      "Epoch 29/350\n",
      "4049/4049 [==============================] - 776s 192ms/step - loss: 2.0782 - accuracy: 0.3386 - top-3-accuracy: 0.5944 - val_loss: 1.4398 - val_accuracy: 0.6158 - val_top-3-accuracy: 0.8586\n",
      "Epoch 30/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 2.0647 - accuracy: 0.3461 - top-3-accuracy: 0.5990 - val_loss: 1.4267 - val_accuracy: 0.6232 - val_top-3-accuracy: 0.8612\n",
      "Epoch 31/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 2.0617 - accuracy: 0.3485 - top-3-accuracy: 0.5987 - val_loss: 1.5834 - val_accuracy: 0.5594 - val_top-3-accuracy: 0.8375\n",
      "Epoch 32/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 2.0516 - accuracy: 0.3553 - top-3-accuracy: 0.6015 - val_loss: 1.3836 - val_accuracy: 0.6414 - val_top-3-accuracy: 0.8688\n",
      "Epoch 33/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 2.0379 - accuracy: 0.3636 - top-3-accuracy: 0.6066 - val_loss: 1.3744 - val_accuracy: 0.6544 - val_top-3-accuracy: 0.8717\n",
      "Epoch 34/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 2.0294 - accuracy: 0.3689 - top-3-accuracy: 0.6086 - val_loss: 1.3609 - val_accuracy: 0.6560 - val_top-3-accuracy: 0.8713\n",
      "Epoch 35/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 2.0217 - accuracy: 0.3736 - top-3-accuracy: 0.6107 - val_loss: 1.4017 - val_accuracy: 0.6312 - val_top-3-accuracy: 0.8592\n",
      "Epoch 36/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 2.0153 - accuracy: 0.3776 - top-3-accuracy: 0.6120 - val_loss: 1.3374 - val_accuracy: 0.6699 - val_top-3-accuracy: 0.8748\n",
      "Epoch 37/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 2.0091 - accuracy: 0.3813 - top-3-accuracy: 0.6134 - val_loss: 1.3265 - val_accuracy: 0.6722 - val_top-3-accuracy: 0.8731\n",
      "Epoch 38/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 2.0039 - accuracy: 0.3843 - top-3-accuracy: 0.6155 - val_loss: 1.2959 - val_accuracy: 0.6795 - val_top-3-accuracy: 0.8774\n",
      "Epoch 39/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 1.9979 - accuracy: 0.3878 - top-3-accuracy: 0.6163 - val_loss: 1.3037 - val_accuracy: 0.6899 - val_top-3-accuracy: 0.8764\n",
      "Epoch 40/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 1.9939 - accuracy: 0.3902 - top-3-accuracy: 0.6176 - val_loss: 1.2909 - val_accuracy: 0.6962 - val_top-3-accuracy: 0.8798\n",
      "Epoch 41/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 1.9885 - accuracy: 0.3932 - top-3-accuracy: 0.6186 - val_loss: 1.2804 - val_accuracy: 0.6962 - val_top-3-accuracy: 0.8797\n",
      "Epoch 42/350\n",
      "4049/4049 [==============================] - 778s 192ms/step - loss: 1.9867 - accuracy: 0.3941 - top-3-accuracy: 0.6196 - val_loss: 1.2708 - val_accuracy: 0.7009 - val_top-3-accuracy: 0.8812\n",
      "Epoch 43/350\n",
      "4049/4049 [==============================] - 779s 192ms/step - loss: 1.9797 - accuracy: 0.3981 - top-3-accuracy: 0.6211 - val_loss: 1.2950 - val_accuracy: 0.7011 - val_top-3-accuracy: 0.8795\n",
      "Epoch 44/350\n",
      "4049/4049 [==============================] - 779s 192ms/step - loss: 1.9800 - accuracy: 0.3984 - top-3-accuracy: 0.6211 - val_loss: 1.3284 - val_accuracy: 0.6868 - val_top-3-accuracy: 0.8762\n",
      "Epoch 45/350\n",
      "4049/4049 [==============================] - 779s 192ms/step - loss: 1.9745 - accuracy: 0.4012 - top-3-accuracy: 0.6229 - val_loss: 1.2556 - val_accuracy: 0.7098 - val_top-3-accuracy: 0.8829\n",
      "Epoch 46/350\n",
      "4049/4049 [==============================] - 779s 192ms/step - loss: 1.9693 - accuracy: 0.4044 - top-3-accuracy: 0.6231 - val_loss: 1.2403 - val_accuracy: 0.7141 - val_top-3-accuracy: 0.8835\n",
      "Epoch 47/350\n",
      "4049/4049 [==============================] - 779s 193ms/step - loss: 1.9655 - accuracy: 0.4060 - top-3-accuracy: 0.6250 - val_loss: 1.2397 - val_accuracy: 0.7162 - val_top-3-accuracy: 0.8844\n",
      "Epoch 48/350\n",
      "4049/4049 [==============================] - 780s 193ms/step - loss: 1.9637 - accuracy: 0.4065 - top-3-accuracy: 0.6257 - val_loss: 1.2776 - val_accuracy: 0.7149 - val_top-3-accuracy: 0.8802\n",
      "Epoch 49/350\n",
      "4049/4049 [==============================] - 780s 193ms/step - loss: 1.9745 - accuracy: 0.4004 - top-3-accuracy: 0.6224 - val_loss: 1.2406 - val_accuracy: 0.7218 - val_top-3-accuracy: 0.8849\n",
      "Epoch 50/350\n",
      "4049/4049 [==============================] - 780s 193ms/step - loss: 1.9619 - accuracy: 0.4077 - top-3-accuracy: 0.6253 - val_loss: 1.3185 - val_accuracy: 0.6935 - val_top-3-accuracy: 0.8713\n",
      "Epoch 51/350\n",
      "4049/4049 [==============================] - 780s 193ms/step - loss: 1.9555 - accuracy: 0.4106 - top-3-accuracy: 0.6271 - val_loss: 1.2567 - val_accuracy: 0.7158 - val_top-3-accuracy: 0.8812\n",
      "Epoch 52/350\n",
      "4049/4049 [==============================] - 780s 193ms/step - loss: 1.9523 - accuracy: 0.4125 - top-3-accuracy: 0.6288 - val_loss: 1.2204 - val_accuracy: 0.7303 - val_top-3-accuracy: 0.8876\n",
      "Epoch 53/350\n",
      "4049/4049 [==============================] - 780s 193ms/step - loss: 1.9492 - accuracy: 0.4141 - top-3-accuracy: 0.6290 - val_loss: 1.2258 - val_accuracy: 0.7291 - val_top-3-accuracy: 0.8874\n",
      "Epoch 54/350\n",
      "4049/4049 [==============================] - 780s 193ms/step - loss: 1.9463 - accuracy: 0.4153 - top-3-accuracy: 0.6293 - val_loss: 1.2247 - val_accuracy: 0.7326 - val_top-3-accuracy: 0.8865\n",
      "Epoch 55/350\n",
      "4049/4049 [==============================] - 780s 193ms/step - loss: 1.9432 - accuracy: 0.4171 - top-3-accuracy: 0.6302 - val_loss: 1.2542 - val_accuracy: 0.7229 - val_top-3-accuracy: 0.8847\n",
      "Epoch 56/350\n",
      "4049/4049 [==============================] - 780s 193ms/step - loss: 1.9438 - accuracy: 0.4168 - top-3-accuracy: 0.6297 - val_loss: 1.1957 - val_accuracy: 0.7356 - val_top-3-accuracy: 0.8896\n",
      "Epoch 57/350\n",
      "4049/4049 [==============================] - 773s 191ms/step - loss: 1.9400 - accuracy: 0.4188 - top-3-accuracy: 0.6312 - val_loss: 1.2569 - val_accuracy: 0.6966 - val_top-3-accuracy: 0.8769\n",
      "Epoch 58/350\n",
      "4049/4049 [==============================] - 771s 191ms/step - loss: 1.9369 - accuracy: 0.4200 - top-3-accuracy: 0.6319 - val_loss: 1.1940 - val_accuracy: 0.7356 - val_top-3-accuracy: 0.8866\n",
      "Epoch 59/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9353 - accuracy: 0.4208 - top-3-accuracy: 0.6316 - val_loss: 1.2004 - val_accuracy: 0.7398 - val_top-3-accuracy: 0.8883\n",
      "Epoch 60/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9366 - accuracy: 0.4195 - top-3-accuracy: 0.6317 - val_loss: 1.2455 - val_accuracy: 0.7123 - val_top-3-accuracy: 0.8801\n",
      "Epoch 61/350\n",
      "4049/4049 [==============================] - 771s 191ms/step - loss: 1.9329 - accuracy: 0.4223 - top-3-accuracy: 0.6329 - val_loss: 1.2132 - val_accuracy: 0.7213 - val_top-3-accuracy: 0.8829\n",
      "Epoch 62/350\n",
      "4049/4049 [==============================] - 771s 190ms/step - loss: 1.9298 - accuracy: 0.4231 - top-3-accuracy: 0.6336 - val_loss: 1.1912 - val_accuracy: 0.7397 - val_top-3-accuracy: 0.8870\n",
      "Epoch 63/350\n",
      "4049/4049 [==============================] - 771s 190ms/step - loss: 1.9292 - accuracy: 0.4234 - top-3-accuracy: 0.6338 - val_loss: 1.2042 - val_accuracy: 0.7404 - val_top-3-accuracy: 0.8873\n",
      "Epoch 64/350\n",
      "4049/4049 [==============================] - 774s 191ms/step - loss: 1.9255 - accuracy: 0.4248 - top-3-accuracy: 0.6344 - val_loss: 1.1633 - val_accuracy: 0.7434 - val_top-3-accuracy: 0.8889\n",
      "Epoch 65/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9239 - accuracy: 0.4259 - top-3-accuracy: 0.6348 - val_loss: 1.1815 - val_accuracy: 0.7471 - val_top-3-accuracy: 0.8898\n",
      "Epoch 66/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9264 - accuracy: 0.4238 - top-3-accuracy: 0.6347 - val_loss: 1.1888 - val_accuracy: 0.7471 - val_top-3-accuracy: 0.8882\n",
      "Epoch 67/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9213 - accuracy: 0.4266 - top-3-accuracy: 0.6350 - val_loss: 1.2028 - val_accuracy: 0.7460 - val_top-3-accuracy: 0.8866\n",
      "Epoch 68/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9196 - accuracy: 0.4271 - top-3-accuracy: 0.6364 - val_loss: 1.1799 - val_accuracy: 0.7513 - val_top-3-accuracy: 0.8918\n",
      "Epoch 69/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9186 - accuracy: 0.4279 - top-3-accuracy: 0.6363 - val_loss: 1.2026 - val_accuracy: 0.7464 - val_top-3-accuracy: 0.8886: 0.428\n",
      "Epoch 70/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9156 - accuracy: 0.4285 - top-3-accuracy: 0.6373 - val_loss: 1.1918 - val_accuracy: 0.7409 - val_top-3-accuracy: 0.8867\n",
      "Epoch 71/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9142 - accuracy: 0.4288 - top-3-accuracy: 0.6370 - val_loss: 1.1700 - val_accuracy: 0.7511 - val_top-3-accuracy: 0.8899- top-3-\n",
      "Epoch 72/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9146 - accuracy: 0.4289 - top-3-accuracy: 0.6378 - val_loss: 1.1680 - val_accuracy: 0.7474 - val_top-3-accuracy: 0.8889\n",
      "Epoch 73/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9125 - accuracy: 0.4297 - top-3-accuracy: 0.6383 - val_loss: 1.2170 - val_accuracy: 0.7370 - val_top-3-accuracy: 0.8851\n",
      "Epoch 74/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9114 - accuracy: 0.4300 - top-3-accuracy: 0.6386 - val_loss: 1.1996 - val_accuracy: 0.7423 - val_top-3-accuracy: 0.8878\n",
      "Epoch 75/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9082 - accuracy: 0.4314 - top-3-accuracy: 0.6392 - val_loss: 1.1678 - val_accuracy: 0.7563 - val_top-3-accuracy: 0.8912\n",
      "Epoch 76/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9080 - accuracy: 0.4311 - top-3-accuracy: 0.6390 - val_loss: 1.1949 - val_accuracy: 0.7369 - val_top-3-accuracy: 0.8864\n",
      "Epoch 77/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9099 - accuracy: 0.4304 - top-3-accuracy: 0.6382 - val_loss: 1.1759 - val_accuracy: 0.7521 - val_top-3-accuracy: 0.8873\n",
      "Epoch 78/350\n",
      "4049/4049 [==============================] - 774s 191ms/step - loss: 1.9051 - accuracy: 0.4327 - top-3-accuracy: 0.6403 - val_loss: 1.1612 - val_accuracy: 0.7581 - val_top-3-accuracy: 0.8903\n",
      "Epoch 79/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9046 - accuracy: 0.4326 - top-3-accuracy: 0.6397 - val_loss: 1.1897 - val_accuracy: 0.7361 - val_top-3-accuracy: 0.8846\n",
      "Epoch 80/350\n",
      "4049/4049 [==============================] - 774s 191ms/step - loss: 1.9028 - accuracy: 0.4332 - top-3-accuracy: 0.6407 - val_loss: 1.1437 - val_accuracy: 0.7588 - val_top-3-accuracy: 0.8909\n",
      "Epoch 81/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9026 - accuracy: 0.4329 - top-3-accuracy: 0.6406 - val_loss: 1.1638 - val_accuracy: 0.7568 - val_top-3-accuracy: 0.8911\n",
      "Epoch 82/350\n",
      "4049/4049 [==============================] - 771s 191ms/step - loss: 1.9013 - accuracy: 0.4333 - top-3-accuracy: 0.6416 - val_loss: 1.1550 - val_accuracy: 0.7488 - val_top-3-accuracy: 0.8903\n",
      "Epoch 83/350\n",
      "4049/4049 [==============================] - 771s 191ms/step - loss: 1.9005 - accuracy: 0.4337 - top-3-accuracy: 0.6412 - val_loss: 1.2487 - val_accuracy: 0.7181 - val_top-3-accuracy: 0.8788\n",
      "Epoch 84/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.8993 - accuracy: 0.4338 - top-3-accuracy: 0.6409 - val_loss: 1.1933 - val_accuracy: 0.7520 - val_top-3-accuracy: 0.8889\n",
      "Epoch 85/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.8969 - accuracy: 0.4350 - top-3-accuracy: 0.6417 - val_loss: 1.1476 - val_accuracy: 0.7598 - val_top-3-accuracy: 0.8916\n",
      "Epoch 86/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.8962 - accuracy: 0.4351 - top-3-accuracy: 0.6426 - val_loss: 1.1463 - val_accuracy: 0.7601 - val_top-3-accuracy: 0.8918\n",
      "Epoch 87/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.8949 - accuracy: 0.4351 - top-3-accuracy: 0.6427 - val_loss: 1.1498 - val_accuracy: 0.7533 - val_top-3-accuracy: 0.8899\n",
      "Epoch 88/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.8947 - accuracy: 0.4354 - top-3-accuracy: 0.6431 - val_loss: 1.1826 - val_accuracy: 0.7532 - val_top-3-accuracy: 0.8870\n",
      "Epoch 89/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.8957 - accuracy: 0.4346 - top-3-accuracy: 0.6425 - val_loss: 1.1802 - val_accuracy: 0.7516 - val_top-3-accuracy: 0.8893s: 1.8956\n",
      "Epoch 90/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.8923 - accuracy: 0.4360 - top-3-accuracy: 0.6444 - val_loss: 1.2368 - val_accuracy: 0.7213 - val_top-3-accuracy: 0.8772\n",
      "Epoch 91/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.8908 - accuracy: 0.4363 - top-3-accuracy: 0.6438 - val_loss: 1.1518 - val_accuracy: 0.7616 - val_top-3-accuracy: 0.8918\n",
      "Epoch 92/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.8903 - accuracy: 0.4367 - top-3-accuracy: 0.6437 - val_loss: 1.1718 - val_accuracy: 0.7568 - val_top-3-accuracy: 0.8894\n",
      "Epoch 93/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0469 - accuracy: 0.3541 - top-3-accuracy: 0.6006 - val_loss: 1.5762 - val_accuracy: 0.5759 - val_top-3-accuracy: 0.8416\n",
      "Epoch 94/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0994 - accuracy: 0.3278 - top-3-accuracy: 0.5880 - val_loss: 1.5220 - val_accuracy: 0.5932 - val_top-3-accuracy: 0.8493\n",
      "Epoch 95/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0838 - accuracy: 0.3361 - top-3-accuracy: 0.5931 - val_loss: 1.4888 - val_accuracy: 0.6054 - val_top-3-accuracy: 0.8562\n",
      "Epoch 96/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0710 - accuracy: 0.3431 - top-3-accuracy: 0.5968 - val_loss: 1.4425 - val_accuracy: 0.6199 - val_top-3-accuracy: 0.8577\n",
      "Epoch 97/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0602 - accuracy: 0.3502 - top-3-accuracy: 0.5999 - val_loss: 1.4595 - val_accuracy: 0.6251 - val_top-3-accuracy: 0.8563\n",
      "Epoch 98/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0495 - accuracy: 0.3559 - top-3-accuracy: 0.6035 - val_loss: 1.4112 - val_accuracy: 0.6388 - val_top-3-accuracy: 0.8638\n",
      "Epoch 99/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0464 - accuracy: 0.3585 - top-3-accuracy: 0.6042 - val_loss: 1.4131 - val_accuracy: 0.6403 - val_top-3-accuracy: 0.8640\n",
      "Epoch 100/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0351 - accuracy: 0.3652 - top-3-accuracy: 0.6064 - val_loss: 1.3826 - val_accuracy: 0.6509 - val_top-3-accuracy: 0.8691\n",
      "Epoch 101/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0267 - accuracy: 0.3708 - top-3-accuracy: 0.6091 - val_loss: 1.3571 - val_accuracy: 0.6600 - val_top-3-accuracy: 0.8713\n",
      "Epoch 102/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0188 - accuracy: 0.3750 - top-3-accuracy: 0.6108 - val_loss: 1.3756 - val_accuracy: 0.6440 - val_top-3-accuracy: 0.8622\n",
      "Epoch 103/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0115 - accuracy: 0.3793 - top-3-accuracy: 0.6132 - val_loss: 1.3184 - val_accuracy: 0.6735 - val_top-3-accuracy: 0.8758\n",
      "Epoch 104/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0049 - accuracy: 0.3834 - top-3-accuracy: 0.6145 - val_loss: 1.3123 - val_accuracy: 0.6797 - val_top-3-accuracy: 0.8756\n",
      "Epoch 105/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0497 - accuracy: 0.3572 - top-3-accuracy: 0.6016 - val_loss: 1.4485 - val_accuracy: 0.6164 - val_top-3-accuracy: 0.8599\n",
      "Epoch 106/350\n",
      "4049/4049 [==============================] - 771s 191ms/step - loss: 2.0331 - accuracy: 0.3655 - top-3-accuracy: 0.6068 - val_loss: 1.3418 - val_accuracy: 0.6686 - val_top-3-accuracy: 0.8737\n",
      "Epoch 107/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0048 - accuracy: 0.3831 - top-3-accuracy: 0.6148 - val_loss: 1.2996 - val_accuracy: 0.6788 - val_top-3-accuracy: 0.8801\n",
      "Epoch 108/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9950 - accuracy: 0.3889 - top-3-accuracy: 0.6169 - val_loss: 1.2799 - val_accuracy: 0.6895 - val_top-3-accuracy: 0.8803\n",
      "Epoch 109/350\n",
      "4049/4049 [==============================] - 771s 191ms/step - loss: 1.9872 - accuracy: 0.3937 - top-3-accuracy: 0.6191 - val_loss: 1.3224 - val_accuracy: 0.6889 - val_top-3-accuracy: 0.8767\n",
      "Epoch 110/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9823 - accuracy: 0.3965 - top-3-accuracy: 0.6204 - val_loss: 1.2987 - val_accuracy: 0.7002 - val_top-3-accuracy: 0.8786\n",
      "Epoch 111/350\n",
      "4049/4049 [==============================] - 779s 192ms/step - loss: 1.9768 - accuracy: 0.3996 - top-3-accuracy: 0.6218 - val_loss: 1.3349 - val_accuracy: 0.6761 - val_top-3-accuracy: 0.8700\n",
      "Epoch 112/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9723 - accuracy: 0.4016 - top-3-accuracy: 0.6229 - val_loss: 1.2652 - val_accuracy: 0.7081 - val_top-3-accuracy: 0.8802\n",
      "Epoch 113/350\n",
      "2048/4049 [==============>...............] - ETA: 6:00 - loss: 1.9792 - accuracy: 0.3978 - top-3-accuracy: 0.6208"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(x_train, y_train_1hot,\n",
    "      epochs= 350, \n",
    "      batch_size= batch_size, \n",
    "      validation_data=(x_test, y_test_1hot),\n",
    "     callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa8311c6-9529-4374-9f19-aab4be904e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get file name: auto-generating name\n",
      "Activation_function not in workspace\n",
      "extras  is not in workspace\n",
      "Current run hyper_params are dict_keys(['S_N', 'Start_time', 'NoteBook_name', 'Uniqueness_of_each_run', 'Base_dir', 'Train_shape', 'Output_shape', 'num_epochs', 'Activation_function', 'optimizer', 'learning_rate', 'loss_function', 'Accuracy_per_epoch', 'Loss_per_epoch', 'Stop_time', 'Model_config', 'Performance_on_test_set', 'output_path', 'shuffle', 'Computer_name', 'extras']):dict_values([16, '09_January_22_1705', 'NewAttention_RowBlock_Dec', 'Used Amsgrad and default learning rate to train. Removed label smoothing too', '../all_block_data\\\\FindPeaks_data\\\\Dec_Train_block_len_21_030122_0614', (518245, 15, 21), '', '', '', '', '', '', [], [], '', '', '', '', 0, 'AQ-LHJBMA1', ''])\n",
      "Fields to be updated include: ['Activation_function', 'learning_rate', 'loss_function', 'Accuracy_per_epoch', 'Loss_per_epoch', 'Stop_time', 'Model_config', 'Performance_on_test_set', 'extras']\n"
     ]
    }
   ],
   "source": [
    "log['Uniqueness_of_each_run'] = 'Used Amsgrad and default learning rate to train. Removed label smoothing too'\n",
    "run_completion_comment = f'Training on first 400 echos: Training looks so good! 98% acc. Need to test for overfitting'\n",
    "if \"log_idx\" in globals():\n",
    "    log[\"S_N\"] = log_idx\n",
    "    log['run_completion_comment'] = run_completion_comment\n",
    "    log_idx = create_log_entry('../testing_sheet2.xlsx', log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bebfea3f-776e-45e5-a223-d3071cc4c4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check start idx: 11343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "check_start = random.randint(0,len(x_val))\n",
    "\n",
    "print(f'Check start idx: {check_start}')\n",
    "[(np.argmax(y_val[idx]), np.argmax(model.predict(np.expand_dims(x_val[idx],axis=0))) ) for idx in range(check_start,check_start+20) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43003c33-f2e8-4981-a601-84b1765ab943",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013/1013 [==============================] - 27s 26ms/step - loss: 14.9815 - accuracy: 0.0233 - top-3-accuracy: 0.1946\n",
      "Test accuracy: 2.33%\n"
     ]
    }
   ],
   "source": [
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
    "_, accuracy,top_5_accuracy = model.evaluate(x_val, y_val)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "# print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "\n",
    "model.save(f'{base_path}//{ipynbname.name()}//{time_stamp}_Acc_{accuracy}_{row_length}x{col_length}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83731cd6-3657-4e9e-b7e8-68c0d826956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train further\n",
    "if accuracy < 0.7:\n",
    "    history = model.fit(x_train, y_train,\n",
    "          epochs= 20, \n",
    "          batch_size= batch_size, \n",
    "          validation_data=(x_test, y_test),\n",
    "         callbacks=callbacks) #mcp_save, callbacks=[reduce_lr_loss]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibk_tf_new",
   "language": "python",
   "name": "ibk_tf_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
