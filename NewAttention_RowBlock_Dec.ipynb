{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbf0fa04-d15f-40e3-bc8e-e0c581c9707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages Loaded\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,TensorBoard,ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.datasets import mnist, cifar10\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from scipy.io import loadmat \n",
    "import mat73\n",
    "from datetime import datetime\n",
    "import ipynbname\n",
    "\n",
    "print(\"Packages Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4d22a9-05e5-4ece-bd8d-66a58fb87557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e0ff66a-fe8d-4b53-923d-87fd82eaa274",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mibksolar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ibksolar/my-test-project/runs/30qxbm0c\" target=\"_blank\">NewAttention_RowBlock_Dec02_February_22_1130</a></strong> to <a href=\"https://wandb.ai/ibksolar/my-test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/ibksolar/my-test-project/runs/30qxbm0c?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x16931bcf9a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "time_stamp = datetime.strftime( datetime.now(),'%d_%B_%y_%H%M')\n",
    "wandb.init(project=\"my-test-project\", entity=\"ibksolar\", name=ipynbname.name()+time_stamp)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9fb9b83-f2b1-4b99-82a7-e1580e7a2694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# base_path = '..\\\\..\\\\all_block_data\\Dec_Train_block_len_21_011121_2331'\n",
    "#base_path = '../all_block_data/Old_data/Dec_Train_block_len_21_231121_1531' '../all_block_data\\FindPeaks_data\\Dec_Train_block_len_21_030122_0614'\n",
    "\n",
    "base_path = '../../../Python_Env/final_layers_rowblock15_21/filtered_image'\n",
    "\n",
    "# Confirm path is right...\n",
    "print(f'{os.path.isdir(base_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e179ca79-43c2-45d8-a10e-1bb54507a5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of NaNs in orignally in data is 1; in target is 0 \n",
      "Sum of NaNs in data after setting all to 0 is 0; in target is 0 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "raw_data1 = mat73.loadmat(base_path + '/echo_cnn_in_out_jstars.mat')\n",
    "all_data = raw_data1['echo_cnn_input']\n",
    "all_target = raw_data1['echo_cnn_target']\n",
    "all_coords = raw_data1['coords']\n",
    "echo_idx =raw_data1['orig_echo_idx']\n",
    "\n",
    "\n",
    "# Set all nan in the data to zeroprint(f'Sum of NaNs in data is {np.sum(np.any(np.isnan(all_data)))}; in target is {np.sum(np.any(np.isnan(all_target)))} ')\n",
    "\n",
    "print(f'Sum of NaNs in orignally in data is {np.sum(np.any(np.isnan(all_data)))}; in target is {np.sum(np.any(np.isnan(all_target)))} ')\n",
    "nan_idx = np.isnan(all_data).any(axis =-1)\n",
    "all_target[nan_idx] = 0\n",
    "all_data[ np.isnan(all_data) ]= 0\n",
    "\n",
    "print(f'Sum of NaNs in data after setting all to 0 is {np.sum(np.any(np.isnan(all_data)))}; in target is {np.sum(np.any(np.isnan(all_target)))} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ad9b9de-ad50-40b2-acd3-2ccd92622741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize all_data\n",
    "standardize = False\n",
    "if standardize:\n",
    "    all_data  = ( all_data - all_data.mean() ) / all_data.std()\n",
    "\n",
    "scale_data = False\n",
    "if scale_data:\n",
    "    all_data = 255*all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65ad29b3-3554-467b-ac66-aa751552daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate data because data after truncate point is notgood for training\n",
    "truncate_data = False\n",
    "if truncate_data:    \n",
    "    echo_idx = np.asarray(echo_idx)\n",
    "    stop_val = 400\n",
    "\n",
    "    stop_list, = np.where(echo_idx == stop_val)\n",
    "    stop_idx = stop_list[-1]\n",
    "\n",
    "    all_data = all_data[:stop_idx]\n",
    "    all_target = all_target[:stop_idx]\n",
    "    all_coords = all_coords[:stop_idx]\n",
    "    echo_idx = echo_idx[:stop_idx]\n",
    "\n",
    "    print(f'Data shape {all_data.shape}')\n",
    "    print(f'Target shape {all_target.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eaf3c7e-1bb9-4d3b-b0af-deca0f0995b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions match\n"
     ]
    }
   ],
   "source": [
    "row_length = 21 # CHANGE HERE <==\n",
    "col_length = 15\n",
    "\n",
    "# Check that the dimension of data is correct\n",
    "if all_data.shape[1] == row_length*col_length:\n",
    "    print('Dimensions match')\n",
    "else:\n",
    "    print(f' Row block length:{row_length} and col length:{col_length} does not match Data dimension:{all_data.shape[1]}') \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "240c5978-0a4c-4a42-af11-b067dffe8ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2094400, 15, 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positional Encoding\n",
    "time_seq = col_length #5\n",
    "# all_coords = raw_data1['coords']\n",
    "all_coord_exp = np.zeros((all_coords.shape[0],time_seq,row_length))\n",
    "\n",
    "for idx in range(len(all_coords)):\n",
    "    a,b,c,_ = np.asarray(all_coords[idx],dtype=\"int\")\n",
    "    if (a%2) == 0: # If row index is even - this isn't implemented well because it requires iterating through individual rows\n",
    "        all_coord_exp[idx] = np.sin( np.outer( np.arange(c,c+time_seq), pow(10000, (2*np.arange(a,b)/row_length)) ) )\n",
    "    else:\n",
    "        all_coord_exp[idx] = np.cos( np.outer( np.arange(c,c+time_seq), pow(10000, (2*np.arange(a,b)/row_length)) ) )\n",
    "\n",
    "if 0: #truncate_data:\n",
    "    difficult_coords = all_coord_exp[stop_idx+1:]         \n",
    "    all_coord_exp = all_coord_exp[:stop_idx]        \n",
    "   \n",
    "    \n",
    "all_coord_exp.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab1acb17-7dee-417b-97bc-8d0bba4e4cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:(1675520, 15, 21)  X_test:(314160, 15, 21)\n",
      "Shape of y_train:(1675520,)  y_test:(314160,)\n"
     ]
    }
   ],
   "source": [
    "max_class = row_length \n",
    "\n",
    "# Highest class is mapped to row_length+1\n",
    "all_target[all_target == max_class+1 ] = 0\n",
    "\n",
    "\n",
    "shuffle = 1\n",
    "if shuffle:\n",
    "    random.Random(13).shuffle(all_data)\n",
    "    random.Random(13).shuffle(all_target)\n",
    "    random.Random(13).shuffle(all_coord_exp)\n",
    "    # random.Random(1337).shuffle(all_idx)\n",
    "\n",
    "## Prep data\n",
    "train_size = int(np.floor(0.8*len(all_target)));\n",
    "test_size = int(np.round( 0.15* all_data.shape[0] ))\n",
    "val_size = all_data.shape[0] -train_size - test_size\n",
    "\n",
    "mid_pt = 8\n",
    "x_train = all_data[0:train_size,:]\n",
    "x_train = np.reshape( x_train, (x_train.shape[0],max_class,-1),order ='F' )\n",
    "#x_train = x_train[:,:,mid_pt-2:mid_pt+3]\n",
    "# x_train = np.reshape(x_train,(x_train.shape[0],-1))\n",
    "x_train = np.transpose(x_train,(0,2,1))\n",
    "coords_train = all_coord_exp[0:train_size,:]\n",
    "\n",
    "\n",
    "x_test = all_data[train_size:train_size+test_size,:]\n",
    "x_test = np.reshape( x_test,(x_test.shape[0],max_class,-1), order ='F' )\n",
    "#x_test = x_test[:,:,mid_pt-2:mid_pt+3]\n",
    "# x_test = np.reshape(x_test,(x_test.shape[0],-1))\n",
    "x_test = np.transpose(x_test,(0,2,1))\n",
    "coords_test = all_coord_exp[train_size:train_size+test_size,:]\n",
    "\n",
    "\n",
    "x_val = all_data[-val_size:,:]\n",
    "x_val = np.reshape( x_val,(x_val.shape[0],max_class,-1), order ='F' )\n",
    "#x_val = x_val[:,:,mid_pt-2:mid_pt+3]\n",
    "# x_val = np.reshape(x_val,(x_val.shape[0],-1))\n",
    "x_val = np.transpose(x_val,(0,2,1))\n",
    "coords_val = all_coord_exp[-val_size:,:]\n",
    "\n",
    "\n",
    "y_train = all_target[:train_size]\n",
    "y_test  = all_target[train_size:train_size+test_size]\n",
    "y_val = all_target[-val_size:]\n",
    "\n",
    "var_input_shape = x_train.shape[1:] # 240 columns\n",
    "num_classes = max_class+1 # layers\n",
    "\n",
    "\n",
    "# Convert labels to categorical orthonormal vectors\n",
    "y_train_1hot = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_1hot  = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(f'Shape of X_train:{x_train.shape}  X_test:{x_test.shape}')\n",
    "print(f'Shape of y_train:{y_train.shape}  y_test:{y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2641993-96aa-4d4f-9342-5806258036fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train_new = x_train + coords_train\n",
    "x_test_new = x_test + coords_test\n",
    "x_val_new = x_val + coords_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90eaf02e-ac0c-47ae-93f8-ff9098ad79e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some of the input\n",
    "rand_idx = random.choice( range(1,x_train.shape[0]) )\n",
    "_ = plt.plot(x_train[rand_idx].flatten())\n",
    "_ = plt.title(f'Index {rand_idx}___Target_value:{y_train[rand_idx]}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b703d53-632b-4e15-8a4d-8b4f58c78d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get file name: auto-generating name\n",
      "Activation_function not in workspace\n",
      "loss_function not in workspace\n",
      "Accuracy_per_epoch not in workspace\n",
      "Loss_per_epoch not in workspace\n",
      "Stop_time not in workspace\n",
      "extras  is not in workspace\n",
      "Current run hyper_params are dict_keys(['S_N', 'Start_time', 'NoteBook_name', 'Uniqueness_of_each_run', 'Base_dir', 'Train_shape', 'Output_shape', 'num_epochs', 'Activation_function', 'optimizer', 'learning_rate', 'loss_function', 'Accuracy_per_epoch', 'Loss_per_epoch', 'Stop_time', 'Model_config', 'Performance_on_test_set', 'output_path', 'shuffle', 'Computer_name', 'extras']):dict_values([33, '02_February_22_1144', 'NewAttention_RowBlock_Dec', 'Using FilteredFileterd Old data as training set:Shuffling: Seed 13, Using 15 time_steps_Large batch size(128: Cant do more Memory exhausted)__Adam default optimizer', '../../../Python_Env/final_layers_rowblock15_21/filtered_image', (1675520, 15, 21), '', '', '', '', '', '', '', '', '', '', '', '', 1, 'AQ-98JH673', ''])\n",
      "Fields to be updated include: ['Activation_function', 'loss_function', 'Accuracy_per_epoch', 'Loss_per_epoch', 'Stop_time', 'Model_config', 'extras']\n"
     ]
    }
   ],
   "source": [
    "# Populate the param log\n",
    "log ={}\n",
    "log['Notebook_name'] = ipynbname.name()\n",
    "log['Uniqueness_of_each_run'] = 'Using FilteredFileterd Old data as training set:Shuffling: Seed 13, Using 15 time_steps_Large batch size(128: Cant do more Memory exhausted)__Adam default optimizer'\n",
    "log['base_dir'] = base_path\n",
    "log['Train_shape'] = x_train.shape\n",
    "log['Output_shape'] = ''\n",
    "log['num_epochs'] = ''\n",
    "log['batch_size'] = ''\n",
    "log['activation_function'] = ''\n",
    "log['optimizer'] = ''\n",
    "log['learning_rate'] = ''\n",
    "log['loss_finction'] = ''\n",
    "log['accuracy'] = []\n",
    "log['loss'] = []\n",
    "log['stop_time'] = ''\n",
    "log['Model_config'] = ''\n",
    "log['Performance_on_test_set'] = ''\n",
    "log['output_path'] = ''  # output: where the trained model is saved\n",
    "log['shuffle'] = shuffle\n",
    "log['run_completion_comment'] = '' # Comment on training and probably evaluation too\n",
    "\n",
    "from model_hyper_param_log import create_log_entry,update_log_entry\n",
    "if \"log_idx\" in globals():\n",
    "    log[\"S_N\"] = log_idx\n",
    "log_idx = create_log_entry('../testing_sheet2.xlsx', log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b480746-2398-4f2a-95d3-4e92c7c3b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRY KERAS TUNER\n",
    "if 0:\n",
    "    # ResNet params\n",
    "    resnet_heads = 15\n",
    "\n",
    "    # Attention params\n",
    "    num_epochs = 3\n",
    "    batch_size = 64\n",
    "    nodes = 512 #512\n",
    "    learning_rate = 3e-3\n",
    "\n",
    "    head_size = 256 # 256,64\n",
    "    num_heads = 8\n",
    "    ff_dim= 16\n",
    "    num_transformer_blocks= 15\n",
    "    mlp_units=[nodes]*2,  # 128\n",
    "    mlp_dropout=0.3,     #0.4\n",
    "    dropout=0.2    \n",
    "\n",
    "\n",
    "    def model_builder(\n",
    "        input_shape,\n",
    "        hp,\n",
    "        head_size = head_size,\n",
    "        num_heads = num_heads,\n",
    "        ff_dim = ff_dim,\n",
    "        num_transformer_blocks = num_transformer_blocks,\n",
    "        mlp_units = mlp_units,    \n",
    "        dropout=0,\n",
    "        mlp_dropout=0,    \n",
    "    ):\n",
    "        inputs = tf.keras.Input(shape=input_shape)\n",
    "        # x = inputs\n",
    "        x =   layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(inputs)\n",
    "\n",
    "        for _ in range(resnet_heads):\n",
    "            x = ResNetBlock(x)\n",
    "\n",
    "        x = tf.reduce_sum(x,axis=-1)\n",
    "\n",
    "        for _ in range(num_transformer_blocks):\n",
    "            x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "        # Pool or average\n",
    "        # x = layers.GlobalAveragePooling1D()(x)#data_format=\"channels_first\"    \n",
    "        # x = layers.Flatten()(x)\n",
    "\n",
    "        for dim in mlp_units:\n",
    "            x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "            x = layers.Dropout(mlp_dropout)(x)\n",
    "\n",
    "        x = layers.Flatten()(x)\n",
    "        x = layers.Dense(64, activation=\"softmax\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "        outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "        # Tune the learning rate for the optimizer\n",
    "        # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "\n",
    "        hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                    metrics=['accuracy']) \n",
    "        return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    tuner = kt.Hyperband(model_builder,\n",
    "                         objective='val_accuracy',\n",
    "                         max_epochs=10,\n",
    "                         factor=3,)\n",
    "\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    tuner.search(x_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "    # Get the optimal hyperparameters\n",
    "    best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    print(f\"\"\"\n",
    "    The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "    layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "    is {best_hps.get('learning_rate')}.\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b709185f-c394-4c52-afa5-75bcf5964ad9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start time:06_February_22_2213\n",
      "Epoch 1/150\n",
      "13090/13090 [==============================] - 4302s 328ms/step - loss: 20.3188 - accuracy: 0.1166 - top-3-accuracy: 0.3204 - val_loss: 2.6309 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3304\n",
      "Epoch 2/150\n",
      "13090/13090 [==============================] - 4290s 328ms/step - loss: 239.4211 - accuracy: 0.1123 - top-3-accuracy: 0.3172 - val_loss: 2.6118 - val_accuracy: 0.0946 - val_top-3-accuracy: 0.3331\n",
      "Epoch 3/150\n",
      "13090/13090 [==============================] - 4271s 326ms/step - loss: 2.6231 - accuracy: 0.1158 - top-3-accuracy: 0.3219 - val_loss: 2.6123 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3304\n",
      "Epoch 4/150\n",
      "13090/13090 [==============================] - 4273s 326ms/step - loss: 2.6137 - accuracy: 0.1192 - top-3-accuracy: 0.3239 - val_loss: 2.6002 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3403\n",
      "Epoch 5/150\n",
      "13090/13090 [==============================] - 4280s 327ms/step - loss: 265.0177 - accuracy: 0.1188 - top-3-accuracy: 0.3242 - val_loss: 2.5980 - val_accuracy: 0.1043 - val_top-3-accuracy: 0.3304\n",
      "Epoch 6/150\n",
      "13090/13090 [==============================] - 4297s 328ms/step - loss: 2.6016 - accuracy: 0.1248 - top-3-accuracy: 0.3294 - val_loss: 2.5953 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3284\n",
      "Epoch 7/150\n",
      "13090/13090 [==============================] - 4305s 329ms/step - loss: 2.6000 - accuracy: 0.1247 - top-3-accuracy: 0.3294 - val_loss: 2.6066 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3307\n",
      "Epoch 8/150\n",
      "13090/13090 [==============================] - 4272s 326ms/step - loss: 226.8332 - accuracy: 0.1252 - top-3-accuracy: 0.3298 - val_loss: 2.6029 - val_accuracy: 0.1019 - val_top-3-accuracy: 0.3307\n",
      "Epoch 9/150\n",
      "13090/13090 [==============================] - 4264s 326ms/step - loss: 2.5917 - accuracy: 0.1303 - top-3-accuracy: 0.3334 - val_loss: 2.5923 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3403\n",
      "Epoch 10/150\n",
      "13090/13090 [==============================] - 4296s 328ms/step - loss: 2.5922 - accuracy: 0.1306 - top-3-accuracy: 0.3327 - val_loss: 2.5904 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3307\n",
      "Epoch 11/150\n",
      "13090/13090 [==============================] - 4296s 328ms/step - loss: 2.5923 - accuracy: 0.1302 - top-3-accuracy: 0.3326 - val_loss: 2.5907 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3403\n",
      "Epoch 12/150\n",
      "13090/13090 [==============================] - 4276s 327ms/step - loss: 155.6074 - accuracy: 0.1302 - top-3-accuracy: 0.3331 - val_loss: 2.5934 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3304\n",
      "Epoch 13/150\n",
      "13090/13090 [==============================] - 4262s 326ms/step - loss: 2.5908 - accuracy: 0.1316 - top-3-accuracy: 0.3328 - val_loss: 2.5921 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3403\n",
      "Epoch 14/150\n",
      "13090/13090 [==============================] - 4268s 326ms/step - loss: 2.5907 - accuracy: 0.1315 - top-3-accuracy: 0.3330 - val_loss: 2.5906 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3403\n",
      "Epoch 15/150\n",
      "13090/13090 [==============================] - 4256s 325ms/step - loss: 70.1525 - accuracy: 0.1303 - top-3-accuracy: 0.3329 - val_loss: 2.5900 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3403\n",
      "Epoch 16/150\n",
      "13090/13090 [==============================] - 4266s 326ms/step - loss: 2.5903 - accuracy: 0.1319 - top-3-accuracy: 0.3334 - val_loss: 2.5917 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3403\n",
      "Epoch 17/150\n",
      "13090/13090 [==============================] - 4289s 328ms/step - loss: 2.5904 - accuracy: 0.1320 - top-3-accuracy: 0.3334 - val_loss: 2.5895 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3298\n",
      "Epoch 18/150\n",
      "13090/13090 [==============================] - 4260s 325ms/step - loss: 40.1446 - accuracy: 0.1327 - top-3-accuracy: 0.3346 - val_loss: 2.5922 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3331\n",
      "Epoch 19/150\n",
      "13090/13090 [==============================] - 4266s 326ms/step - loss: 25.0193 - accuracy: 0.1328 - top-3-accuracy: 0.3345 - val_loss: 2.5896 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3322\n",
      "Epoch 20/150\n",
      "13090/13090 [==============================] - 4257s 325ms/step - loss: 2.5890 - accuracy: 0.1328 - top-3-accuracy: 0.3340 - val_loss: 2.5911 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3309\n",
      "Epoch 21/150\n",
      "13090/13090 [==============================] - 4280s 327ms/step - loss: 2.5890 - accuracy: 0.1328 - top-3-accuracy: 0.3344 - val_loss: 2.5914 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3307\n",
      "Epoch 22/150\n",
      "13090/13090 [==============================] - 4261s 326ms/step - loss: 299.9094 - accuracy: 0.1328 - top-3-accuracy: 0.3356 - val_loss: 2.5901 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3331\n",
      "Epoch 23/150\n",
      "13090/13090 [==============================] - 4271s 326ms/step - loss: 271.3145 - accuracy: 0.1321 - top-3-accuracy: 0.3343 - val_loss: 2.5894 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3403\n",
      "Epoch 24/150\n",
      "13090/13090 [==============================] - 4265s 326ms/step - loss: 1419.0916 - accuracy: 0.1324 - top-3-accuracy: 0.3350 - val_loss: 2.5909 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3280\n",
      "Epoch 25/150\n",
      "13090/13090 [==============================] - 4283s 327ms/step - loss: 2.5891 - accuracy: 0.1326 - top-3-accuracy: 0.3348 - val_loss: 2.5910 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3403\n",
      "Epoch 26/150\n",
      "13090/13090 [==============================] - 4279s 327ms/step - loss: 59.1080 - accuracy: 0.1329 - top-3-accuracy: 0.3357 - val_loss: 2.5900 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3198\n",
      "Epoch 27/150\n",
      "13090/13090 [==============================] - 4258s 325ms/step - loss: 80.0515 - accuracy: 0.1328 - top-3-accuracy: 0.3354 - val_loss: 2.5898 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3309\n",
      "Epoch 28/150\n",
      "13090/13090 [==============================] - 4264s 326ms/step - loss: 177.9523 - accuracy: 0.1329 - top-3-accuracy: 0.3351 - val_loss: 2.5905 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3284\n",
      "Epoch 29/150\n",
      "13090/13090 [==============================] - 4271s 326ms/step - loss: 81.5980 - accuracy: 0.1325 - top-3-accuracy: 0.3351 - val_loss: 2.5901 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3403\n",
      "Epoch 30/150\n",
      "13090/13090 [==============================] - 4267s 326ms/step - loss: 74.4618 - accuracy: 0.1315 - top-3-accuracy: 0.3345 - val_loss: 2.5940 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3304\n",
      "Epoch 31/150\n",
      "13090/13090 [==============================] - 4275s 327ms/step - loss: 118.5583 - accuracy: 0.1299 - top-3-accuracy: 0.3347 - val_loss: 2.5910 - val_accuracy: 0.1342 - val_top-3-accuracy: 0.3403\n",
      "Epoch 32/150\n",
      " 7109/13090 [===============>..............] - ETA: 30:43 - loss: 2.5902 - accuracy: 0.1324 - top-3-accuracy: 0.3336"
     ]
    }
   ],
   "source": [
    "\n",
    "def ResNetBlock(x,nodes):\n",
    "    #x =   layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(x) #input_layer\n",
    "    conv1 = layers.Conv2D(filters=nodes, kernel_size=3, padding=\"same\")(x) # input_layer, Conv1D\n",
    "    conv1 = layers.BatchNormalization()(conv1)\n",
    "    conv1 = layers.ReLU()(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(filters=nodes, kernel_size=3, padding=\"same\")(conv1)\n",
    "    conv2 = layers.BatchNormalization()(conv2)\n",
    "    conv2 = layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = layers.Conv2D(filters=nodes, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = layers.BatchNormalization()(conv3)\n",
    "    conv3 = layers.ReLU()(conv3)\n",
    "    \n",
    "#     conv4 = layers.Conv2D(filters=nodes, kernel_size=3, padding=\"same\")(conv3)\n",
    "#     conv4 = layers.BatchNormalization()(conv4)\n",
    "#     conv4 = layers.ReLU()(conv4)\n",
    "    \n",
    "#     conv5 = layers.Conv2D(filters=nodes, kernel_size=3, padding=\"same\")(conv4)\n",
    "#     conv5 = layers.BatchNormalization()(conv5)\n",
    "#     conv5 = layers.ReLU()(conv5)\n",
    "    \n",
    "    conv3 = layers.add([x,conv3])\n",
    "    x = layers.ReLU()(conv3) # Overwrite x\n",
    "    \n",
    "    return x\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    conv_feed_fwd = False\n",
    "    \n",
    "    # Attention and Normalization\n",
    "    inputs2 = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    \n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(inputs2, inputs2)\n",
    "    \n",
    "    x = x + inputs # Skip connection\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    res = x\n",
    "    #x = layers.Dropout(dropout)(x)       \n",
    "\n",
    "    # Feed Forward Part\n",
    "    if conv_feed_fwd:\n",
    "        x = layers.Conv2D(filters=ff_dim, kernel_size=(5,3),padding=\"same\", activation=\"relu\")(res)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.Conv2D(filters=ff_dim, kernel_size=(5,3),padding=\"same\", activation=\"relu\")(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    else:\n",
    "        for units in [ff_dim*2, ff_dim]: # Bad implementation: This has to be 64\n",
    "            x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "            x = layers.Dropout(0.1)(x)\n",
    "    return x + res\n",
    "\n",
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    nodes,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,    \n",
    "):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    #x =   layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(inputs)\n",
    "    \n",
    "    for _ in range(resnet_heads):\n",
    "        x = ResNetBlock(x,ff_dim)\n",
    "     \n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)   \n",
    "\n",
    "    # x = tf.reduce_sum(x,axis=-1)\n",
    "    # Pool or average\n",
    "    # x = layers.GlobalAveragePooling1D()(x)#data_format=\"channels_first\"    \n",
    "    # x = layers.Flatten()(x)   \n",
    "    \n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=tf.nn.gelu)(x) #\"relu\"\n",
    "        x = layers.Dropout(mlp_dropout)(x)   \n",
    "    \n",
    "    # x = tf.reduce_sum(x,axis=-1) # Add in \"filters\" dimension to speed up?\n",
    "    #x = layers.LayerNormalization(epsilon=1e-6)(x) \n",
    "    #x = layers.Dense(64, activation=\"relu\")(x) #\"relu\"\n",
    "    \n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "input_shape = (x_train.shape[1:]) + (1,) #input_shape = (21,5,) #x_train.shape[2]\n",
    "\n",
    "# ResNet params\n",
    "resnet_heads = 10\n",
    "\n",
    "# Checkpoint path\n",
    "base_path2 = r'Y:\\ibikunle\\Python_Project\\Fall_2021\\all_block_data\\PulsedTrainTest'\n",
    "\n",
    "# Attention params\n",
    "num_epochs = 150\n",
    "batch_size = 128\n",
    "nodes = 64 #512\n",
    "learning_rate = 5e-2\n",
    "\n",
    "head_size = 64 # 256,64\n",
    "num_heads = 4\n",
    "ff_dim= 64\n",
    "num_transformer_blocks= 8\n",
    "mlp_units= [512,1024]  # 128,512\n",
    "mlp_dropout=0.1    #0.4\n",
    "dropout=0.1          #0.25\n",
    "\n",
    "model = build_model(input_shape,head_size=head_size,num_heads=num_heads,ff_dim=ff_dim,\n",
    "                    num_transformer_blocks = num_transformer_blocks,\n",
    "                    mlp_units=mlp_units, nodes=nodes, \n",
    "                    mlp_dropout=mlp_dropout, dropout=dropout)\n",
    "\n",
    "wandb.config = {\n",
    "  \"learning_rate\": \"learning_rate\",\n",
    "  \"epochs\": num_epochs, \n",
    "  \"batch_size\": batch_size,\n",
    "  \"nodes\": nodes,\n",
    "  \"row_length\":row_length,\n",
    "  \"base_path\":base_path,\n",
    "  \"head_size\":head_size, \"num_heads\":num_heads,\n",
    "  \"ff_dim\":ff_dim, \"num_transformer_blocks\":num_transformer_blocks,\n",
    "  \"mlp_units\":mlp_units, \"mlp_dropout\":mlp_dropout,\n",
    "  \"dropout\":dropout\n",
    "}\n",
    "\n",
    "\n",
    "# Poly Rate scheduler\n",
    "starter_learning_rate = 0.001\n",
    "end_learning_rate = 0.0001\n",
    "decay_steps = 1000\n",
    "learning_rate_fn = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    starter_learning_rate,\n",
    "    decay_steps,\n",
    "    end_learning_rate,\n",
    "    power=0.25)\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(base_path2+'/'+ipynbname.name()+\"/best_model.h5\", save_best_only=True, monitor=\"val_loss\"),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.05, patience=10, min_lr=0.0001),\n",
    "    #EarlyStopping(monitor=\"val_loss\", patience=25, verbose=1), \n",
    "    WandbCallback()\n",
    "]\n",
    "\n",
    "# Trying different optimizers\n",
    "opt1 = tf.keras.optimizers.RMSprop(learning_rate=learning_rate,rho=0.9,momentum=0.9, epsilon=1e-07,centered=True,name=\"RMSprop\")\n",
    "opt2 = tf.keras.optimizers.Adam(learning_rate=learning_rate,amsgrad=True)\n",
    "opt3 = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True, name=\"SGD\")\n",
    "opt4 = tfa.optimizers.AdamW(weight_decay = 0.0001, learning_rate=learning_rate,)\n",
    "\n",
    "poly_rate = tf.keras.optimizers.SGD(learning_rate = learning_rate_fn)\n",
    "poly_rate2 = tf.keras.optimizers.Adam(learning_rate = learning_rate_fn)\n",
    "top_K = 3\n",
    "\n",
    "start_time = datetime.strftime( datetime.now(),'%d_%B_%y_%H%M')\n",
    "print(f'Training start time:{start_time}')\n",
    "\n",
    "# model.compile( optimizer = opt, loss= 'categorical_crossentropy', metrics=['accuracy',tf.keras.metrics.TopKCategoricalAccuracy(top_K, name=\"top-3-accuracy\")])  #label_smoothing=0.05, tf.keras.losses.KLDivergence()\n",
    "#model.compile( optimizer=opt1,loss=\"sparse_categorical_crossentropy\" , metrics=[\"sparse_categorical_accuracy\"],) #\"sparse_categorical_crossentropy\" , sparse_categorical_accuracy\", tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.3)\n",
    "model.compile( optimizer = opt4, loss=\"categorical_crossentropy\" , metrics=['accuracy',tf.keras.metrics.TopKCategoricalAccuracy(top_K, name=\"top-3-accuracy\")],) # sparse_categorical_accuracy\", tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.3)\n",
    "#Adam(amsgrad=True), loss=\"categorical_crossentropy\"  optimizer=opt2,loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2)\n",
    "\n",
    "history = model.fit(x_train, y_train_1hot,\n",
    "          epochs= num_epochs, \n",
    "          batch_size= batch_size, \n",
    "          validation_data=(x_test, y_test_1hot),\n",
    "         callbacks=callbacks) #mcp_save, callbacks=[reduce_lr_loss]\n",
    "\n",
    "# Update manual log file\n",
    "params_to_be_updated = update_log_entry('../testing_sheet2.xlsx', log_idx, model, history)\n",
    "\n",
    "# Update model with the best from Callbacks\n",
    "model = tf.keras.models.load_model(base_path2+'/'+ipynbname.name()+\"/best_model.h5\")\n",
    "\n",
    "end_time = datetime.strftime( datetime.now(),'%d_%B_%y_%H_%M')\n",
    "print(f'End time {end_time}')\n",
    "\n",
    "# Previous accuracy before using Findpeaks data was 12%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac03520-07a5-4310-a377-8745960293c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "4049/4049 [==============================] - 780s 192ms/step - loss: 2.0241 - accuracy: 0.3702 - top-3-accuracy: 0.6095 - val_loss: 1.3898 - val_accuracy: 0.6444 - val_top-3-accuracy: 0.8642\n",
      "Epoch 2/350\n",
      "4049/4049 [==============================] - 776s 192ms/step - loss: 2.0203 - accuracy: 0.3735 - top-3-accuracy: 0.6107 - val_loss: 1.3472 - val_accuracy: 0.6591 - val_top-3-accuracy: 0.8709\n",
      "Epoch 3/350\n",
      "4049/4049 [==============================] - 773s 191ms/step - loss: 2.0225 - accuracy: 0.3722 - top-3-accuracy: 0.6096 - val_loss: 1.3711 - val_accuracy: 0.6602 - val_top-3-accuracy: 0.8686\n",
      "Epoch 4/350\n",
      "4049/4049 [==============================] - 776s 192ms/step - loss: 2.0118 - accuracy: 0.3789 - top-3-accuracy: 0.6129 - val_loss: 1.3100 - val_accuracy: 0.6737 - val_top-3-accuracy: 0.8754\n",
      "Epoch 5/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 2.0063 - accuracy: 0.3823 - top-3-accuracy: 0.6139 - val_loss: 1.3071 - val_accuracy: 0.6761 - val_top-3-accuracy: 0.8755\n",
      "Epoch 6/350\n",
      "4049/4049 [==============================] - 774s 191ms/step - loss: 2.0027 - accuracy: 0.3843 - top-3-accuracy: 0.6151 - val_loss: 1.3312 - val_accuracy: 0.6641 - val_top-3-accuracy: 0.8735\n",
      "Epoch 7/350\n",
      "4049/4049 [==============================] - 776s 192ms/step - loss: 1.9988 - accuracy: 0.3868 - top-3-accuracy: 0.6165 - val_loss: 1.2930 - val_accuracy: 0.6904 - val_top-3-accuracy: 0.8794\n",
      "Epoch 8/350\n",
      "4049/4049 [==============================] - 777s 192ms/step - loss: 1.9966 - accuracy: 0.3876 - top-3-accuracy: 0.6167 - val_loss: 1.2868 - val_accuracy: 0.6855 - val_top-3-accuracy: 0.8801\n",
      "Epoch 9/350\n",
      "4049/4049 [==============================] - 774s 191ms/step - loss: 2.0062 - accuracy: 0.3826 - top-3-accuracy: 0.6135 - val_loss: 1.5256 - val_accuracy: 0.5918 - val_top-3-accuracy: 0.8388\n",
      "Epoch 10/350\n",
      "4049/4049 [==============================] - 773s 191ms/step - loss: 2.0182 - accuracy: 0.3747 - top-3-accuracy: 0.6112 - val_loss: 1.2934 - val_accuracy: 0.6830 - val_top-3-accuracy: 0.8780\n",
      "Epoch 11/350\n",
      "4049/4049 [==============================] - 776s 192ms/step - loss: 1.9921 - accuracy: 0.3902 - top-3-accuracy: 0.6184 - val_loss: 1.2845 - val_accuracy: 0.6952 - val_top-3-accuracy: 0.8829\n",
      "Epoch 12/350\n",
      "4049/4049 [==============================] - 776s 192ms/step - loss: 1.9834 - accuracy: 0.3955 - top-3-accuracy: 0.6203 - val_loss: 1.2770 - val_accuracy: 0.6981 - val_top-3-accuracy: 0.8790\n",
      "Epoch 13/350\n",
      "4049/4049 [==============================] - 777s 192ms/step - loss: 1.9792 - accuracy: 0.3983 - top-3-accuracy: 0.6214 - val_loss: 1.2477 - val_accuracy: 0.7056 - val_top-3-accuracy: 0.8843\n",
      "Epoch 14/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 1.9763 - accuracy: 0.3994 - top-3-accuracy: 0.6214 - val_loss: 1.2723 - val_accuracy: 0.6969 - val_top-3-accuracy: 0.8812\n",
      "Epoch 15/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 1.9722 - accuracy: 0.4018 - top-3-accuracy: 0.6228 - val_loss: 1.2544 - val_accuracy: 0.7081 - val_top-3-accuracy: 0.8820\n",
      "Epoch 16/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 1.9691 - accuracy: 0.4032 - top-3-accuracy: 0.6236 - val_loss: 1.2497 - val_accuracy: 0.7078 - val_top-3-accuracy: 0.8822\n",
      "Epoch 17/350\n",
      "4049/4049 [==============================] - 777s 192ms/step - loss: 1.9668 - accuracy: 0.4049 - top-3-accuracy: 0.6239 - val_loss: 1.2430 - val_accuracy: 0.7158 - val_top-3-accuracy: 0.8834\n",
      "Epoch 18/350\n",
      "4049/4049 [==============================] - 778s 192ms/step - loss: 1.9647 - accuracy: 0.4062 - top-3-accuracy: 0.6251 - val_loss: 1.2388 - val_accuracy: 0.7123 - val_top-3-accuracy: 0.8824\n",
      "Epoch 19/350\n",
      "4049/4049 [==============================] - 777s 192ms/step - loss: 1.9615 - accuracy: 0.4077 - top-3-accuracy: 0.6255 - val_loss: 1.2243 - val_accuracy: 0.7195 - val_top-3-accuracy: 0.8854\n",
      "Epoch 20/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 1.9589 - accuracy: 0.4086 - top-3-accuracy: 0.6260 - val_loss: 1.2305 - val_accuracy: 0.7193 - val_top-3-accuracy: 0.8854\n",
      "Epoch 21/350\n",
      "4049/4049 [==============================] - 773s 191ms/step - loss: 1.9591 - accuracy: 0.4084 - top-3-accuracy: 0.6267 - val_loss: 1.2355 - val_accuracy: 0.7224 - val_top-3-accuracy: 0.8882\n",
      "Epoch 22/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9562 - accuracy: 0.4102 - top-3-accuracy: 0.6267 - val_loss: 1.2445 - val_accuracy: 0.7222 - val_top-3-accuracy: 0.8834\n",
      "Epoch 23/350\n",
      "4049/4049 [==============================] - 779s 192ms/step - loss: 1.9525 - accuracy: 0.4122 - top-3-accuracy: 0.6278 - val_loss: 1.2433 - val_accuracy: 0.7235 - val_top-3-accuracy: 0.8863\n",
      "Epoch 24/350\n",
      "4049/4049 [==============================] - 782s 193ms/step - loss: 1.9576 - accuracy: 0.4094 - top-3-accuracy: 0.6262 - val_loss: 1.2221 - val_accuracy: 0.7208 - val_top-3-accuracy: 0.8833\n",
      "Epoch 25/350\n",
      "4049/4049 [==============================] - 782s 193ms/step - loss: 1.9500 - accuracy: 0.4132 - top-3-accuracy: 0.6289 - val_loss: 1.2168 - val_accuracy: 0.7301 - val_top-3-accuracy: 0.8871\n",
      "Epoch 26/350\n",
      "4049/4049 [==============================] - 781s 193ms/step - loss: 1.9471 - accuracy: 0.4150 - top-3-accuracy: 0.6294 - val_loss: 1.1845 - val_accuracy: 0.7331 - val_top-3-accuracy: 0.8890\n",
      "Epoch 27/350\n",
      "4049/4049 [==============================] - 779s 192ms/step - loss: 2.0671 - accuracy: 0.3456 - top-3-accuracy: 0.5939 - val_loss: 1.5457 - val_accuracy: 0.5789 - val_top-3-accuracy: 0.8423\n",
      "Epoch 28/350\n",
      "4049/4049 [==============================] - 779s 193ms/step - loss: 2.0968 - accuracy: 0.3279 - top-3-accuracy: 0.5888 - val_loss: 1.4910 - val_accuracy: 0.5973 - val_top-3-accuracy: 0.8531\n",
      "Epoch 29/350\n",
      "4049/4049 [==============================] - 776s 192ms/step - loss: 2.0782 - accuracy: 0.3386 - top-3-accuracy: 0.5944 - val_loss: 1.4398 - val_accuracy: 0.6158 - val_top-3-accuracy: 0.8586\n",
      "Epoch 30/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 2.0647 - accuracy: 0.3461 - top-3-accuracy: 0.5990 - val_loss: 1.4267 - val_accuracy: 0.6232 - val_top-3-accuracy: 0.8612\n",
      "Epoch 31/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 2.0617 - accuracy: 0.3485 - top-3-accuracy: 0.5987 - val_loss: 1.5834 - val_accuracy: 0.5594 - val_top-3-accuracy: 0.8375\n",
      "Epoch 32/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 2.0516 - accuracy: 0.3553 - top-3-accuracy: 0.6015 - val_loss: 1.3836 - val_accuracy: 0.6414 - val_top-3-accuracy: 0.8688\n",
      "Epoch 33/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 2.0379 - accuracy: 0.3636 - top-3-accuracy: 0.6066 - val_loss: 1.3744 - val_accuracy: 0.6544 - val_top-3-accuracy: 0.8717\n",
      "Epoch 34/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 2.0294 - accuracy: 0.3689 - top-3-accuracy: 0.6086 - val_loss: 1.3609 - val_accuracy: 0.6560 - val_top-3-accuracy: 0.8713\n",
      "Epoch 35/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 2.0217 - accuracy: 0.3736 - top-3-accuracy: 0.6107 - val_loss: 1.4017 - val_accuracy: 0.6312 - val_top-3-accuracy: 0.8592\n",
      "Epoch 36/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 2.0153 - accuracy: 0.3776 - top-3-accuracy: 0.6120 - val_loss: 1.3374 - val_accuracy: 0.6699 - val_top-3-accuracy: 0.8748\n",
      "Epoch 37/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 2.0091 - accuracy: 0.3813 - top-3-accuracy: 0.6134 - val_loss: 1.3265 - val_accuracy: 0.6722 - val_top-3-accuracy: 0.8731\n",
      "Epoch 38/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 2.0039 - accuracy: 0.3843 - top-3-accuracy: 0.6155 - val_loss: 1.2959 - val_accuracy: 0.6795 - val_top-3-accuracy: 0.8774\n",
      "Epoch 39/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 1.9979 - accuracy: 0.3878 - top-3-accuracy: 0.6163 - val_loss: 1.3037 - val_accuracy: 0.6899 - val_top-3-accuracy: 0.8764\n",
      "Epoch 40/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 1.9939 - accuracy: 0.3902 - top-3-accuracy: 0.6176 - val_loss: 1.2909 - val_accuracy: 0.6962 - val_top-3-accuracy: 0.8798\n",
      "Epoch 41/350\n",
      "4049/4049 [==============================] - 775s 191ms/step - loss: 1.9885 - accuracy: 0.3932 - top-3-accuracy: 0.6186 - val_loss: 1.2804 - val_accuracy: 0.6962 - val_top-3-accuracy: 0.8797\n",
      "Epoch 42/350\n",
      "4049/4049 [==============================] - 778s 192ms/step - loss: 1.9867 - accuracy: 0.3941 - top-3-accuracy: 0.6196 - val_loss: 1.2708 - val_accuracy: 0.7009 - val_top-3-accuracy: 0.8812\n",
      "Epoch 43/350\n",
      "4049/4049 [==============================] - 779s 192ms/step - loss: 1.9797 - accuracy: 0.3981 - top-3-accuracy: 0.6211 - val_loss: 1.2950 - val_accuracy: 0.7011 - val_top-3-accuracy: 0.8795\n",
      "Epoch 44/350\n",
      "4049/4049 [==============================] - 779s 192ms/step - loss: 1.9800 - accuracy: 0.3984 - top-3-accuracy: 0.6211 - val_loss: 1.3284 - val_accuracy: 0.6868 - val_top-3-accuracy: 0.8762\n",
      "Epoch 45/350\n",
      "4049/4049 [==============================] - 779s 192ms/step - loss: 1.9745 - accuracy: 0.4012 - top-3-accuracy: 0.6229 - val_loss: 1.2556 - val_accuracy: 0.7098 - val_top-3-accuracy: 0.8829\n",
      "Epoch 46/350\n",
      "4049/4049 [==============================] - 779s 192ms/step - loss: 1.9693 - accuracy: 0.4044 - top-3-accuracy: 0.6231 - val_loss: 1.2403 - val_accuracy: 0.7141 - val_top-3-accuracy: 0.8835\n",
      "Epoch 47/350\n",
      "4049/4049 [==============================] - 779s 193ms/step - loss: 1.9655 - accuracy: 0.4060 - top-3-accuracy: 0.6250 - val_loss: 1.2397 - val_accuracy: 0.7162 - val_top-3-accuracy: 0.8844\n",
      "Epoch 48/350\n",
      "4049/4049 [==============================] - 780s 193ms/step - loss: 1.9637 - accuracy: 0.4065 - top-3-accuracy: 0.6257 - val_loss: 1.2776 - val_accuracy: 0.7149 - val_top-3-accuracy: 0.8802\n",
      "Epoch 49/350\n",
      "4049/4049 [==============================] - 780s 193ms/step - loss: 1.9745 - accuracy: 0.4004 - top-3-accuracy: 0.6224 - val_loss: 1.2406 - val_accuracy: 0.7218 - val_top-3-accuracy: 0.8849\n",
      "Epoch 50/350\n",
      "4049/4049 [==============================] - 780s 193ms/step - loss: 1.9619 - accuracy: 0.4077 - top-3-accuracy: 0.6253 - val_loss: 1.3185 - val_accuracy: 0.6935 - val_top-3-accuracy: 0.8713\n",
      "Epoch 51/350\n",
      "4049/4049 [==============================] - 780s 193ms/step - loss: 1.9555 - accuracy: 0.4106 - top-3-accuracy: 0.6271 - val_loss: 1.2567 - val_accuracy: 0.7158 - val_top-3-accuracy: 0.8812\n",
      "Epoch 52/350\n",
      "4049/4049 [==============================] - 780s 193ms/step - loss: 1.9523 - accuracy: 0.4125 - top-3-accuracy: 0.6288 - val_loss: 1.2204 - val_accuracy: 0.7303 - val_top-3-accuracy: 0.8876\n",
      "Epoch 53/350\n",
      "4049/4049 [==============================] - 780s 193ms/step - loss: 1.9492 - accuracy: 0.4141 - top-3-accuracy: 0.6290 - val_loss: 1.2258 - val_accuracy: 0.7291 - val_top-3-accuracy: 0.8874\n",
      "Epoch 54/350\n",
      "4049/4049 [==============================] - 780s 193ms/step - loss: 1.9463 - accuracy: 0.4153 - top-3-accuracy: 0.6293 - val_loss: 1.2247 - val_accuracy: 0.7326 - val_top-3-accuracy: 0.8865\n",
      "Epoch 55/350\n",
      "4049/4049 [==============================] - 780s 193ms/step - loss: 1.9432 - accuracy: 0.4171 - top-3-accuracy: 0.6302 - val_loss: 1.2542 - val_accuracy: 0.7229 - val_top-3-accuracy: 0.8847\n",
      "Epoch 56/350\n",
      "4049/4049 [==============================] - 780s 193ms/step - loss: 1.9438 - accuracy: 0.4168 - top-3-accuracy: 0.6297 - val_loss: 1.1957 - val_accuracy: 0.7356 - val_top-3-accuracy: 0.8896\n",
      "Epoch 57/350\n",
      "4049/4049 [==============================] - 773s 191ms/step - loss: 1.9400 - accuracy: 0.4188 - top-3-accuracy: 0.6312 - val_loss: 1.2569 - val_accuracy: 0.6966 - val_top-3-accuracy: 0.8769\n",
      "Epoch 58/350\n",
      "4049/4049 [==============================] - 771s 191ms/step - loss: 1.9369 - accuracy: 0.4200 - top-3-accuracy: 0.6319 - val_loss: 1.1940 - val_accuracy: 0.7356 - val_top-3-accuracy: 0.8866\n",
      "Epoch 59/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9353 - accuracy: 0.4208 - top-3-accuracy: 0.6316 - val_loss: 1.2004 - val_accuracy: 0.7398 - val_top-3-accuracy: 0.8883\n",
      "Epoch 60/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9366 - accuracy: 0.4195 - top-3-accuracy: 0.6317 - val_loss: 1.2455 - val_accuracy: 0.7123 - val_top-3-accuracy: 0.8801\n",
      "Epoch 61/350\n",
      "4049/4049 [==============================] - 771s 191ms/step - loss: 1.9329 - accuracy: 0.4223 - top-3-accuracy: 0.6329 - val_loss: 1.2132 - val_accuracy: 0.7213 - val_top-3-accuracy: 0.8829\n",
      "Epoch 62/350\n",
      "4049/4049 [==============================] - 771s 190ms/step - loss: 1.9298 - accuracy: 0.4231 - top-3-accuracy: 0.6336 - val_loss: 1.1912 - val_accuracy: 0.7397 - val_top-3-accuracy: 0.8870\n",
      "Epoch 63/350\n",
      "4049/4049 [==============================] - 771s 190ms/step - loss: 1.9292 - accuracy: 0.4234 - top-3-accuracy: 0.6338 - val_loss: 1.2042 - val_accuracy: 0.7404 - val_top-3-accuracy: 0.8873\n",
      "Epoch 64/350\n",
      "4049/4049 [==============================] - 774s 191ms/step - loss: 1.9255 - accuracy: 0.4248 - top-3-accuracy: 0.6344 - val_loss: 1.1633 - val_accuracy: 0.7434 - val_top-3-accuracy: 0.8889\n",
      "Epoch 65/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9239 - accuracy: 0.4259 - top-3-accuracy: 0.6348 - val_loss: 1.1815 - val_accuracy: 0.7471 - val_top-3-accuracy: 0.8898\n",
      "Epoch 66/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9264 - accuracy: 0.4238 - top-3-accuracy: 0.6347 - val_loss: 1.1888 - val_accuracy: 0.7471 - val_top-3-accuracy: 0.8882\n",
      "Epoch 67/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9213 - accuracy: 0.4266 - top-3-accuracy: 0.6350 - val_loss: 1.2028 - val_accuracy: 0.7460 - val_top-3-accuracy: 0.8866\n",
      "Epoch 68/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9196 - accuracy: 0.4271 - top-3-accuracy: 0.6364 - val_loss: 1.1799 - val_accuracy: 0.7513 - val_top-3-accuracy: 0.8918\n",
      "Epoch 69/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9186 - accuracy: 0.4279 - top-3-accuracy: 0.6363 - val_loss: 1.2026 - val_accuracy: 0.7464 - val_top-3-accuracy: 0.8886: 0.428\n",
      "Epoch 70/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9156 - accuracy: 0.4285 - top-3-accuracy: 0.6373 - val_loss: 1.1918 - val_accuracy: 0.7409 - val_top-3-accuracy: 0.8867\n",
      "Epoch 71/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9142 - accuracy: 0.4288 - top-3-accuracy: 0.6370 - val_loss: 1.1700 - val_accuracy: 0.7511 - val_top-3-accuracy: 0.8899- top-3-\n",
      "Epoch 72/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9146 - accuracy: 0.4289 - top-3-accuracy: 0.6378 - val_loss: 1.1680 - val_accuracy: 0.7474 - val_top-3-accuracy: 0.8889\n",
      "Epoch 73/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9125 - accuracy: 0.4297 - top-3-accuracy: 0.6383 - val_loss: 1.2170 - val_accuracy: 0.7370 - val_top-3-accuracy: 0.8851\n",
      "Epoch 74/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9114 - accuracy: 0.4300 - top-3-accuracy: 0.6386 - val_loss: 1.1996 - val_accuracy: 0.7423 - val_top-3-accuracy: 0.8878\n",
      "Epoch 75/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9082 - accuracy: 0.4314 - top-3-accuracy: 0.6392 - val_loss: 1.1678 - val_accuracy: 0.7563 - val_top-3-accuracy: 0.8912\n",
      "Epoch 76/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9080 - accuracy: 0.4311 - top-3-accuracy: 0.6390 - val_loss: 1.1949 - val_accuracy: 0.7369 - val_top-3-accuracy: 0.8864\n",
      "Epoch 77/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9099 - accuracy: 0.4304 - top-3-accuracy: 0.6382 - val_loss: 1.1759 - val_accuracy: 0.7521 - val_top-3-accuracy: 0.8873\n",
      "Epoch 78/350\n",
      "4049/4049 [==============================] - 774s 191ms/step - loss: 1.9051 - accuracy: 0.4327 - top-3-accuracy: 0.6403 - val_loss: 1.1612 - val_accuracy: 0.7581 - val_top-3-accuracy: 0.8903\n",
      "Epoch 79/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9046 - accuracy: 0.4326 - top-3-accuracy: 0.6397 - val_loss: 1.1897 - val_accuracy: 0.7361 - val_top-3-accuracy: 0.8846\n",
      "Epoch 80/350\n",
      "4049/4049 [==============================] - 774s 191ms/step - loss: 1.9028 - accuracy: 0.4332 - top-3-accuracy: 0.6407 - val_loss: 1.1437 - val_accuracy: 0.7588 - val_top-3-accuracy: 0.8909\n",
      "Epoch 81/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9026 - accuracy: 0.4329 - top-3-accuracy: 0.6406 - val_loss: 1.1638 - val_accuracy: 0.7568 - val_top-3-accuracy: 0.8911\n",
      "Epoch 82/350\n",
      "4049/4049 [==============================] - 771s 191ms/step - loss: 1.9013 - accuracy: 0.4333 - top-3-accuracy: 0.6416 - val_loss: 1.1550 - val_accuracy: 0.7488 - val_top-3-accuracy: 0.8903\n",
      "Epoch 83/350\n",
      "4049/4049 [==============================] - 771s 191ms/step - loss: 1.9005 - accuracy: 0.4337 - top-3-accuracy: 0.6412 - val_loss: 1.2487 - val_accuracy: 0.7181 - val_top-3-accuracy: 0.8788\n",
      "Epoch 84/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.8993 - accuracy: 0.4338 - top-3-accuracy: 0.6409 - val_loss: 1.1933 - val_accuracy: 0.7520 - val_top-3-accuracy: 0.8889\n",
      "Epoch 85/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.8969 - accuracy: 0.4350 - top-3-accuracy: 0.6417 - val_loss: 1.1476 - val_accuracy: 0.7598 - val_top-3-accuracy: 0.8916\n",
      "Epoch 86/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.8962 - accuracy: 0.4351 - top-3-accuracy: 0.6426 - val_loss: 1.1463 - val_accuracy: 0.7601 - val_top-3-accuracy: 0.8918\n",
      "Epoch 87/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.8949 - accuracy: 0.4351 - top-3-accuracy: 0.6427 - val_loss: 1.1498 - val_accuracy: 0.7533 - val_top-3-accuracy: 0.8899\n",
      "Epoch 88/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.8947 - accuracy: 0.4354 - top-3-accuracy: 0.6431 - val_loss: 1.1826 - val_accuracy: 0.7532 - val_top-3-accuracy: 0.8870\n",
      "Epoch 89/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.8957 - accuracy: 0.4346 - top-3-accuracy: 0.6425 - val_loss: 1.1802 - val_accuracy: 0.7516 - val_top-3-accuracy: 0.8893s: 1.8956\n",
      "Epoch 90/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.8923 - accuracy: 0.4360 - top-3-accuracy: 0.6444 - val_loss: 1.2368 - val_accuracy: 0.7213 - val_top-3-accuracy: 0.8772\n",
      "Epoch 91/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.8908 - accuracy: 0.4363 - top-3-accuracy: 0.6438 - val_loss: 1.1518 - val_accuracy: 0.7616 - val_top-3-accuracy: 0.8918\n",
      "Epoch 92/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.8903 - accuracy: 0.4367 - top-3-accuracy: 0.6437 - val_loss: 1.1718 - val_accuracy: 0.7568 - val_top-3-accuracy: 0.8894\n",
      "Epoch 93/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0469 - accuracy: 0.3541 - top-3-accuracy: 0.6006 - val_loss: 1.5762 - val_accuracy: 0.5759 - val_top-3-accuracy: 0.8416\n",
      "Epoch 94/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0994 - accuracy: 0.3278 - top-3-accuracy: 0.5880 - val_loss: 1.5220 - val_accuracy: 0.5932 - val_top-3-accuracy: 0.8493\n",
      "Epoch 95/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0838 - accuracy: 0.3361 - top-3-accuracy: 0.5931 - val_loss: 1.4888 - val_accuracy: 0.6054 - val_top-3-accuracy: 0.8562\n",
      "Epoch 96/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0710 - accuracy: 0.3431 - top-3-accuracy: 0.5968 - val_loss: 1.4425 - val_accuracy: 0.6199 - val_top-3-accuracy: 0.8577\n",
      "Epoch 97/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0602 - accuracy: 0.3502 - top-3-accuracy: 0.5999 - val_loss: 1.4595 - val_accuracy: 0.6251 - val_top-3-accuracy: 0.8563\n",
      "Epoch 98/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0495 - accuracy: 0.3559 - top-3-accuracy: 0.6035 - val_loss: 1.4112 - val_accuracy: 0.6388 - val_top-3-accuracy: 0.8638\n",
      "Epoch 99/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0464 - accuracy: 0.3585 - top-3-accuracy: 0.6042 - val_loss: 1.4131 - val_accuracy: 0.6403 - val_top-3-accuracy: 0.8640\n",
      "Epoch 100/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0351 - accuracy: 0.3652 - top-3-accuracy: 0.6064 - val_loss: 1.3826 - val_accuracy: 0.6509 - val_top-3-accuracy: 0.8691\n",
      "Epoch 101/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0267 - accuracy: 0.3708 - top-3-accuracy: 0.6091 - val_loss: 1.3571 - val_accuracy: 0.6600 - val_top-3-accuracy: 0.8713\n",
      "Epoch 102/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0188 - accuracy: 0.3750 - top-3-accuracy: 0.6108 - val_loss: 1.3756 - val_accuracy: 0.6440 - val_top-3-accuracy: 0.8622\n",
      "Epoch 103/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0115 - accuracy: 0.3793 - top-3-accuracy: 0.6132 - val_loss: 1.3184 - val_accuracy: 0.6735 - val_top-3-accuracy: 0.8758\n",
      "Epoch 104/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0049 - accuracy: 0.3834 - top-3-accuracy: 0.6145 - val_loss: 1.3123 - val_accuracy: 0.6797 - val_top-3-accuracy: 0.8756\n",
      "Epoch 105/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0497 - accuracy: 0.3572 - top-3-accuracy: 0.6016 - val_loss: 1.4485 - val_accuracy: 0.6164 - val_top-3-accuracy: 0.8599\n",
      "Epoch 106/350\n",
      "4049/4049 [==============================] - 771s 191ms/step - loss: 2.0331 - accuracy: 0.3655 - top-3-accuracy: 0.6068 - val_loss: 1.3418 - val_accuracy: 0.6686 - val_top-3-accuracy: 0.8737\n",
      "Epoch 107/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 2.0048 - accuracy: 0.3831 - top-3-accuracy: 0.6148 - val_loss: 1.2996 - val_accuracy: 0.6788 - val_top-3-accuracy: 0.8801\n",
      "Epoch 108/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9950 - accuracy: 0.3889 - top-3-accuracy: 0.6169 - val_loss: 1.2799 - val_accuracy: 0.6895 - val_top-3-accuracy: 0.8803\n",
      "Epoch 109/350\n",
      "4049/4049 [==============================] - 771s 191ms/step - loss: 1.9872 - accuracy: 0.3937 - top-3-accuracy: 0.6191 - val_loss: 1.3224 - val_accuracy: 0.6889 - val_top-3-accuracy: 0.8767\n",
      "Epoch 110/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9823 - accuracy: 0.3965 - top-3-accuracy: 0.6204 - val_loss: 1.2987 - val_accuracy: 0.7002 - val_top-3-accuracy: 0.8786\n",
      "Epoch 111/350\n",
      "4049/4049 [==============================] - 779s 192ms/step - loss: 1.9768 - accuracy: 0.3996 - top-3-accuracy: 0.6218 - val_loss: 1.3349 - val_accuracy: 0.6761 - val_top-3-accuracy: 0.8700\n",
      "Epoch 112/350\n",
      "4049/4049 [==============================] - 772s 191ms/step - loss: 1.9723 - accuracy: 0.4016 - top-3-accuracy: 0.6229 - val_loss: 1.2652 - val_accuracy: 0.7081 - val_top-3-accuracy: 0.8802\n",
      "Epoch 113/350\n",
      "2048/4049 [==============>...............] - ETA: 6:00 - loss: 1.9792 - accuracy: 0.3978 - top-3-accuracy: 0.6208"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(x_train, y_train_1hot,\n",
    "      epochs= 350, \n",
    "      batch_size= batch_size, \n",
    "      validation_data=(x_test, y_test_1hot),\n",
    "     callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa8311c6-9529-4374-9f19-aab4be904e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get file name: auto-generating name\n",
      "Activation_function not in workspace\n",
      "extras  is not in workspace\n",
      "Current run hyper_params are dict_keys(['S_N', 'Start_time', 'NoteBook_name', 'Uniqueness_of_each_run', 'Base_dir', 'Train_shape', 'Output_shape', 'num_epochs', 'Activation_function', 'optimizer', 'learning_rate', 'loss_function', 'Accuracy_per_epoch', 'Loss_per_epoch', 'Stop_time', 'Model_config', 'Performance_on_test_set', 'output_path', 'shuffle', 'Computer_name', 'extras']):dict_values([16, '09_January_22_1705', 'NewAttention_RowBlock_Dec', 'Used Amsgrad and default learning rate to train. Removed label smoothing too', '../all_block_data\\\\FindPeaks_data\\\\Dec_Train_block_len_21_030122_0614', (518245, 15, 21), '', '', '', '', '', '', [], [], '', '', '', '', 0, 'AQ-LHJBMA1', ''])\n",
      "Fields to be updated include: ['Activation_function', 'learning_rate', 'loss_function', 'Accuracy_per_epoch', 'Loss_per_epoch', 'Stop_time', 'Model_config', 'Performance_on_test_set', 'extras']\n"
     ]
    }
   ],
   "source": [
    "log['Uniqueness_of_each_run'] = 'Used Amsgrad and default learning rate to train. Removed label smoothing too'\n",
    "run_completion_comment = f'Training on first 400 echos: Training looks so good! 98% acc. Need to test for overfitting'\n",
    "if \"log_idx\" in globals():\n",
    "    log[\"S_N\"] = log_idx\n",
    "    log['run_completion_comment'] = run_completion_comment\n",
    "    log_idx = create_log_entry('../testing_sheet2.xlsx', log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bebfea3f-776e-45e5-a223-d3071cc4c4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check start idx: 11343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7),\n",
       " (12, 7)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "check_start = random.randint(0,len(x_val))\n",
    "\n",
    "print(f'Check start idx: {check_start}')\n",
    "[(np.argmax(y_val[idx]), np.argmax(model.predict(np.expand_dims(x_val[idx],axis=0))) ) for idx in range(check_start,check_start+20) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43003c33-f2e8-4981-a601-84b1765ab943",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013/1013 [==============================] - 27s 26ms/step - loss: 14.9815 - accuracy: 0.0233 - top-3-accuracy: 0.1946\n",
      "Test accuracy: 2.33%\n"
     ]
    }
   ],
   "source": [
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
    "_, accuracy,top_5_accuracy = model.evaluate(x_val, y_val)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "# print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "\n",
    "model.save(f'{base_path}//{ipynbname.name()}//{time_stamp}_Acc_{accuracy}_{row_length}x{col_length}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83731cd6-3657-4e9e-b7e8-68c0d826956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train further\n",
    "if accuracy < 0.7:\n",
    "    history = model.fit(x_train, y_train,\n",
    "          epochs= 20, \n",
    "          batch_size= batch_size, \n",
    "          validation_data=(x_test, y_test),\n",
    "         callbacks=callbacks) #mcp_save, callbacks=[reduce_lr_loss]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibk_tf_2.6",
   "language": "python",
   "name": "tf2.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
